{
  "version": 3,
  "sources": ["../../../../node_modules/optimism/src/cache.ts", "../../../../node_modules/@wry/context/src/slot.ts", "../../../../node_modules/@wry/context/src/index.ts", "../../../../node_modules/optimism/src/context.ts", "../../../../node_modules/optimism/src/helpers.ts", "../../../../node_modules/optimism/src/entry.ts", "../../../../node_modules/optimism/src/dep.ts", "../../../../node_modules/optimism/src/index.ts", "../../../../node_modules/@apollo/src/cache/core/cache.ts", "../../../../node_modules/@apollo/src/cache/core/types/Cache.ts", "../../../../node_modules/@apollo/src/cache/core/types/common.ts", "../../../../node_modules/@wry/equality/src/index.ts", "../../../../node_modules/@apollo/src/cache/inmemory/helpers.ts", "../../../../node_modules/@apollo/src/cache/inmemory/entityStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/object-canon.ts", "../../../../node_modules/@apollo/src/cache/inmemory/readFromStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/reactiveVars.ts", "../../../../node_modules/@apollo/src/cache/inmemory/key-extractor.ts", "../../../../node_modules/@apollo/src/cache/inmemory/policies.ts", "../../../../node_modules/@apollo/src/cache/inmemory/writeToStore.ts", "../../../../node_modules/@apollo/src/cache/inmemory/inMemoryCache.ts", "../../../../node_modules/@apollo/src/cache/inmemory/fragmentRegistry.ts"],
  "sourcesContent": ["interface Node<K, V> {\n  key: K;\n  value: V;\n  newer: Node<K, V> | null;\n  older: Node<K, V> | null;\n}\n\nfunction defaultDispose() {}\n\nexport class Cache<K = any, V = any> {\n  private map = new Map<K, Node<K, V>>();\n  private newest: Node<K, V> | null = null;\n  private oldest: Node<K, V> | null = null;\n\n  constructor(\n    private max = Infinity,\n    public dispose: (value: V, key: K) => void = defaultDispose,\n  ) {}\n\n  public has(key: K): boolean {\n    return this.map.has(key);\n  }\n\n  public get(key: K): V | undefined {\n    const node = this.getNode(key);\n    return node && node.value;\n  }\n\n  private getNode(key: K): Node<K, V> | undefined {\n    const node = this.map.get(key);\n\n    if (node && node !== this.newest) {\n      const { older, newer } = node;\n\n      if (newer) {\n        newer.older = older;\n      }\n\n      if (older) {\n        older.newer = newer;\n      }\n\n      node.older = this.newest;\n      node.older!.newer = node;\n\n      node.newer = null;\n      this.newest = node;\n\n      if (node === this.oldest) {\n        this.oldest = newer;\n      }\n    }\n\n    return node;\n  }\n\n  public set(key: K, value: V): V {\n    let node = this.getNode(key);\n    if (node) {\n      return node.value = value;\n    }\n\n    node = {\n      key,\n      value,\n      newer: null,\n      older: this.newest\n    };\n\n    if (this.newest) {\n      this.newest.newer = node;\n    }\n\n    this.newest = node;\n    this.oldest = this.oldest || node;\n\n    this.map.set(key, node);\n\n    return node.value;\n  }\n\n  public clean() {\n    while (this.oldest && this.map.size > this.max) {\n      this.delete(this.oldest.key);\n    }\n  }\n\n  public delete(key: K): boolean {\n    const node = this.map.get(key);\n    if (node) {\n      if (node === this.newest) {\n        this.newest = node.older;\n      }\n\n      if (node === this.oldest) {\n        this.oldest = node.newer;\n      }\n\n      if (node.newer) {\n        node.newer.older = node.older;\n      }\n\n      if (node.older) {\n        node.older.newer = node.newer;\n      }\n\n      this.map.delete(key);\n      this.dispose(node.value, key);\n\n      return true;\n    }\n\n    return false;\n  }\n}\n", "type Context = {\n  parent: Context | null;\n  slots: { [slotId: string]: any };\n}\n\n// This currentContext variable will only be used if the makeSlotClass\n// function is called, which happens only if this is the first copy of the\n// @wry/context package to be imported.\nlet currentContext: Context | null = null;\n\n// This unique internal object is used to denote the absence of a value\n// for a given Slot, and is never exposed to outside code.\nconst MISSING_VALUE: any = {};\n\nlet idCounter = 1;\n\n// Although we can't do anything about the cost of duplicated code from\n// accidentally bundling multiple copies of the @wry/context package, we can\n// avoid creating the Slot class more than once using makeSlotClass.\nconst makeSlotClass = () => class Slot<TValue> {\n  // If you have a Slot object, you can find out its slot.id, but you cannot\n  // guess the slot.id of a Slot you don't have access to, thanks to the\n  // randomized suffix.\n  public readonly id = [\n    \"slot\",\n    idCounter++,\n    Date.now(),\n    Math.random().toString(36).slice(2),\n  ].join(\":\");\n\n  public hasValue() {\n    for (let context = currentContext; context; context = context.parent) {\n      // We use the Slot object iself as a key to its value, which means the\n      // value cannot be obtained without a reference to the Slot object.\n      if (this.id in context.slots) {\n        const value = context.slots[this.id];\n        if (value === MISSING_VALUE) break;\n        if (context !== currentContext) {\n          // Cache the value in currentContext.slots so the next lookup will\n          // be faster. This caching is safe because the tree of contexts and\n          // the values of the slots are logically immutable.\n          currentContext!.slots[this.id] = value;\n        }\n        return true;\n      }\n    }\n    if (currentContext) {\n      // If a value was not found for this Slot, it's never going to be found\n      // no matter how many times we look it up, so we might as well cache\n      // the absence of the value, too.\n      currentContext.slots[this.id] = MISSING_VALUE;\n    }\n    return false;\n  }\n\n  public getValue(): TValue | undefined {\n    if (this.hasValue()) {\n      return currentContext!.slots[this.id] as TValue;\n    }\n  }\n\n  public withValue<TResult, TArgs extends any[], TThis = any>(\n    value: TValue,\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ): TResult {\n    const slots = {\n      __proto__: null,\n      [this.id]: value,\n    };\n    const parent = currentContext;\n    currentContext = { parent, slots };\n    try {\n      // Function.prototype.apply allows the arguments array argument to be\n      // omitted or undefined, so args! is fine here.\n      return callback.apply(thisArg!, args!);\n    } finally {\n      currentContext = parent;\n    }\n  }\n\n  // Capture the current context and wrap a callback function so that it\n  // reestablishes the captured context when called.\n  static bind<TArgs extends any[], TResult, TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n  ) {\n    const context = currentContext;\n    return function (this: TThis) {\n      const saved = currentContext;\n      try {\n        currentContext = context;\n        return callback.apply(this, arguments as any);\n      } finally {\n        currentContext = saved;\n      }\n    } as typeof callback;\n  }\n\n  // Immediately run a callback function without any captured context.\n  static noContext<TResult, TArgs extends any[], TThis = any>(\n    callback: (this: TThis, ...args: TArgs) => TResult,\n    // Given the prevalence of arrow functions, specifying arguments is likely\n    // to be much more common than specifying `this`, hence this ordering:\n    args?: TArgs,\n    thisArg?: TThis,\n  ) {\n    if (currentContext) {\n      const saved = currentContext;\n      try {\n        currentContext = null;\n        // Function.prototype.apply allows the arguments array argument to be\n        // omitted or undefined, so args! is fine here.\n        return callback.apply(thisArg!, args!);\n      } finally {\n        currentContext = saved;\n      }\n    } else {\n      return callback.apply(thisArg!, args!);\n    }\n  }\n};\n\nfunction maybe<T>(fn: () => T): T | undefined {\n  try {\n    return fn();\n  } catch (ignored) {}\n}\n\n// We store a single global implementation of the Slot class as a permanent\n// non-enumerable property of the globalThis object. This obfuscation does\n// nothing to prevent access to the Slot class, but at least it ensures the\n// implementation (i.e. currentContext) cannot be tampered with, and all copies\n// of the @wry/context package (hopefully just one) will share the same Slot\n// implementation. Since the first copy of the @wry/context package to be\n// imported wins, this technique imposes a steep cost for any future breaking\n// changes to the Slot class.\nconst globalKey = \"@wry/context:Slot\";\n\nconst host =\n  // Prefer globalThis when available.\n  // https://github.com/benjamn/wryware/issues/347\n  maybe(() => globalThis) ||\n  // Fall back to global, which works in Node.js and may be converted by some\n  // bundlers to the appropriate identifier (window, self, ...) depending on the\n  // bundling target. https://github.com/endojs/endo/issues/576#issuecomment-1178515224\n  maybe(() => global) ||\n  // Otherwise, use a dummy host that's local to this module. We used to fall\n  // back to using the Array constructor as a namespace, but that was flagged in\n  // https://github.com/benjamn/wryware/issues/347, and can be avoided.\n  Object.create(null) as typeof Array;\n\n// Whichever globalHost we're using, make TypeScript happy about the additional\n// globalKey property.\nconst globalHost: typeof host & {\n  [globalKey]?: typeof Slot;\n} = host;\n\nexport const Slot: ReturnType<typeof makeSlotClass> =\n  globalHost[globalKey] ||\n  // Earlier versions of this package stored the globalKey property on the Array\n  // constructor, so we check there as well, to prevent Slot class duplication.\n  (Array as typeof globalHost)[globalKey] ||\n  (function (Slot) {\n    try {\n      Object.defineProperty(globalHost, globalKey, {\n        value: Slot,\n        enumerable: false,\n        writable: false,\n        // When it was possible for globalHost to be the Array constructor (a\n        // legacy Slot dedup strategy), it was important for the property to be\n        // configurable:true so it could be deleted. That does not seem to be as\n        // important when globalHost is the global object, but I don't want to\n        // cause similar problems again, and configurable:true seems safest.\n        // https://github.com/endojs/endo/issues/576#issuecomment-1178274008\n        configurable: true\n      });\n    } finally {\n      return Slot;\n    }\n  })(makeSlotClass());\n", "import { Slot } from \"./slot.js\";\nexport { Slot }\nexport const { bind, noContext } = Slot;\n\n// Relying on the @types/node declaration of global.setTimeout can make\n// things tricky for dowstream projects (see PR #7).\ndeclare function setTimeout(\n  callback: (...args: any[]) => any,\n  ms?: number,\n  ...args: any[]\n): any;\n\n// Like global.setTimeout, except the callback runs with captured context.\nexport { setTimeoutWithContext as setTimeout };\nfunction setTimeoutWithContext(callback: () => any, delay: number) {\n  return setTimeout(bind(callback), delay);\n}\n\n// Turn any generator function into an async function (using yield instead\n// of await), with context automatically preserved across yields.\nexport function asyncFromGen<\n  TArgs extends any[],\n  TYield = any,\n  TReturn = any,\n  TNext = any,\n>(\n  genFn: (...args: TArgs) => Generator<TYield, TReturn, TNext>\n) {\n  return function (this: any) {\n    const gen = genFn.apply(this, arguments as any);\n\n    type Method = (\n      this: Generator<TYield, TReturn, TNext>,\n      arg: any,\n    ) => IteratorResult<TYield, TReturn>;\n\n    const boundNext: Method = bind(gen.next);\n    const boundThrow: Method = bind(gen.throw!);\n\n    return new Promise((resolve, reject) => {\n      function invoke(method: Method, argument: any) {\n        try {\n          var result: any = method.call(gen, argument);\n        } catch (error) {\n          return reject(error);\n        }\n        const next = result.done ? resolve : invokeNext;\n        if (isPromiseLike(result.value)) {\n          result.value.then(next, result.done ? reject : invokeThrow);\n        } else {\n          next(result.value);\n        }\n      }\n      const invokeNext = (value?: any) => invoke(boundNext, value);\n      const invokeThrow = (error: any) => invoke(boundThrow, error);\n      invokeNext();\n    });\n  } as (...args: TArgs) => Promise<any>;\n}\n\nfunction isPromiseLike(value: any): value is PromiseLike<any> {\n  return value && typeof value.then === \"function\";\n}\n\n// If you use the fibers npm package to implement coroutines in Node.js,\n// you should call this function at least once to ensure context management\n// remains coherent across any yields.\nconst wrappedFibers: Function[] = [];\nexport function wrapYieldingFiberMethods<F extends Function>(Fiber: F): F {\n  // There can be only one implementation of Fiber per process, so this array\n  // should never grow longer than one element.\n  if (wrappedFibers.indexOf(Fiber) < 0) {\n    const wrap = (obj: any, method: string) => {\n      const fn = obj[method];\n      obj[method] = function () {\n        return noContext(fn, arguments as any, this);\n      };\n    }\n    // These methods can yield, according to\n    // https://github.com/laverdet/node-fibers/blob/ddebed9b8ae3883e57f822e2108e6943e5c8d2a8/fibers.js#L97-L100\n    wrap(Fiber, \"yield\");\n    wrap(Fiber.prototype, \"run\");\n    wrap(Fiber.prototype, \"throwInto\");\n    wrappedFibers.push(Fiber);\n  }\n  return Fiber;\n}\n", "import { Slot } from \"@wry/context\";\nimport { AnyEntry } from \"./entry.js\";\n\nexport const parentEntrySlot = new Slot<AnyEntry | undefined>();\n\nexport function nonReactive<R>(fn: () => R): R {\n  return parentEntrySlot.withValue(void 0, fn);\n}\n\nexport {\n  bind as bindContext,\n  noContext,\n  setTimeout,\n  asyncFromGen,\n} from \"@wry/context\";\n", "export const {\n  hasOwnProperty,\n} = Object.prototype;\n\nexport const arrayFromSet: <T>(set: Set<T>) => T[] =\n  Array.from ||\n  function (set) {\n    const array: any[] = [];\n    set.forEach(item => array.push(item));\n    return array;\n  };\n\nexport type Unsubscribable = {\n  unsubscribe?: void | (() => any);\n}\n\nexport function maybeUnsubscribe(entryOrDep: Unsubscribable) {\n  const { unsubscribe } = entryOrDep;\n  if (typeof unsubscribe === \"function\") {\n    entryOrDep.unsubscribe = void 0;\n    unsubscribe();\n  }\n}\n", "import { parentEntrySlot } from \"./context.js\";\nimport { OptimisticWrapOptions } from \"./index.js\";\nimport { Dep } from \"./dep.js\";\nimport { maybeUnsubscribe, arrayFromSet, Unsubscribable } from \"./helpers.js\";\n\nconst emptySetPool: Set<any>[] = [];\nconst POOL_TARGET_SIZE = 100;\n\n// Since this package might be used browsers, we should avoid using the\n// Node built-in assert module.\nfunction assert(condition: any, optionalMessage?: string) {\n  if (! condition) {\n    throw new Error(optionalMessage || \"assertion failure\");\n  }\n}\n\n// Since exceptions are cached just like normal values, we need an efficient\n// way of representing unknown, ordinary, and exceptional values.\ntype Value<T> =\n  | []           // unknown\n  | [T]          // known value\n  | [void, any]; // known exception\n\nfunction valueIs(a: Value<any>, b: Value<any>) {\n  const len = a.length;\n  return (\n    // Unknown values are not equal to each other.\n    len > 0 &&\n    // Both values must be ordinary (or both exceptional) to be equal.\n    len === b.length &&\n    // The underlying value or exception must be the same.\n    a[len - 1] === b[len - 1]\n  );\n}\n\nfunction valueGet<T>(value: Value<T>): T {\n  switch (value.length) {\n    case 0: throw new Error(\"unknown value\");\n    case 1: return value[0];\n    case 2: throw value[1];\n  }\n}\n\nfunction valueCopy<T>(value: Value<T>): Value<T> {\n  return value.slice(0) as Value<T>;\n}\n\nexport type AnyEntry = Entry<any, any>;\n\nexport class Entry<TArgs extends any[], TValue> {\n  public static count = 0;\n\n  public subscribe: OptimisticWrapOptions<TArgs>[\"subscribe\"];\n  public unsubscribe: Unsubscribable[\"unsubscribe\"];\n\n  public readonly parents = new Set<AnyEntry>();\n  public readonly childValues = new Map<AnyEntry, Value<any>>();\n\n  // When this Entry has children that are dirty, this property becomes\n  // a Set containing other Entry objects, borrowed from emptySetPool.\n  // When the set becomes empty, it gets recycled back to emptySetPool.\n  public dirtyChildren: Set<AnyEntry> | null = null;\n\n  public dirty = true;\n  public recomputing = false;\n  public readonly value: Value<TValue> = [];\n\n  constructor(\n    public readonly fn: (...args: TArgs) => TValue,\n  ) {\n    ++Entry.count;\n  }\n\n  public peek(): TValue | undefined {\n    if (this.value.length === 1 && !mightBeDirty(this)) {\n      rememberParent(this);\n      return this.value[0];\n    }\n  }\n\n  // This is the most important method of the Entry API, because it\n  // determines whether the cached this.value can be returned immediately,\n  // or must be recomputed. The overall performance of the caching system\n  // depends on the truth of the following observations: (1) this.dirty is\n  // usually false, (2) this.dirtyChildren is usually null/empty, and thus\n  // (3) valueGet(this.value) is usually returned without recomputation.\n  public recompute(args: TArgs): TValue {\n    assert(! this.recomputing, \"already recomputing\");\n    rememberParent(this);\n    return mightBeDirty(this)\n      ? reallyRecompute(this, args)\n      : valueGet(this.value);\n  }\n\n  public setDirty() {\n    if (this.dirty) return;\n    this.dirty = true;\n    this.value.length = 0;\n    reportDirty(this);\n    // We can go ahead and unsubscribe here, since any further dirty\n    // notifications we receive will be redundant, and unsubscribing may\n    // free up some resources, e.g. file watchers.\n    maybeUnsubscribe(this);\n  }\n\n  public dispose() {\n    this.setDirty();\n\n    // Sever any dependency relationships with our own children, so those\n    // children don't retain this parent Entry in their child.parents sets,\n    // thereby preventing it from being fully garbage collected.\n    forgetChildren(this);\n\n    // Because this entry has been kicked out of the cache (in index.js),\n    // we've lost the ability to find out if/when this entry becomes dirty,\n    // whether that happens through a subscription, because of a direct call\n    // to entry.setDirty(), or because one of its children becomes dirty.\n    // Because of this loss of future information, we have to assume the\n    // worst (that this entry might have become dirty very soon), so we must\n    // immediately mark this entry's parents as dirty. Normally we could\n    // just call entry.setDirty() rather than calling parent.setDirty() for\n    // each parent, but that would leave this entry in parent.childValues\n    // and parent.dirtyChildren, which would prevent the child from being\n    // truly forgotten.\n    eachParent(this, (parent, child) => {\n      parent.setDirty();\n      forgetChild(parent, this);\n    });\n  }\n\n  public forget() {\n    // The code that creates Entry objects in index.ts will replace this method\n    // with one that actually removes the Entry from the cache, which will also\n    // trigger the entry.dispose method.\n    this.dispose();\n  }\n\n  private deps: Set<Dep<any>> | null = null;\n\n  public dependOn(dep: Dep<any>) {\n    dep.add(this);\n    if (! this.deps) {\n      this.deps = emptySetPool.pop() || new Set<Set<AnyEntry>>();\n    }\n    this.deps.add(dep);\n  }\n\n  public forgetDeps() {\n    if (this.deps) {\n      arrayFromSet(this.deps).forEach(dep => dep.delete(this));\n      this.deps.clear();\n      emptySetPool.push(this.deps);\n      this.deps = null;\n    }\n  }\n}\n\nfunction rememberParent(child: AnyEntry) {\n  const parent = parentEntrySlot.getValue();\n  if (parent) {\n    child.parents.add(parent);\n\n    if (! parent.childValues.has(child)) {\n      parent.childValues.set(child, []);\n    }\n\n    if (mightBeDirty(child)) {\n      reportDirtyChild(parent, child);\n    } else {\n      reportCleanChild(parent, child);\n    }\n\n    return parent;\n  }\n}\n\nfunction reallyRecompute(entry: AnyEntry, args: any[]) {\n  forgetChildren(entry);\n\n  // Set entry as the parent entry while calling recomputeNewValue(entry).\n  parentEntrySlot.withValue(entry, recomputeNewValue, [entry, args]);\n\n  if (maybeSubscribe(entry, args)) {\n    // If we successfully recomputed entry.value and did not fail to\n    // (re)subscribe, then this Entry is no longer explicitly dirty.\n    setClean(entry);\n  }\n\n  return valueGet(entry.value);\n}\n\nfunction recomputeNewValue(entry: AnyEntry, args: any[]) {\n  entry.recomputing = true;\n  // Set entry.value as unknown.\n  entry.value.length = 0;\n  try {\n    // If entry.fn succeeds, entry.value will become a normal Value.\n    entry.value[0] = entry.fn.apply(null, args);\n  } catch (e) {\n    // If entry.fn throws, entry.value will become exceptional.\n    entry.value[1] = e;\n  }\n  // Either way, this line is always reached.\n  entry.recomputing = false;\n}\n\nfunction mightBeDirty(entry: AnyEntry) {\n  return entry.dirty || !!(entry.dirtyChildren && entry.dirtyChildren.size);\n}\n\nfunction setClean(entry: AnyEntry) {\n  entry.dirty = false;\n\n  if (mightBeDirty(entry)) {\n    // This Entry may still have dirty children, in which case we can't\n    // let our parents know we're clean just yet.\n    return;\n  }\n\n  reportClean(entry);\n}\n\nfunction reportDirty(child: AnyEntry) {\n  eachParent(child, reportDirtyChild);\n}\n\nfunction reportClean(child: AnyEntry) {\n  eachParent(child, reportCleanChild);\n}\n\nfunction eachParent(\n  child: AnyEntry,\n  callback: (parent: AnyEntry, child: AnyEntry) => any,\n) {\n  const parentCount = child.parents.size;\n  if (parentCount) {\n    const parents = arrayFromSet(child.parents);\n    for (let i = 0; i < parentCount; ++i) {\n      callback(parents[i], child);\n    }\n  }\n}\n\n// Let a parent Entry know that one of its children may be dirty.\nfunction reportDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberParent(child) before calling\n  // reportDirtyChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(mightBeDirty(child));\n  const parentWasClean = !mightBeDirty(parent);\n\n  if (! parent.dirtyChildren) {\n    parent.dirtyChildren = emptySetPool.pop() || new Set;\n\n  } else if (parent.dirtyChildren.has(child)) {\n    // If we already know this child is dirty, then we must have already\n    // informed our own parents that we are dirty, so we can terminate\n    // the recursion early.\n    return;\n  }\n\n  parent.dirtyChildren.add(child);\n\n  // If parent was clean before, it just became (possibly) dirty (according to\n  // mightBeDirty), since we just added child to parent.dirtyChildren.\n  if (parentWasClean) {\n    reportDirty(parent);\n  }\n}\n\n// Let a parent Entry know that one of its children is no longer dirty.\nfunction reportCleanChild(parent: AnyEntry, child: AnyEntry) {\n  // Must have called rememberChild(child) before calling\n  // reportCleanChild(parent, child).\n  assert(parent.childValues.has(child));\n  assert(! mightBeDirty(child));\n\n  const childValue = parent.childValues.get(child)!;\n  if (childValue.length === 0) {\n    parent.childValues.set(child, valueCopy(child.value));\n  } else if (! valueIs(childValue, child.value)) {\n    parent.setDirty();\n  }\n\n  removeDirtyChild(parent, child);\n\n  if (mightBeDirty(parent)) {\n    return;\n  }\n\n  reportClean(parent);\n}\n\nfunction removeDirtyChild(parent: AnyEntry, child: AnyEntry) {\n  const dc = parent.dirtyChildren;\n  if (dc) {\n    dc.delete(child);\n    if (dc.size === 0) {\n      if (emptySetPool.length < POOL_TARGET_SIZE) {\n        emptySetPool.push(dc);\n      }\n      parent.dirtyChildren = null;\n    }\n  }\n}\n\n// Removes all children from this entry and returns an array of the\n// removed children.\nfunction forgetChildren(parent: AnyEntry) {\n  if (parent.childValues.size > 0) {\n    parent.childValues.forEach((_value, child) => {\n      forgetChild(parent, child);\n    });\n  }\n\n  // Remove this parent Entry from any sets to which it was added by the\n  // addToSet method.\n  parent.forgetDeps();\n\n  // After we forget all our children, this.dirtyChildren must be empty\n  // and therefore must have been reset to null.\n  assert(parent.dirtyChildren === null);\n}\n\nfunction forgetChild(parent: AnyEntry, child: AnyEntry) {\n  child.parents.delete(parent);\n  parent.childValues.delete(child);\n  removeDirtyChild(parent, child);\n}\n\nfunction maybeSubscribe(entry: AnyEntry, args: any[]) {\n  if (typeof entry.subscribe === \"function\") {\n    try {\n      maybeUnsubscribe(entry); // Prevent double subscriptions.\n      entry.unsubscribe = entry.subscribe.apply(null, args);\n    } catch (e) {\n      // If this Entry has a subscribe function and it threw an exception\n      // (or an unsubscribe function it previously returned now throws),\n      // return false to indicate that we were not able to subscribe (or\n      // unsubscribe), and this Entry should remain dirty.\n      entry.setDirty();\n      return false;\n    }\n  }\n\n  // Returning true indicates either that there was no entry.subscribe\n  // function or that it succeeded.\n  return true;\n}\n", "import { AnyEntry } from \"./entry.js\";\nimport { OptimisticWrapOptions } from \"./index.js\";\nimport { parentEntrySlot } from \"./context.js\";\nimport {\n  hasOwnProperty,\n  Unsubscribable,\n  maybeUnsubscribe,\n  arrayFromSet,\n } from \"./helpers.js\";\n\ntype EntryMethodName = keyof typeof EntryMethods;\nconst EntryMethods = {\n  setDirty: true, // Mark parent Entry as needing to be recomputed (default)\n  dispose: true,  // Detach parent Entry from parents and children, but leave in LRU cache\n  forget: true,   // Fully remove parent Entry from LRU cache and computation graph\n};\n\nexport type OptimisticDependencyFunction<TKey> =\n  ((key: TKey) => void) & {\n    dirty: (key: TKey, entryMethodName?: EntryMethodName) => void;\n  };\n\nexport type Dep<TKey> = Set<AnyEntry> & {\n  subscribe: OptimisticWrapOptions<[TKey]>[\"subscribe\"];\n} & Unsubscribable;\n\nexport function dep<TKey>(options?: {\n  subscribe: Dep<TKey>[\"subscribe\"];\n}) {\n  const depsByKey = new Map<TKey, Dep<TKey>>();\n  const subscribe = options && options.subscribe;\n\n  function depend(key: TKey) {\n    const parent = parentEntrySlot.getValue();\n    if (parent) {\n      let dep = depsByKey.get(key);\n      if (!dep) {\n        depsByKey.set(key, dep = new Set as Dep<TKey>);\n      }\n      parent.dependOn(dep);\n      if (typeof subscribe === \"function\") {\n        maybeUnsubscribe(dep);\n        dep.unsubscribe = subscribe(key);\n      }\n    }\n  }\n\n  depend.dirty = function dirty(\n    key: TKey,\n    entryMethodName?: EntryMethodName,\n  ) {\n    const dep = depsByKey.get(key);\n    if (dep) {\n      const m: EntryMethodName = (\n        entryMethodName &&\n        hasOwnProperty.call(EntryMethods, entryMethodName)\n      ) ? entryMethodName : \"setDirty\";\n      // We have to use arrayFromSet(dep).forEach instead of dep.forEach,\n      // because modifying a Set while iterating over it can cause elements in\n      // the Set to be removed from the Set before they've been iterated over.\n      arrayFromSet(dep).forEach(entry => entry[m]());\n      depsByKey.delete(key);\n      maybeUnsubscribe(dep);\n    }\n  };\n\n  return depend as OptimisticDependencyFunction<TKey>;\n}\n", "import { Trie } from \"@wry/trie\";\n\nimport { Cache } from \"./cache.js\";\nimport { Entry, AnyEntry } from \"./entry.js\";\nimport { parentEntrySlot } from \"./context.js\";\n\n// These helper functions are important for making optimism work with\n// asynchronous code. In order to register parent-child dependencies,\n// optimism needs to know about any currently active parent computations.\n// In ordinary synchronous code, the parent context is implicit in the\n// execution stack, but asynchronous code requires some extra guidance in\n// order to propagate context from one async task segment to the next.\nexport {\n  bindContext,\n  noContext,\n  nonReactive,\n  setTimeout,\n  asyncFromGen,\n} from \"./context.js\";\n\n// A lighter-weight dependency, similar to OptimisticWrapperFunction, except\n// with only one argument, no makeCacheKey, no wrapped function to recompute,\n// and no result value. Useful for representing dependency leaves in the graph\n// of computation. Subscriptions are supported.\nexport { dep, OptimisticDependencyFunction } from \"./dep.js\";\n\n// The defaultMakeCacheKey function is remarkably powerful, because it gives\n// a unique object for any shallow-identical list of arguments. If you need\n// to implement a custom makeCacheKey function, you may find it helpful to\n// delegate the final work to defaultMakeCacheKey, which is why we export it\n// here. However, you may want to avoid defaultMakeCacheKey if your runtime\n// does not support WeakMap, or you have the ability to return a string key.\n// In those cases, just write your own custom makeCacheKey functions.\nlet defaultKeyTrie: Trie<object> | undefined;\nexport function defaultMakeCacheKey(...args: any[]): object {\n  const trie = defaultKeyTrie || (\n    defaultKeyTrie = new Trie(typeof WeakMap === \"function\")\n  );\n  return trie.lookupArray(args);\n}\n\n// If you're paranoid about memory leaks, or you want to avoid using WeakMap\n// under the hood, but you still need the behavior of defaultMakeCacheKey,\n// import this constructor to create your own tries.\nexport { Trie as KeyTrie }\n\nexport type OptimisticWrapperFunction<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = ((...args: TArgs) => TResult) & {\n  // Get the current number of Entry objects in the LRU cache.\n  readonly size: number;\n\n  // Snapshot of wrap options used to create this wrapper function.\n  options: OptimisticWrapOptions<TArgs, TKeyArgs, TCacheKey>;\n\n  // \"Dirty\" any cached Entry stored for the given arguments, marking that Entry\n  // and its ancestors as potentially needing to be recomputed. The .dirty(...)\n  // method of an optimistic function takes the same parameter types as the\n  // original function by default, unless a keyArgs function is configured, and\n  // then it matters that .dirty takes TKeyArgs instead of TArgs.\n  dirty: (...args: TKeyArgs) => void;\n  // A version of .dirty that accepts a key returned by .getKey.\n  dirtyKey: (key: TCacheKey) => void;\n\n  // Examine the current value without recomputing it.\n  peek: (...args: TKeyArgs) => TResult | undefined;\n  // A version of .peek that accepts a key returned by .getKey.\n  peekKey: (key: TCacheKey) => TResult | undefined;\n\n  // Completely remove the entry from the cache, dirtying any parent entries.\n  forget: (...args: TKeyArgs) => boolean;\n  // A version of .forget that accepts a key returned by .getKey.\n  forgetKey: (key: TCacheKey) => boolean;\n\n  // In order to use the -Key version of the above functions, you need a key\n  // rather than the arguments used to compute the key. These two functions take\n  // TArgs or TKeyArgs and return the corresponding TCacheKey. If no keyArgs\n  // function has been configured, TArgs will be the same as TKeyArgs, and thus\n  // getKey and makeCacheKey will be synonymous.\n  getKey: (...args: TArgs) => TCacheKey;\n\n  // This property is equivalent to the makeCacheKey function provided in the\n  // OptimisticWrapOptions, or (if no options.makeCacheKey function is provided)\n  // a default implementation of makeCacheKey.\n  makeCacheKey: (...args: TKeyArgs) => TCacheKey;\n};\n\nexport type OptimisticWrapOptions<\n  TArgs extends any[],\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n> = {\n  // The maximum number of cache entries that should be retained before the\n  // cache begins evicting the oldest ones.\n  max?: number;\n  // Transform the raw arguments to some other type of array, which will then\n  // be passed to makeCacheKey.\n  keyArgs?: (...args: TArgs) => TKeyArgs;\n  // The makeCacheKey function takes the same arguments that were passed to\n  // the wrapper function and returns a single value that can be used as a key\n  // in a Map to identify the cached result.\n  makeCacheKey?: (...args: TKeyArgs) => TCacheKey;\n  // If provided, the subscribe function should either return an unsubscribe\n  // function or return nothing.\n  subscribe?: (...args: TArgs) => void | (() => any);\n};\n\nconst caches = new Set<Cache<any, AnyEntry>>();\n\nexport function wrap<\n  TArgs extends any[],\n  TResult,\n  TKeyArgs extends any[] = TArgs,\n  TCacheKey = any,\n>(originalFunction: (...args: TArgs) => TResult, {\n  max = Math.pow(2, 16),\n  makeCacheKey = defaultMakeCacheKey,\n  keyArgs,\n  subscribe,\n}: OptimisticWrapOptions<TArgs, TKeyArgs> = Object.create(null)) {\n  const cache = new Cache<TCacheKey, Entry<TArgs, TResult>>(\n    max,\n    entry => entry.dispose(),\n  );\n\n  const optimistic = function (): TResult {\n    const key = makeCacheKey.apply(\n      null,\n      keyArgs ? keyArgs.apply(null, arguments as any) : arguments as any\n    );\n\n    if (key === void 0) {\n      return originalFunction.apply(null, arguments as any);\n    }\n\n    let entry = cache.get(key)!;\n    if (!entry) {\n      cache.set(key, entry = new Entry(originalFunction));\n      entry.subscribe = subscribe;\n      // Give the Entry the ability to trigger cache.delete(key), even though\n      // the Entry itself does not know about key or cache.\n      entry.forget = () => cache.delete(key);\n    }\n\n    const value = entry.recompute(\n      Array.prototype.slice.call(arguments) as TArgs,\n    );\n\n    // Move this entry to the front of the least-recently used queue,\n    // since we just finished computing its value.\n    cache.set(key, entry);\n\n    caches.add(cache);\n\n    // Clean up any excess entries in the cache, but only if there is no\n    // active parent entry, meaning we're not in the middle of a larger\n    // computation that might be flummoxed by the cleaning.\n    if (! parentEntrySlot.hasValue()) {\n      caches.forEach(cache => cache.clean());\n      caches.clear();\n    }\n\n    return value;\n  } as OptimisticWrapperFunction<TArgs, TResult, TKeyArgs, TCacheKey>;\n\n  Object.defineProperty(optimistic, \"size\", {\n    get() {\n      return cache[\"map\"].size;\n    },\n    configurable: false,\n    enumerable: false,\n  });\n\n  Object.freeze(optimistic.options = {\n    max,\n    makeCacheKey,\n    keyArgs,\n    subscribe,\n  });\n\n  function dirtyKey(key: TCacheKey) {\n    const entry = cache.get(key);\n    if (entry) {\n      entry.setDirty();\n    }\n  }\n  optimistic.dirtyKey = dirtyKey;\n  optimistic.dirty = function dirty() {\n    dirtyKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function peekKey(key: TCacheKey) {\n    const entry = cache.get(key);\n    if (entry) {\n      return entry.peek();\n    }\n  }\n  optimistic.peekKey = peekKey;\n  optimistic.peek = function peek() {\n    return peekKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  function forgetKey(key: TCacheKey) {\n    return cache.delete(key);\n  }\n  optimistic.forgetKey = forgetKey;\n  optimistic.forget = function forget() {\n    return forgetKey(makeCacheKey.apply(null, arguments as any));\n  };\n\n  optimistic.makeCacheKey = makeCacheKey;\n  optimistic.getKey = keyArgs ? function getKey() {\n    return makeCacheKey.apply(null, keyArgs.apply(null, arguments as any));\n  } : makeCacheKey as (...args: any[]) => TCacheKey;\n\n  return Object.freeze(optimistic);\n}\n", "import type { DocumentNode } from 'graphql';\nimport { wrap } from 'optimism';\n\nimport type {\n  StoreObject,\n  Reference} from '../../utilities/index.js';\nimport {\n  getFragmentQueryDocument,\n} from '../../utilities/index.js';\nimport type { DataProxy } from './types/DataProxy.js';\nimport type { Cache } from './types/Cache.js';\n\nexport type Transaction<T> = (c: ApolloCache<T>) => void;\n\nexport abstract class ApolloCache<TSerialized> implements DataProxy {\n  public readonly assumeImmutableResults: boolean = false;\n\n  // required to implement\n  // core API\n  public abstract read<TData = any, TVariables = any>(\n    query: Cache.ReadOptions<TVariables, TData>,\n  ): TData | null;\n  public abstract write<TData = any, TVariables = any>(\n    write: Cache.WriteOptions<TData, TVariables>,\n  ): Reference | undefined;\n  public abstract diff<T>(query: Cache.DiffOptions): Cache.DiffResult<T>;\n  public abstract watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>,\n  ): () => void;\n\n  // Empty the cache and restart all current watches (unless\n  // options.discardWatches is true).\n  public abstract reset(options?: Cache.ResetOptions): Promise<void>;\n\n  // Remove whole objects from the cache by passing just options.id, or\n  // specific fields by passing options.field and/or options.args. If no\n  // options.args are provided, all fields matching options.field (even\n  // those with arguments) will be removed. Returns true iff any data was\n  // removed from the cache.\n  public abstract evict(options: Cache.EvictOptions): boolean;\n\n  // initializer / offline / ssr API\n  /**\n   * Replaces existing state in the cache (if any) with the values expressed by\n   * `serializedState`.\n   *\n   * Called when hydrating a cache (server side rendering, or offline storage),\n   * and also (potentially) during hot reloads.\n   */\n  public abstract restore(\n    serializedState: TSerialized,\n  ): ApolloCache<TSerialized>;\n\n  /**\n   * Exposes the cache's complete state, in a serializable format for later restoration.\n   */\n  public abstract extract(optimistic?: boolean): TSerialized;\n\n  // Optimistic API\n\n  public abstract removeOptimistic(id: string): void;\n\n  // Transactional API\n\n  // The batch method is intended to replace/subsume both performTransaction\n  // and recordOptimisticTransaction, but performTransaction came first, so we\n  // provide a default batch implementation that's just another way of calling\n  // performTransaction. Subclasses of ApolloCache (such as InMemoryCache) can\n  // override the batch method to do more interesting things with its options.\n  public batch<U>(options: Cache.BatchOptions<this, U>): U {\n    const optimisticId =\n      typeof options.optimistic === \"string\" ? options.optimistic :\n      options.optimistic === false ? null : void 0;\n    let updateResult: U;\n    this.performTransaction(\n      () => updateResult = options.update(this),\n      optimisticId,\n    );\n    return updateResult!;\n  }\n\n  public abstract performTransaction(\n    transaction: Transaction<TSerialized>,\n    // Although subclasses may implement recordOptimisticTransaction\n    // however they choose, the default implementation simply calls\n    // performTransaction with a string as the second argument, allowing\n    // performTransaction to handle both optimistic and non-optimistic\n    // (broadcast-batching) transactions. Passing null for optimisticId is\n    // also allowed, and indicates that performTransaction should apply\n    // the transaction non-optimistically (ignoring optimistic data).\n    optimisticId?: string | null,\n  ): void;\n\n  public recordOptimisticTransaction(\n    transaction: Transaction<TSerialized>,\n    optimisticId: string,\n  ) {\n    this.performTransaction(transaction, optimisticId);\n  }\n\n  // Optional API\n\n  // Called once per input document, allowing the cache to make static changes\n  // to the query, such as adding __typename fields.\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  // Called before each ApolloLink request, allowing the cache to make dynamic\n  // changes to the query, such as filling in missing fragment definitions.\n  public transformForLink(document: DocumentNode): DocumentNode {\n    return document;\n  }\n\n  public identify(object: StoreObject | Reference): string | undefined {\n    return;\n  }\n\n  public gc(): string[] {\n    return [];\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(options: Cache.ModifyOptions<Entity>): boolean {\n    return false;\n  }\n\n  // DataProxy API\n  /**\n   *\n   * @param options\n   * @param optimistic\n   */\n  public readQuery<QueryType, TVariables = any>(\n    options: Cache.ReadQueryOptions<QueryType, TVariables>,\n    optimistic = !!options.optimistic,\n  ): QueryType | null {\n    return this.read({\n      ...options,\n      rootId: options.id || 'ROOT_QUERY',\n      optimistic,\n    });\n  }\n\n  // Make sure we compute the same (===) fragment query document every\n  // time we receive the same fragment in readFragment.\n  private getFragmentDoc = wrap(getFragmentQueryDocument);\n\n  public readFragment<FragmentType, TVariables = any>(\n    options: Cache.ReadFragmentOptions<FragmentType, TVariables>,\n    optimistic = !!options.optimistic,\n  ): FragmentType | null {\n    return this.read({\n      ...options,\n      query: this.getFragmentDoc(options.fragment, options.fragmentName),\n      rootId: options.id,\n      optimistic,\n    });\n  }\n\n  public writeQuery<TData = any, TVariables = any>({\n    id,\n    data,\n    ...options\n  }: Cache.WriteQueryOptions<TData, TVariables>): Reference | undefined {\n    return this.write(Object.assign(options, {\n      dataId: id || 'ROOT_QUERY',\n      result: data,\n    }));\n  }\n\n  public writeFragment<TData = any, TVariables = any>({\n    id,\n    data,\n    fragment,\n    fragmentName,\n    ...options\n  }: Cache.WriteFragmentOptions<TData, TVariables>): Reference | undefined {\n    return this.write(Object.assign(options, {\n      query: this.getFragmentDoc(fragment, fragmentName),\n      dataId: id,\n      result: data,\n    }));\n  }\n\n  public updateQuery<TData = any, TVariables = any>(\n    options: Cache.UpdateQueryOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void,\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readQuery<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeQuery<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n\n  public updateFragment<TData = any, TVariables = any>(\n    options: Cache.UpdateFragmentOptions<TData, TVariables>,\n    update: (data: TData | null) => TData | null | void,\n  ): TData | null {\n    return this.batch({\n      update(cache) {\n        const value = cache.readFragment<TData, TVariables>(options);\n        const data = update(value);\n        if (data === void 0 || data === null) return value;\n        cache.writeFragment<TData, TVariables>({ ...options, data });\n        return data;\n      },\n    });\n  }\n}\n", "import { DataProxy } from './DataProxy.js';\nimport type { AllFieldsModifier, Modifiers } from './common.js';;\nimport type { ApolloCache } from '../cache.js';\n\nexport namespace Cache {\n  export type WatchCallback<TData = any> = (\n    diff: Cache.DiffResult<TData>,\n    lastDiff?: Cache.DiffResult<TData>,\n  ) => void;\n\n  export interface ReadOptions<TVariables = any, TData = any>\n    extends DataProxy.Query<TVariables, TData> {\n    rootId?: string;\n    previousResult?: any;\n    optimistic: boolean;\n    returnPartialData?: boolean;\n    canonizeResults?: boolean;\n  }\n\n  export interface WriteOptions<TResult = any, TVariables = any>\n    extends Omit<DataProxy.Query<TVariables, TResult>, \"id\">,\n            Omit<DataProxy.WriteOptions<TResult>, \"data\">\n  {\n    dataId?: string;\n    result: TResult;\n  }\n\n  export interface DiffOptions<\n    TData = any,\n    TVariables = any,\n  > extends Omit<ReadOptions<TVariables, TData>, \"rootId\"> {\n    // The DiffOptions interface is currently just an alias for\n    // ReadOptions, though DiffOptions used to be responsible for\n    // declaring the returnPartialData option.\n  }\n\n  export interface WatchOptions<\n    TData = any,\n    TVariables = any,\n  > extends DiffOptions<TData, TVariables> {\n    watcher?: object;\n    immediate?: boolean;\n    callback: WatchCallback<TData>;\n    lastDiff?: DiffResult<TData>;\n  }\n\n  export interface EvictOptions {\n    id?: string;\n    fieldName?: string;\n    args?: Record<string, any>;\n    broadcast?: boolean;\n  }\n\n  // Although you can call cache.reset() without options, its behavior can be\n  // configured by passing a Cache.ResetOptions object.\n  export interface ResetOptions {\n    discardWatches?: boolean;\n  }\n\n  export interface ModifyOptions<Entity extends Record<string, any> = Record<string, any>> {\n    id?: string;\n    fields: Modifiers<Entity> | AllFieldsModifier<Entity>;\n    optimistic?: boolean;\n    broadcast?: boolean;\n  }\n\n  export interface BatchOptions<\n    TCache extends ApolloCache<any>,\n    TUpdateResult = void,\n  > {\n    // Same as the first parameter of performTransaction, except the cache\n    // argument will have the subclass type rather than ApolloCache.\n    update(cache: TCache): TUpdateResult;\n\n    // Passing a string for this option creates a new optimistic layer, with the\n    // given string as its layer.id, just like passing a string for the\n    // optimisticId parameter of performTransaction. Passing true is the same as\n    // passing undefined to performTransaction (running the batch operation\n    // against the current top layer of the cache), and passing false is the\n    // same as passing null (running the operation against root/non-optimistic\n    // cache data).\n    optimistic?: string | boolean;\n\n    // If you specify the ID of an optimistic layer using this option, that\n    // layer will be removed as part of the batch transaction, triggering at\n    // most one broadcast for both the transaction and the removal of the layer.\n    // Note: this option is needed because calling cache.removeOptimistic during\n    // the transaction function may not be not safe, since any modifications to\n    // cache layers may be discarded after the transaction finishes.\n    removeOptimistic?: string;\n\n    // If you want to find out which watched queries were invalidated during\n    // this batch operation, pass this optional callback function. Returning\n    // false from the callback will prevent broadcasting this result.\n    onWatchUpdated?: (\n      this: TCache,\n      watch: Cache.WatchOptions,\n      diff: Cache.DiffResult<any>,\n      lastDiff: Cache.DiffResult<any> | undefined,\n    ) => any;\n  }\n\n  export import DiffResult = DataProxy.DiffResult;\n  export import ReadQueryOptions = DataProxy.ReadQueryOptions;\n  export import ReadFragmentOptions = DataProxy.ReadFragmentOptions;\n  export import WriteQueryOptions = DataProxy.WriteQueryOptions;\n  export import WriteFragmentOptions = DataProxy.WriteFragmentOptions;\n  export import UpdateQueryOptions = DataProxy.UpdateQueryOptions;\n  export import UpdateFragmentOptions = DataProxy.UpdateFragmentOptions;\n  export import Fragment = DataProxy.Fragment;\n}\n", "import type { DocumentNode, FieldNode } from 'graphql';\n\nimport type {\n  Reference,\n  StoreObject,\n  StoreValue,\n  isReference,\n} from '../../../utilities/index.js';\n\nimport type { StorageType } from '../../inmemory/policies.js';\n\n// The Readonly<T> type only really works for object types, since it marks\n// all of the object's properties as readonly, but there are many cases when\n// a generic type parameter like TExisting might be a string or some other\n// primitive type, in which case we need to avoid wrapping it with Readonly.\n// SafeReadonly<string> collapses to just string, which makes string\n// assignable to SafeReadonly<any>, whereas string is not assignable to\n// Readonly<any>, somewhat surprisingly.\nexport type SafeReadonly<T> = T extends object ? Readonly<T> : T;\n\nexport type MissingTree = string | {\n  readonly [key: string]: MissingTree;\n};\n\nexport class MissingFieldError extends Error {\n  constructor(\n    public readonly message: string,\n    public readonly path: MissingTree | Array<string | number>,\n    public readonly query: DocumentNode,\n    public readonly variables?: Record<string, any>,\n  ) {\n    // 'Error' breaks prototype chain here\n    super(message);\n\n    if (Array.isArray(this.path)) {\n      this.missing = this.message;\n      for (let i = this.path.length - 1; i >= 0; --i) {\n        this.missing = { [this.path[i]]: this.missing };\n      }\n    } else {\n      this.missing = this.path;\n    }\n\n    // We're not using `Object.setPrototypeOf` here as it isn't fully supported\n    // on Android (see issue #3236).\n    (this as any).__proto__ = MissingFieldError.prototype;\n  }\n\n  public readonly missing: MissingTree;\n}\n\nexport interface FieldSpecifier {\n  typename?: string;\n  fieldName: string;\n  field?: FieldNode;\n  args?: Record<string, any>;\n  variables?: Record<string, any>;\n}\n\nexport interface ReadFieldOptions extends FieldSpecifier {\n  from?: StoreObject | Reference;\n}\n\nexport interface ReadFieldFunction {\n  <V = StoreValue>(options: ReadFieldOptions): SafeReadonly<V> | undefined;\n  <V = StoreValue>(\n    fieldName: string,\n    from?: StoreObject | Reference,\n  ): SafeReadonly<V> | undefined;\n}\n\nexport type ToReferenceFunction = (\n  objOrIdOrRef: StoreObject | string | Reference,\n  mergeIntoStore?: boolean,\n) => Reference | undefined;\n\nexport type CanReadFunction = (value: StoreValue) => boolean;\n\ndeclare const _deleteModifier: unique symbol;\nexport interface DeleteModifier { [_deleteModifier]: true }\ndeclare const _invalidateModifier: unique symbol;\nexport interface InvalidateModifier { [_invalidateModifier]: true}\n\nexport type ModifierDetails = {\n  DELETE: DeleteModifier;\n  INVALIDATE: InvalidateModifier;\n  fieldName: string;\n  storeFieldName: string;\n  readField: ReadFieldFunction;\n  canRead: CanReadFunction;\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n  storage: StorageType;\n}\n\nexport type Modifier<T> = (\n  value: T,\n  details: ModifierDetails\n) => T | DeleteModifier | InvalidateModifier;\n\ntype StoreObjectValueMaybeReference<StoreVal> =\n  StoreVal extends Record<string, any>[]\n  ? Readonly<StoreVal> | readonly Reference[]\n  : StoreVal extends Record<string, any>\n  ? StoreVal | Reference\n  : StoreVal;\n\nexport type AllFieldsModifier<\n  Entity extends Record<string, any>\n> = Modifier<Entity[keyof Entity] extends infer Value ?\n  StoreObjectValueMaybeReference<Exclude<Value, undefined>>\n  : never>;\n\nexport type Modifiers<\n  T extends Record<string, any> = Record<string, unknown>\n> = Partial<{\n  [FieldName in keyof T]: Modifier<\n    StoreObjectValueMaybeReference<Exclude<T[FieldName], undefined>>\n  >;\n}>;\n", "const { toString, hasOwnProperty } = Object.prototype;\nconst fnToStr = Function.prototype.toString;\nconst previousComparisons = new Map<object, Set<object>>();\n\n/**\n * Performs a deep equality check on two JavaScript values, tolerating cycles.\n */\nexport function equal(a: any, b: any): boolean {\n  try {\n    return check(a, b);\n  } finally {\n    previousComparisons.clear();\n  }\n}\n\n// Allow default imports as well.\nexport default equal;\n\nfunction check(a: any, b: any): boolean {\n  // If the two values are strictly equal, our job is easy.\n  if (a === b) {\n    return true;\n  }\n\n  // Object.prototype.toString returns a representation of the runtime type of\n  // the given value that is considerably more precise than typeof.\n  const aTag = toString.call(a);\n  const bTag = toString.call(b);\n\n  // If the runtime types of a and b are different, they could maybe be equal\n  // under some interpretation of equality, but for simplicity and performance\n  // we just return false instead.\n  if (aTag !== bTag) {\n    return false;\n  }\n\n  switch (aTag) {\n    case '[object Array]':\n      // Arrays are a lot like other objects, but we can cheaply compare their\n      // lengths as a short-cut before comparing their elements.\n      if (a.length !== b.length) return false;\n      // Fall through to object case...\n    case '[object Object]': {\n      if (previouslyCompared(a, b)) return true;\n\n      const aKeys = definedKeys(a);\n      const bKeys = definedKeys(b);\n\n      // If `a` and `b` have a different number of enumerable keys, they\n      // must be different.\n      const keyCount = aKeys.length;\n      if (keyCount !== bKeys.length) return false;\n\n      // Now make sure they have the same keys.\n      for (let k = 0; k < keyCount; ++k) {\n        if (!hasOwnProperty.call(b, aKeys[k])) {\n          return false;\n        }\n      }\n\n      // Finally, check deep equality of all child properties.\n      for (let k = 0; k < keyCount; ++k) {\n        const key = aKeys[k];\n        if (!check(a[key], b[key])) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Error]':\n      return a.name === b.name && a.message === b.message;\n\n    case '[object Number]':\n      // Handle NaN, which is !== itself.\n      if (a !== a) return b !== b;\n      // Fall through to shared +a === +b case...\n    case '[object Boolean]':\n    case '[object Date]':\n      return +a === +b;\n\n    case '[object RegExp]':\n    case '[object String]':\n      return a == `${b}`;\n\n    case '[object Map]':\n    case '[object Set]': {\n      if (a.size !== b.size) return false;\n      if (previouslyCompared(a, b)) return true;\n\n      const aIterator = a.entries();\n      const isMap = aTag === '[object Map]';\n\n      while (true) {\n        const info = aIterator.next();\n        if (info.done) break;\n\n        // If a instanceof Set, aValue === aKey.\n        const [aKey, aValue] = info.value;\n\n        // So this works the same way for both Set and Map.\n        if (!b.has(aKey)) {\n          return false;\n        }\n\n        // However, we care about deep equality of values only when dealing\n        // with Map structures.\n        if (isMap && !check(aValue, b.get(aKey))) {\n          return false;\n        }\n      }\n\n      return true;\n    }\n\n    case '[object Uint16Array]':\n    case '[object Uint8Array]': // Buffer, in Node.js.\n    case '[object Uint32Array]':\n    case '[object Int32Array]':\n    case '[object Int8Array]':\n    case '[object Int16Array]':\n    case '[object ArrayBuffer]':\n      // DataView doesn't need these conversions, but the equality check is\n      // otherwise the same.\n      a = new Uint8Array(a);\n      b = new Uint8Array(b);\n      // Fall through...\n    case '[object DataView]': {\n      let len = a.byteLength;\n      if (len === b.byteLength) {\n        while (len-- && a[len] === b[len]) {\n          // Keep looping as long as the bytes are equal.\n        }\n      }\n      return len === -1;\n    }\n\n    case '[object AsyncFunction]':\n    case '[object GeneratorFunction]':\n    case '[object AsyncGeneratorFunction]':\n    case '[object Function]': {\n      const aCode = fnToStr.call(a);\n      if (aCode !== fnToStr.call(b)) {\n        return false;\n      }\n\n      // We consider non-native functions equal if they have the same code\n      // (native functions require === because their code is censored).\n      // Note that this behavior is not entirely sound, since !== function\n      // objects with the same code can behave differently depending on\n      // their closure scope. However, any function can behave differently\n      // depending on the values of its input arguments (including this)\n      // and its calling context (including its closure scope), even\n      // though the function object is === to itself; and it is entirely\n      // possible for functions that are not === to behave exactly the\n      // same under all conceivable circumstances. Because none of these\n      // factors are statically decidable in JavaScript, JS function\n      // equality is not well-defined. This ambiguity allows us to\n      // consider the best possible heuristic among various imperfect\n      // options, and equating non-native functions that have the same\n      // code has enormous practical benefits, such as when comparing\n      // functions that are repeatedly passed as fresh function\n      // expressions within objects that are otherwise deeply equal. Since\n      // any function created from the same syntactic expression (in the\n      // same code location) will always stringify to the same code\n      // according to fnToStr.call, we can reasonably expect these\n      // repeatedly passed function expressions to have the same code, and\n      // thus behave \"the same\" (with all the caveats mentioned above),\n      // even though the runtime function objects are !== to one another.\n      return !endsWith(aCode, nativeCodeSuffix);\n    }\n  }\n\n  // Otherwise the values are not equal.\n  return false;\n}\n\nfunction definedKeys<TObject extends object>(obj: TObject) {\n  // Remember that the second argument to Array.prototype.filter will be\n  // used as `this` within the callback function.\n  return Object.keys(obj).filter(isDefinedKey, obj);\n}\nfunction isDefinedKey<TObject extends object>(\n  this: TObject,\n  key: keyof TObject,\n) {\n  return this[key] !== void 0;\n}\n\nconst nativeCodeSuffix = \"{ [native code] }\";\n\nfunction endsWith(full: string, suffix: string) {\n  const fromIndex = full.length - suffix.length;\n  return fromIndex >= 0 &&\n    full.indexOf(suffix, fromIndex) === fromIndex;\n}\n\nfunction previouslyCompared(a: object, b: object): boolean {\n  // Though cyclic references can make an object graph appear infinite from the\n  // perspective of a depth-first traversal, the graph still contains a finite\n  // number of distinct object references. We use the previousComparisons cache\n  // to avoid comparing the same pair of object references more than once, which\n  // guarantees termination (even if we end up comparing every object in one\n  // graph to every object in the other graph, which is extremely unlikely),\n  // while still allowing weird isomorphic structures (like rings with different\n  // lengths) a chance to pass the equality test.\n  let bSet = previousComparisons.get(a);\n  if (bSet) {\n    // Return true here because we can be sure false will be returned somewhere\n    // else if the objects are not equivalent.\n    if (bSet.has(b)) return true;\n  } else {\n    previousComparisons.set(a, bSet = new Set);\n  }\n  bSet.add(b);\n  return false;\n}\n", "import type { DocumentNode, FragmentDefinitionNode, SelectionSetNode } from 'graphql';\n\nimport type {\n  NormalizedCache,\n  InMemoryCacheConfig,\n} from './types.js';\n\nimport type { KeyFieldsContext } from './policies.js';\nimport type { FragmentRegistryAPI } from './fragmentRegistry.js';\n\nimport type {\n  Reference,\n  StoreValue,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction} from '../../utilities/index.js';\nimport {\n  isReference,\n  isField,\n  DeepMerger,\n  resultKeyNameFromField,\n  shouldInclude,\n  isNonNullObject,\n  compact,\n  createFragmentMap,\n  getFragmentDefinitions,\n  isArray,\n} from '../../utilities/index.js';\n\nexport const {\n  hasOwnProperty: hasOwn,\n} = Object.prototype;\n\nexport function isNullish(value: any): value is null | undefined {\n  return value === null || value === void 0;\n}\n\nexport { isArray };\n\nexport function defaultDataIdFromObject(\n  { __typename, id, _id }: Readonly<StoreObject>,\n  context?: KeyFieldsContext,\n): string | undefined {\n  if (typeof __typename === \"string\") {\n    if (context) {\n      context.keyObject =\n        !isNullish(id) ? { id } :\n        !isNullish(_id) ? { _id } :\n        void 0;\n    }\n\n    // If there is no object.id, fall back to object._id.\n    if (isNullish(id) && !isNullish(_id)) {\n      id = _id;\n    }\n\n    if (!isNullish(id)) {\n      return `${__typename}:${(\n        typeof id === \"number\" ||\n        typeof id === \"string\"\n      ) ? id : JSON.stringify(id)}`;\n    }\n  }\n}\n\nconst defaultConfig = {\n  dataIdFromObject: defaultDataIdFromObject,\n  addTypename: true,\n  resultCaching: true,\n  // Thanks to the shouldCanonizeResults helper, this should be the only line\n  // you have to change to reenable canonization by default in the future.\n  canonizeResults: false,\n};\n\nexport function normalizeConfig(config: InMemoryCacheConfig) {\n  return compact(defaultConfig, config);\n}\n\nexport function shouldCanonizeResults(\n  config: Pick<InMemoryCacheConfig, \"canonizeResults\">,\n): boolean {\n  const value = config.canonizeResults;\n  return value === void 0 ? defaultConfig.canonizeResults : value;\n}\n\nexport function getTypenameFromStoreObject(\n  store: NormalizedCache,\n  objectOrReference: StoreObject | Reference,\n): string | undefined {\n  return isReference(objectOrReference)\n    ? store.get(objectOrReference.__ref, \"__typename\") as string\n    : objectOrReference && objectOrReference.__typename;\n}\n\nexport const TypeOrFieldNameRegExp = /^[_a-z][_0-9a-z]*/i;\n\nexport function fieldNameFromStoreName(storeFieldName: string): string {\n  const match = storeFieldName.match(TypeOrFieldNameRegExp);\n  return match ? match[0] : storeFieldName;\n}\n\nexport function selectionSetMatchesResult(\n  selectionSet: SelectionSetNode,\n  result: Record<string, any>,\n  variables?: Record<string, any>,\n): boolean {\n  if (isNonNullObject(result)) {\n    return isArray(result)\n      ? result.every(item => selectionSetMatchesResult(selectionSet, item, variables))\n      : selectionSet.selections.every(field => {\n        if (isField(field) && shouldInclude(field, variables)) {\n          const key = resultKeyNameFromField(field);\n          return hasOwn.call(result, key) &&\n            (!field.selectionSet ||\n             selectionSetMatchesResult(field.selectionSet, result[key], variables));\n        }\n        // If the selection has been skipped with @skip(true) or\n        // @include(false), it should not count against the matching. If\n        // the selection is not a field, it must be a fragment (inline or\n        // named). We will determine if selectionSetMatchesResult for that\n        // fragment when we get to it, so for now we return true.\n        return true;\n      });\n  }\n  return false;\n}\n\nexport function storeValueIsStoreObject(\n  value: StoreValue,\n): value is StoreObject {\n  return isNonNullObject(value) &&\n    !isReference(value) &&\n    !isArray(value);\n}\n\nexport function makeProcessedFieldsMerger() {\n  return new DeepMerger;\n}\n\nexport function extractFragmentContext(\n  document: DocumentNode,\n  fragments?: FragmentRegistryAPI,\n): {\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n} {\n  // FragmentMap consisting only of fragments defined directly in document, not\n  // including other fragments registered in the FragmentRegistry.\n  const fragmentMap = createFragmentMap(getFragmentDefinitions(document));\n  return {\n    fragmentMap,\n    lookupFragment(name) {\n      let def: FragmentDefinitionNode | null = fragmentMap[name];\n      if (!def && fragments) {\n        def = fragments.lookup(name);\n      }\n      return def || null;\n    },\n  };\n}\n", "import { invariant } from '../../utilities/globals/index.js';\nimport type { OptimisticDependencyFunction } from 'optimism';\nimport { dep } from 'optimism';\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\n\nimport type {\n  StoreValue,\n  StoreObject,\n  Reference} from '../../utilities/index.js';\nimport {\n  isReference,\n  makeReference,\n  DeepMerger,\n  maybeDeepFreeze,\n  canUseWeakMap,\n  isNonNullObject,\n} from '../../utilities/index.js';\nimport type { NormalizedCache, NormalizedCacheObject } from './types.js';\nimport { hasOwn, fieldNameFromStoreName } from './helpers.js';\nimport type { Policies, StorageType } from './policies.js';\nimport type { Cache } from '../core/types/Cache.js';\nimport type {\n  SafeReadonly,\n  Modifier,\n  Modifiers,\n  ReadFieldOptions,\n  ToReferenceFunction,\n  CanReadFunction,\n  InvalidateModifier,\n  DeleteModifier,\n  ModifierDetails,\n} from '../core/types/common.js';\n\nconst DELETE: DeleteModifier = Object.create(null);\nconst delModifier: Modifier<any> = () => DELETE;\nconst INVALIDATE: InvalidateModifier = Object.create(null);\n\nexport abstract class EntityStore implements NormalizedCache {\n  protected data: NormalizedCacheObject = Object.create(null);\n\n  constructor(\n    public readonly policies: Policies,\n    public readonly group: CacheGroup,\n  ) {}\n\n  public abstract addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any,\n  ): Layer;\n\n  public abstract removeLayer(layerId: string): EntityStore;\n\n  // Although the EntityStore class is abstract, it contains concrete\n  // implementations of the various NormalizedCache interface methods that\n  // are inherited by the Root and Layer subclasses.\n\n  public toObject(): NormalizedCacheObject {\n    return { ...this.data };\n  }\n\n  public has(dataId: string): boolean {\n    return this.lookup(dataId, true) !== void 0;\n  }\n\n  public get(dataId: string, fieldName: string): StoreValue {\n    this.group.depend(dataId, fieldName);\n    if (hasOwn.call(this.data, dataId)) {\n      const storeObject = this.data[dataId];\n      if (storeObject && hasOwn.call(storeObject, fieldName)) {\n        return storeObject[fieldName];\n      }\n    }\n    if (fieldName === \"__typename\" &&\n        hasOwn.call(this.policies.rootTypenamesById, dataId)) {\n      return this.policies.rootTypenamesById[dataId];\n    }\n    if (this instanceof Layer) {\n      return this.parent.get(dataId, fieldName);\n    }\n  }\n\n  protected lookup(dataId: string, dependOnExistence?: boolean): StoreObject | undefined {\n    // The has method (above) calls lookup with dependOnExistence = true, so\n    // that it can later be invalidated when we add or remove a StoreObject for\n    // this dataId. Any consumer who cares about the contents of the StoreObject\n    // should not rely on this dependency, since the contents could change\n    // without the object being added or removed.\n    if (dependOnExistence) this.group.depend(dataId, \"__exists\");\n\n    if (hasOwn.call(this.data, dataId)) {\n      return this.data[dataId];\n    }\n\n    if (this instanceof Layer) {\n      return this.parent.lookup(dataId, dependOnExistence);\n    }\n\n    if (this.policies.rootTypenamesById[dataId]) {\n      return Object.create(null);\n    }\n  }\n\n  public merge(\n    older: string | StoreObject,\n    newer: StoreObject | string,\n  ): void {\n    let dataId: string | undefined;\n\n    // Convert unexpected references to ID strings.\n    if (isReference(older)) older = older.__ref;\n    if (isReference(newer)) newer = newer.__ref;\n\n    const existing: StoreObject | undefined =\n      typeof older === \"string\"\n        ? this.lookup(dataId = older)\n        : older;\n\n    const incoming: StoreObject | undefined =\n      typeof newer === \"string\"\n        ? this.lookup(dataId = newer)\n        : newer;\n\n    // If newer was a string ID, but that ID was not defined in this store,\n    // then there are no fields to be merged, so we're done.\n    if (!incoming) return;\n\n    invariant(\n      typeof dataId === \"string\",\n      \"store.merge expects a string ID\",\n    );\n\n    const merged: StoreObject =\n      new DeepMerger(storeObjectReconciler).merge(existing, incoming);\n\n    // Even if merged === existing, existing may have come from a lower\n    // layer, so we always need to set this.data[dataId] on this level.\n    this.data[dataId] = merged;\n\n    if (merged !== existing) {\n      delete this.refs[dataId];\n      if (this.group.caching) {\n        const fieldsToDirty: Record<string, 1> = Object.create(null);\n\n        // If we added a new StoreObject where there was previously none, dirty\n        // anything that depended on the existence of this dataId, such as the\n        // EntityStore#has method.\n        if (!existing) fieldsToDirty.__exists = 1;\n\n        // Now invalidate dependents who called getFieldValue for any fields\n        // that are changing as a result of this merge.\n        Object.keys(incoming).forEach(storeFieldName => {\n          if (!existing || existing[storeFieldName] !== merged[storeFieldName]) {\n            // Always dirty the full storeFieldName, which may include\n            // serialized arguments following the fieldName prefix.\n            fieldsToDirty[storeFieldName] = 1;\n\n            // Also dirty fieldNameFromStoreName(storeFieldName) if it's\n            // different from storeFieldName and this field does not have\n            // keyArgs configured, because that means the cache can't make\n            // any assumptions about how field values with the same field\n            // name but different arguments might be interrelated, so it\n            // must err on the side of invalidating all field values that\n            // share the same short fieldName, regardless of arguments.\n            const fieldName = fieldNameFromStoreName(storeFieldName);\n            if (fieldName !== storeFieldName &&\n                !this.policies.hasKeyArgs(merged.__typename, fieldName)) {\n              fieldsToDirty[fieldName] = 1;\n            }\n\n            // If merged[storeFieldName] has become undefined, and this is the\n            // Root layer, actually delete the property from the merged object,\n            // which is guaranteed to have been created fresh in this method.\n            if (merged[storeFieldName] === void 0 && !(this instanceof Layer)) {\n              delete merged[storeFieldName];\n            }\n          }\n        });\n\n        if (fieldsToDirty.__typename &&\n            !(existing && existing.__typename) &&\n            // Since we return default root __typename strings\n            // automatically from store.get, we don't need to dirty the\n            // ROOT_QUERY.__typename field if merged.__typename is equal\n            // to the default string (usually \"Query\").\n            this.policies.rootTypenamesById[dataId] === merged.__typename) {\n          delete fieldsToDirty.__typename;\n        }\n\n        Object.keys(fieldsToDirty).forEach(\n          fieldName => this.group.dirty(dataId as string, fieldName));\n      }\n    }\n  }\n\n  public modify(\n    dataId: string,\n    fields: Modifier<any> | Modifiers<Record<string, any>>,\n  ): boolean {\n    const storeObject = this.lookup(dataId);\n\n    if (storeObject) {\n      const changedFields: Record<string, any> = Object.create(null);\n      let needToMerge = false;\n      let allDeleted = true;\n\n      const sharedDetails = {\n        DELETE,\n        INVALIDATE,\n        isReference,\n        toReference: this.toReference,\n        canRead: this.canRead,\n        readField: <V = StoreValue>(\n          fieldNameOrOptions: string | ReadFieldOptions,\n          from?: StoreObject | Reference,\n        ) => this.policies.readField<V>(\n          typeof fieldNameOrOptions === \"string\" ? {\n            fieldName: fieldNameOrOptions,\n            from: from || makeReference(dataId),\n          } : fieldNameOrOptions,\n          { store: this },\n        ),\n      } satisfies Partial<ModifierDetails>;\n\n      Object.keys(storeObject).forEach(storeFieldName => {\n        const fieldName = fieldNameFromStoreName(storeFieldName);\n        let fieldValue = storeObject[storeFieldName];\n        if (fieldValue === void 0) return;\n        const modify: Modifier<StoreValue> | undefined = typeof fields === \"function\"\n          ? fields\n          : fields[storeFieldName] || fields[fieldName];\n        if (modify) {\n          let newValue = modify === delModifier ? DELETE :\n            modify(maybeDeepFreeze(fieldValue), {\n              ...sharedDetails,\n              fieldName,\n              storeFieldName,\n              storage: this.getStorage(dataId, storeFieldName),\n            });\n          if (newValue === INVALIDATE) {\n            this.group.dirty(dataId, storeFieldName);\n          } else {\n            if (newValue === DELETE) newValue = void 0;\n            if (newValue !== fieldValue) {\n              changedFields[storeFieldName] = newValue;\n              needToMerge = true;\n              fieldValue = newValue;\n            }\n          }\n        }\n        if (fieldValue !== void 0) {\n          allDeleted = false;\n        }\n      });\n\n      if (needToMerge) {\n        this.merge(dataId, changedFields);\n\n        if (allDeleted) {\n          if (this instanceof Layer) {\n            this.data[dataId] = void 0;\n          } else {\n            delete this.data[dataId];\n          }\n          this.group.dirty(dataId, \"__exists\");\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  }\n\n  // If called with only one argument, removes the entire entity\n  // identified by dataId. If called with a fieldName as well, removes all\n  // fields of that entity whose names match fieldName according to the\n  // fieldNameFromStoreName helper function. If called with a fieldName\n  // and variables, removes all fields of that entity whose names match fieldName\n  // and whose arguments when cached exactly match the variables passed.\n  public delete(\n    dataId: string,\n    fieldName?: string,\n    args?: Record<string, any>,\n  ) {\n    const storeObject = this.lookup(dataId);\n    if (storeObject) {\n      const typename = this.getFieldValue<string>(storeObject, \"__typename\");\n      const storeFieldName = fieldName && args\n        ? this.policies.getStoreFieldName({ typename, fieldName, args })\n        : fieldName;\n      return this.modify(dataId, storeFieldName ? {\n        [storeFieldName]: delModifier,\n      } : delModifier);\n    }\n    return false;\n  }\n\n  public evict(\n    options: Cache.EvictOptions,\n    limit: EntityStore,\n  ): boolean {\n    let evicted = false;\n    if (options.id) {\n      if (hasOwn.call(this.data, options.id)) {\n        evicted = this.delete(options.id, options.fieldName, options.args);\n      }\n      if (this instanceof Layer && this !== limit) {\n        evicted = this.parent.evict(options, limit) || evicted;\n      }\n      // Always invalidate the field to trigger rereading of watched\n      // queries, even if no cache data was modified by the eviction,\n      // because queries may depend on computed fields with custom read\n      // functions, whose values are not stored in the EntityStore.\n      if (options.fieldName || evicted) {\n        this.group.dirty(options.id, options.fieldName || \"__exists\");\n      }\n    }\n    return evicted;\n  }\n\n  public clear(): void {\n    this.replace(null);\n  }\n\n  public extract(): NormalizedCacheObject {\n    const obj = this.toObject();\n    const extraRootIds: string[] = [];\n    this.getRootIdSet().forEach(id => {\n      if (!hasOwn.call(this.policies.rootTypenamesById, id)) {\n        extraRootIds.push(id);\n      }\n    });\n    if (extraRootIds.length) {\n      obj.__META = { extraRootIds: extraRootIds.sort() };\n    }\n    return obj;\n  }\n\n  public replace(newData: NormalizedCacheObject | null): void {\n    Object.keys(this.data).forEach(dataId => {\n      if (!(newData && hasOwn.call(newData, dataId))) {\n        this.delete(dataId);\n      }\n    });\n    if (newData) {\n      const { __META, ...rest } = newData;\n      Object.keys(rest).forEach(dataId => {\n        this.merge(dataId, rest[dataId] as StoreObject);\n      });\n      if (__META) {\n        __META.extraRootIds.forEach(this.retain, this);\n      }\n    }\n  }\n\n  public abstract getStorage(\n    idOrObj: string | StoreObject,\n    ...storeFieldNames: (string | number)[]\n  ): StorageType;\n\n  // Maps root entity IDs to the number of times they have been retained, minus\n  // the number of times they have been released. Retained entities keep other\n  // entities they reference (even indirectly) from being garbage collected.\n  private rootIds: {\n    [rootId: string]: number;\n  } = Object.create(null);\n\n  public retain(rootId: string): number {\n    return this.rootIds[rootId] = (this.rootIds[rootId] || 0) + 1;\n  }\n\n  public release(rootId: string): number {\n    if (this.rootIds[rootId] > 0) {\n      const count = --this.rootIds[rootId];\n      if (!count) delete this.rootIds[rootId];\n      return count;\n    }\n    return 0;\n  }\n\n  // Return a Set<string> of all the ID strings that have been retained by\n  // this layer/root *and* any layers/roots beneath it.\n  public getRootIdSet(ids = new Set<string>()) {\n    Object.keys(this.rootIds).forEach(ids.add, ids);\n    if (this instanceof Layer) {\n      this.parent.getRootIdSet(ids);\n    } else {\n      // Official singleton IDs like ROOT_QUERY and ROOT_MUTATION are\n      // always considered roots for garbage collection, regardless of\n      // their retainment counts in this.rootIds.\n      Object.keys(this.policies.rootTypenamesById).forEach(ids.add, ids);\n    }\n    return ids;\n  }\n\n  // The goal of garbage collection is to remove IDs from the Root layer of the\n  // store that are no longer reachable starting from any IDs that have been\n  // explicitly retained (see retain and release, above). Returns an array of\n  // dataId strings that were removed from the store.\n  public gc() {\n    const ids = this.getRootIdSet();\n    const snapshot = this.toObject();\n    ids.forEach(id => {\n      if (hasOwn.call(snapshot, id)) {\n        // Because we are iterating over an ECMAScript Set, the IDs we add here\n        // will be visited in later iterations of the forEach loop only if they\n        // were not previously contained by the Set.\n        Object.keys(this.findChildRefIds(id)).forEach(ids.add, ids);\n        // By removing IDs from the snapshot object here, we protect them from\n        // getting removed from the root store layer below.\n        delete snapshot[id];\n      }\n    });\n    const idsToRemove = Object.keys(snapshot);\n    if (idsToRemove.length) {\n      let root: EntityStore = this;\n      while (root instanceof Layer) root = root.parent;\n      idsToRemove.forEach(id => root.delete(id));\n    }\n    return idsToRemove;\n  }\n\n  // Lazily tracks { __ref: <dataId> } strings contained by this.data[dataId].\n  private refs: {\n    [dataId: string]: Record<string, true>;\n  } = Object.create(null);\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    if (!hasOwn.call(this.refs, dataId)) {\n      const found = this.refs[dataId] = Object.create(null);\n      const root = this.data[dataId];\n      if (!root) return found;\n\n      const workSet = new Set<Record<string | number, any>>([root]);\n      // Within the store, only arrays and objects can contain child entity\n      // references, so we can prune the traversal using this predicate:\n      workSet.forEach(obj => {\n        if (isReference(obj)) {\n          found[obj.__ref] = true;\n          // In rare cases, a { __ref } Reference object may have other fields.\n          // This often indicates a mismerging of References with StoreObjects,\n          // but garbage collection should not be fooled by a stray __ref\n          // property in a StoreObject (ignoring all the other fields just\n          // because the StoreObject looks like a Reference). To avoid this\n          // premature termination of findChildRefIds recursion, we fall through\n          // to the code below, which will handle any other properties of obj.\n        }\n        if (isNonNullObject(obj)) {\n          Object.keys(obj).forEach(key => {\n            const child = obj[key];\n            // No need to add primitive values to the workSet, since they cannot\n            // contain reference objects.\n            if (isNonNullObject(child)) {\n              workSet.add(child);\n            }\n          });\n        }\n      });\n    }\n    return this.refs[dataId];\n  }\n\n  // Used to compute cache keys specific to this.group.\n  public makeCacheKey(...args: any[]): object;\n  public makeCacheKey() {\n    return this.group.keyMaker.lookupArray(arguments);\n  }\n\n  // Bound function that can be passed around to provide easy access to fields\n  // of Reference objects as well as ordinary objects.\n  public getFieldValue = <T = StoreValue>(\n    objectOrReference: StoreObject | Reference | undefined,\n    storeFieldName: string,\n  ) => maybeDeepFreeze(\n    isReference(objectOrReference)\n      ? this.get(objectOrReference.__ref, storeFieldName)\n      : objectOrReference && objectOrReference[storeFieldName]\n  ) as SafeReadonly<T>;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  public canRead: CanReadFunction = objOrRef => {\n    return isReference(objOrRef)\n      ? this.has(objOrRef.__ref)\n      : typeof objOrRef === \"object\";\n  };\n\n  // Bound function that converts an id or an object with a __typename and\n  // primary key fields to a Reference object. If called with a Reference object,\n  // that same Reference object is returned. Pass true for mergeIntoStore to persist\n  // an object into the store.\n  public toReference: ToReferenceFunction = (\n    objOrIdOrRef,\n    mergeIntoStore,\n  ) => {\n    if (typeof objOrIdOrRef === \"string\") {\n      return makeReference(objOrIdOrRef);\n    }\n\n    if (isReference(objOrIdOrRef)) {\n      return objOrIdOrRef;\n    }\n\n    const [id] = this.policies.identify(objOrIdOrRef);\n\n    if (id) {\n      const ref = makeReference(id);\n      if (mergeIntoStore) {\n        this.merge(id, objOrIdOrRef);\n      }\n      return ref;\n    }\n  };\n}\n\nexport type FieldValueGetter = EntityStore[\"getFieldValue\"];\n\n// A single CacheGroup represents a set of one or more EntityStore objects,\n// typically the Root store in a CacheGroup by itself, and all active Layer\n// stores in a group together. A single EntityStore object belongs to only\n// one CacheGroup, store.group. The CacheGroup is responsible for tracking\n// dependencies, so store.group is helpful for generating unique keys for\n// cached results that need to be invalidated when/if those dependencies\n// change. If we used the EntityStore objects themselves as cache keys (that\n// is, store rather than store.group), the cache would become unnecessarily\n// fragmented by all the different Layer objects. Instead, the CacheGroup\n// approach allows all optimistic Layer objects in the same linked list to\n// belong to one CacheGroup, with the non-optimistic Root object belonging\n// to another CacheGroup, allowing resultCaching dependencies to be tracked\n// separately for optimistic and non-optimistic entity data.\nclass CacheGroup {\n  private d: OptimisticDependencyFunction<string> | null = null;\n\n  // Used by the EntityStore#makeCacheKey method to compute cache keys\n  // specific to this CacheGroup.\n  public keyMaker: Trie<object>;\n\n  constructor(\n    public readonly caching: boolean,\n    private parent: CacheGroup | null = null,\n  ) {\n    this.resetCaching();\n  }\n\n  public resetCaching() {\n    this.d = this.caching ? dep<string>() : null;\n    this.keyMaker = new Trie(canUseWeakMap);\n  }\n\n  public depend(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d(makeDepKey(dataId, storeFieldName));\n      const fieldName = fieldNameFromStoreName(storeFieldName);\n      if (fieldName !== storeFieldName) {\n        // Fields with arguments that contribute extra identifying\n        // information to the fieldName (thus forming the storeFieldName)\n        // depend not only on the full storeFieldName but also on the\n        // short fieldName, so the field can be invalidated using either\n        // level of specificity.\n        this.d(makeDepKey(dataId, fieldName));\n      }\n      if (this.parent) {\n        this.parent.depend(dataId, storeFieldName);\n      }\n    }\n  }\n\n  public dirty(dataId: string, storeFieldName: string) {\n    if (this.d) {\n      this.d.dirty(\n        makeDepKey(dataId, storeFieldName),\n        // When storeFieldName === \"__exists\", that means the entity identified\n        // by dataId has either disappeared from the cache or was newly added,\n        // so the result caching system would do well to \"forget everything it\n        // knows\" about that object. To achieve that kind of invalidation, we\n        // not only dirty the associated result cache entry, but also remove it\n        // completely from the dependency graph. For the optimism implementation\n        // details, see https://github.com/benjamn/optimism/pull/195.\n        storeFieldName === \"__exists\" ? \"forget\" : \"setDirty\",\n      );\n    }\n  }\n}\n\nfunction makeDepKey(dataId: string, storeFieldName: string) {\n  // Since field names cannot have '#' characters in them, this method\n  // of joining the field name and the ID should be unambiguous, and much\n  // cheaper than JSON.stringify([dataId, fieldName]).\n  return storeFieldName + '#' + dataId;\n}\n\nexport function maybeDependOnExistenceOfEntity(\n  store: NormalizedCache,\n  entityId: string,\n) {\n  if (supportsResultCaching(store)) {\n    // We use this pseudo-field __exists elsewhere in the EntityStore code to\n    // represent changes in the existence of the entity object identified by\n    // entityId. This dependency gets reliably dirtied whenever an object with\n    // this ID is deleted (or newly created) within this group, so any result\n    // cache entries (for example, StoreReader#executeSelectionSet results) that\n    // depend on __exists for this entityId will get dirtied as well, leading to\n    // the eventual recomputation (instead of reuse) of those result objects the\n    // next time someone reads them from the cache.\n    store.group.depend(entityId, \"__exists\");\n  }\n}\n\nexport namespace EntityStore {\n  // Refer to this class as EntityStore.Root outside this namespace.\n  export class Root extends EntityStore {\n    constructor({\n      policies,\n      resultCaching = true,\n      seed,\n    }: {\n      policies: Policies;\n      resultCaching?: boolean;\n      seed?: NormalizedCacheObject;\n    }) {\n      super(policies, new CacheGroup(resultCaching));\n      if (seed) this.replace(seed);\n    }\n\n    public readonly stump = new Stump(this);\n\n    public addLayer(\n      layerId: string,\n      replay: (layer: EntityStore) => any,\n    ): Layer {\n      // Adding an optimistic Layer on top of the Root actually adds the Layer\n      // on top of the Stump, so the Stump always comes between the Root and\n      // any Layer objects that we've added.\n      return this.stump.addLayer(layerId, replay);\n    }\n\n    public removeLayer(): Root {\n      // Never remove the root layer.\n      return this;\n    }\n\n    public readonly storageTrie = new Trie<StorageType>(canUseWeakMap);\n    public getStorage(): StorageType {\n      return this.storageTrie.lookupArray(arguments);\n    }\n  }\n}\n\n// Not exported, since all Layer instances are created by the addLayer method\n// of the EntityStore.Root class.\nclass Layer extends EntityStore {\n  constructor(\n    public readonly id: string,\n    public readonly parent: EntityStore,\n    public readonly replay: (layer: EntityStore) => any,\n    public readonly group: CacheGroup,\n  ) {\n    super(parent.policies, group);\n    replay(this);\n  }\n\n  public addLayer(\n    layerId: string,\n    replay: (layer: EntityStore) => any,\n  ): Layer {\n    return new Layer(layerId, this, replay, this.group);\n  }\n\n  public removeLayer(layerId: string): EntityStore {\n    // Remove all instances of the given id, not just the first one.\n    const parent = this.parent.removeLayer(layerId);\n\n    if (layerId === this.id) {\n      if (this.group.caching) {\n        // Dirty every ID we're removing. Technically we might be able to avoid\n        // dirtying fields that have values in higher layers, but we don't have\n        // easy access to higher layers here, and we're about to recreate those\n        // layers anyway (see parent.addLayer below).\n        Object.keys(this.data).forEach(dataId => {\n          const ownStoreObject = this.data[dataId];\n          const parentStoreObject = parent[\"lookup\"](dataId);\n          if (!parentStoreObject) {\n            // The StoreObject identified by dataId was defined in this layer\n            // but will be undefined in the parent layer, so we can delete the\n            // whole entity using this.delete(dataId). Since we're about to\n            // throw this layer away, the only goal of this deletion is to dirty\n            // the removed fields.\n            this.delete(dataId);\n          } else if (!ownStoreObject) {\n            // This layer had an entry for dataId but it was undefined, which\n            // means the entity was deleted in this layer, and it's about to\n            // become undeleted when we remove this layer, so we need to dirty\n            // all fields that are about to be reexposed.\n            this.group.dirty(dataId, \"__exists\");\n            Object.keys(parentStoreObject).forEach(storeFieldName => {\n              this.group.dirty(dataId, storeFieldName);\n            });\n          } else if (ownStoreObject !== parentStoreObject) {\n            // If ownStoreObject is not exactly the same as parentStoreObject,\n            // dirty any fields whose values will change as a result of this\n            // removal.\n            Object.keys(ownStoreObject).forEach(storeFieldName => {\n              if (!equal(ownStoreObject[storeFieldName],\n                         parentStoreObject[storeFieldName])) {\n                this.group.dirty(dataId, storeFieldName);\n              }\n            });\n          }\n        });\n      }\n\n      return parent;\n    }\n\n    // No changes are necessary if the parent chain remains identical.\n    if (parent === this.parent) return this;\n\n    // Recreate this layer on top of the new parent.\n    return parent.addLayer(this.id, this.replay);\n  }\n\n  public toObject(): NormalizedCacheObject {\n    return {\n      ...this.parent.toObject(),\n      ...this.data,\n    };\n  }\n\n  public findChildRefIds(dataId: string): Record<string, true> {\n    const fromParent = this.parent.findChildRefIds(dataId);\n    return hasOwn.call(this.data, dataId) ? {\n      ...fromParent,\n      ...super.findChildRefIds(dataId),\n    } : fromParent;\n  }\n\n  public getStorage(): StorageType {\n    let p: EntityStore = this.parent;\n    while ((p as Layer).parent) p = (p as Layer).parent;\n    return p.getStorage.apply(p, arguments);\n  }\n}\n\n// Represents a Layer permanently installed just above the Root, which allows\n// reading optimistically (and registering optimistic dependencies) even when\n// no optimistic layers are currently active. The stump.group CacheGroup object\n// is shared by any/all Layer objects added on top of the Stump.\nclass Stump extends Layer {\n  constructor(root: EntityStore.Root) {\n    super(\n      \"EntityStore.Stump\",\n      root,\n      () => {},\n      new CacheGroup(root.group.caching, root.group),\n    );\n  }\n\n  public removeLayer() {\n    // Never remove the Stump layer.\n    return this;\n  }\n\n  public merge() {\n    // We never want to write any data into the Stump, so we forward any merge\n    // calls to the Root instead. Another option here would be to throw an\n    // exception, but the toReference(object, true) function can sometimes\n    // trigger Stump writes (which used to be Root writes, before the Stump\n    // concept was introduced).\n    return this.parent.merge.apply(this.parent, arguments);\n  }\n}\n\nfunction storeObjectReconciler(\n  existingObject: StoreObject,\n  incomingObject: StoreObject,\n  property: string,\n): StoreValue {\n  const existingValue = existingObject[property];\n  const incomingValue = incomingObject[property];\n  // Wherever there is a key collision, prefer the incoming value, unless\n  // it is deeply equal to the existing value. It's worth checking deep\n  // equality here (even though blindly returning incoming would be\n  // logically correct) because preserving the referential identity of\n  // existing data can prevent needless rereading and rerendering.\n  return equal(existingValue, incomingValue) ? existingValue : incomingValue;\n}\n\nexport function supportsResultCaching(store: any): store is EntityStore {\n  // When result caching is disabled, store.depend will be null.\n  return !!(store instanceof EntityStore && store.group.caching);\n}\n", "import { Trie } from \"@wry/trie\";\nimport {\n  canUseWeakMap,\n  canUseWeakSet,\n  isNonNullObject as isObjectOrArray,\n} from \"../../utilities/index.js\";\nimport { isArray } from \"./helpers.js\";\n\nfunction shallowCopy<T>(value: T): T {\n  if (isObjectOrArray(value)) {\n    return isArray(value)\n      ? value.slice(0) as any as T\n      : { __proto__: Object.getPrototypeOf(value), ...value };\n  }\n  return value;\n}\n\n// When programmers talk about the \"canonical form\" of an object, they\n// usually have the following meaning in mind, which I've copied from\n// https://en.wiktionary.org/wiki/canonical_form:\n//\n// 1. A standard or normal presentation of a mathematical entity [or\n//    object]. A canonical form is an element of a set of representatives\n//    of equivalence classes of forms such that there is a function or\n//    procedure which projects every element of each equivalence class\n//    onto that one element, the canonical form of that equivalence\n//    class. The canonical form is expected to be simpler than the rest of\n//    the forms in some way.\n//\n// That's a long-winded way of saying any two objects that have the same\n// canonical form may be considered equivalent, even if they are !==,\n// which usually means the objects are structurally equivalent (deeply\n// equal), but don't necessarily use the same memory.\n//\n// Like a literary or musical canon, this ObjectCanon class represents a\n// collection of unique canonical items (JavaScript objects), with the\n// important property that canon.admit(a) === canon.admit(b) if a and b\n// are deeply equal to each other. In terms of the definition above, the\n// canon.admit method is the \"function or procedure which projects every\"\n// object \"onto that one element, the canonical form.\"\n//\n// In the worst case, the canonicalization process may involve looking at\n// every property in the provided object tree, so it takes the same order\n// of time as deep equality checking. Fortunately, already-canonicalized\n// objects are returned immediately from canon.admit, so the presence of\n// canonical subtrees tends to speed up canonicalization.\n//\n// Since consumers of canonical objects can check for deep equality in\n// constant time, canonicalizing cache results can massively improve the\n// performance of application code that skips re-rendering unchanged\n// results, such as \"pure\" UI components in a framework like React.\n//\n// Of course, since canonical objects may be shared widely between\n// unrelated consumers, it's important to think of them as immutable, even\n// though they are not actually frozen with Object.freeze in production,\n// due to the extra performance overhead that comes with frozen objects.\n//\n// Custom scalar objects whose internal class name is neither Array nor\n// Object can be included safely in the admitted tree, but they will not\n// be replaced with a canonical version (to put it another way, they are\n// assumed to be canonical already).\n//\n// If we ignore custom objects, no detection of cycles or repeated object\n// references is currently required by the StoreReader class, since\n// GraphQL result objects are JSON-serializable trees (and thus contain\n// neither cycles nor repeated subtrees), so we can avoid the complexity\n// of keeping track of objects we've already seen during the recursion of\n// the admit method.\n//\n// In the future, we may consider adding additional cases to the switch\n// statement to handle other common object types, such as \"[object Date]\"\n// objects, as needed.\nexport class ObjectCanon {\n  // Set of all canonical objects this ObjectCanon has admitted, allowing\n  // canon.admit to return previously-canonicalized objects immediately.\n  private known = new (canUseWeakSet ? WeakSet : Set)<object>();\n\n  // Efficient storage/lookup structure for canonical objects.\n  private pool = new Trie<{\n    array?: any[];\n    object?: Record<string, any>;\n    keys?: SortedKeysInfo;\n  }>(canUseWeakMap);\n\n  public isKnown(value: any): boolean {\n    return isObjectOrArray(value) && this.known.has(value);\n  }\n\n  // Make the ObjectCanon assume this value has already been\n  // canonicalized.\n  private passes = new WeakMap<object, object>();\n  public pass<T>(value: T): T;\n  public pass(value: any) {\n    if (isObjectOrArray(value)) {\n      const copy = shallowCopy(value);\n      this.passes.set(copy, value);\n      return copy;\n    }\n    return value;\n  }\n\n  // Returns the canonical version of value.\n  public admit<T>(value: T): T;\n  public admit(value: any) {\n    if (isObjectOrArray(value)) {\n      const original = this.passes.get(value);\n      if (original) return original;\n\n      const proto = Object.getPrototypeOf(value);\n      switch (proto) {\n        case Array.prototype: {\n          if (this.known.has(value)) return value;\n          const array: any[] = (value as any[]).map(this.admit, this);\n          // Arrays are looked up in the Trie using their recursively\n          // canonicalized elements, and the known version of the array is\n          // preserved as node.array.\n          const node = this.pool.lookupArray(array);\n          if (!node.array) {\n            this.known.add(node.array = array);\n            // Since canonical arrays may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(array);\n            }\n          }\n          return node.array;\n        }\n\n        case null:\n        case Object.prototype: {\n          if (this.known.has(value)) return value;\n          const proto = Object.getPrototypeOf(value);\n          const array = [proto];\n          const keys = this.sortedKeys(value);\n          array.push(keys.json);\n          const firstValueIndex = array.length;\n          keys.sorted.forEach(key => {\n            array.push(this.admit((value as any)[key]));\n          });\n          // Objects are looked up in the Trie by their prototype (which\n          // is *not* recursively canonicalized), followed by a JSON\n          // representation of their (sorted) keys, followed by the\n          // sequence of recursively canonicalized values corresponding to\n          // those keys. To keep the final results unambiguous with other\n          // sequences (such as arrays that just happen to contain [proto,\n          // keys.json, value1, value2, ...]), the known version of the\n          // object is stored as node.object.\n          const node = this.pool.lookupArray(array);\n          if (!node.object) {\n            const obj = node.object = Object.create(proto);\n            this.known.add(obj);\n            keys.sorted.forEach((key, i) => {\n              obj[key] = array[firstValueIndex + i];\n            });\n            // Since canonical objects may be shared widely between\n            // unrelated consumers, it's important to regard them as\n            // immutable, even if they are not frozen in production.\n            if (__DEV__) {\n              Object.freeze(obj);\n            }\n          }\n          return node.object;\n        }\n      }\n    }\n    return value;\n  }\n\n  // It's worthwhile to cache the sorting of arrays of strings, since the\n  // same initial unsorted arrays tend to be encountered many times.\n  // Fortunately, we can reuse the Trie machinery to look up the sorted\n  // arrays in linear time (which is faster than sorting large arrays).\n  private sortedKeys(obj: object) {\n    const keys = Object.keys(obj);\n    const node = this.pool.lookupArray(keys);\n    if (!node.keys) {\n      keys.sort();\n      const json = JSON.stringify(keys);\n      if (!(node.keys = this.keysByJSON.get(json))) {\n        this.keysByJSON.set(json, node.keys = { sorted: keys, json });\n      }\n    }\n    return node.keys;\n  }\n  // Arrays that contain the same elements in a different order can share\n  // the same SortedKeysInfo object, to save memory.\n  private keysByJSON = new Map<string, SortedKeysInfo>();\n\n  // This has to come last because it depends on keysByJSON.\n  public readonly empty = this.admit({});\n}\n\ntype SortedKeysInfo = {\n  sorted: string[];\n  json: string;\n};\n\n// Since the keys of canonical objects are always created in lexicographically\n// sorted order, we can use the ObjectCanon to implement a fast and stable\n// version of JSON.stringify, which automatically sorts object keys.\nexport const canonicalStringify = Object.assign(function (value: any): string {\n  if (isObjectOrArray(value)) {\n    if (stringifyCanon === void 0) {\n      resetCanonicalStringify();\n    }\n    const canonical = stringifyCanon.admit(value);\n    let json = stringifyCache.get(canonical);\n    if (json === void 0) {\n      stringifyCache.set(\n        canonical,\n        json = JSON.stringify(canonical),\n      );\n    }\n    return json;\n  }\n  return JSON.stringify(value);\n}, {\n  reset: resetCanonicalStringify,\n});\n\n// Can be reset by calling canonicalStringify.reset().\nlet stringifyCanon: ObjectCanon;\nlet stringifyCache: WeakMap<object, string>;\n\nfunction resetCanonicalStringify() {\n  stringifyCanon = new ObjectCanon;\n  stringifyCache = new (canUseWeakMap ? WeakMap : Map)();\n}\n", "import { invariant, newInvariantError } from '../../utilities/globals/index.js';\n\nimport type {\n  DocumentNode,\n  FieldNode,\n  SelectionSetNode} from 'graphql';\nimport {\n  Kind\n} from 'graphql';\nimport type { OptimisticWrapperFunction } from 'optimism';\nimport { wrap } from 'optimism';\n\nimport type {\n  Reference,\n  StoreObject,\n  FragmentMap,\n  FragmentMapFunction} from '../../utilities/index.js';\nimport {\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  makeReference,\n  shouldInclude,\n  addTypenameToDocument,\n  getDefaultValues,\n  getMainDefinition,\n  getQueryDefinition,\n  getFragmentFromSelection,\n  maybeDeepFreeze,\n  mergeDeepArray,\n  DeepMerger,\n  isNonNullObject,\n  canUseWeakMap,\n  compact\n} from '../../utilities/index.js';\nimport type { Cache } from '../core/types/Cache.js';\nimport type {\n  DiffQueryAgainstStoreOptions,\n  InMemoryCacheConfig,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from './types.js';\nimport { maybeDependOnExistenceOfEntity, supportsResultCaching } from './entityStore.js';\nimport { isArray, extractFragmentContext, getTypenameFromStoreObject, shouldCanonizeResults } from './helpers.js';\nimport type { Policies } from './policies.js';\nimport type { InMemoryCache } from './inMemoryCache.js';\nimport type { MissingTree } from '../core/types/common.js';\nimport { MissingFieldError } from '../core/types/common.js';\nimport { canonicalStringify, ObjectCanon } from './object-canon.js';\n\nexport type VariableMap = { [name: string]: any };\n\ninterface ReadContext extends ReadMergeModifyContext {\n  query: DocumentNode;\n  policies: Policies;\n  canonizeResults: boolean;\n  fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n};\n\nexport type ExecResult<R = any> = {\n  result: R;\n  missing?: MissingTree;\n};\n\ntype ExecSelectionSetOptions = {\n  selectionSet: SelectionSetNode;\n  objectOrReference: StoreObject | Reference;\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\ntype ExecSubSelectedArrayOptions = {\n  field: FieldNode;\n  array: readonly any[];\n  enclosingRef: Reference;\n  context: ReadContext;\n};\n\nexport interface StoreReaderConfig {\n  cache: InMemoryCache,\n  addTypename?: boolean;\n  resultCacheMaxSize?: number;\n  canonizeResults?: boolean;\n  canon?: ObjectCanon;\n  fragments?: InMemoryCacheConfig[\"fragments\"];\n}\n\n// Arguments type after keyArgs translation.\ntype ExecSelectionSetKeyArgs = [\n  SelectionSetNode,\n  StoreObject | Reference,\n  ReadMergeModifyContext,\n  boolean,\n];\n\nfunction execSelectionSetKeyArgs(\n  options: ExecSelectionSetOptions,\n): ExecSelectionSetKeyArgs {\n  return [\n    options.selectionSet,\n    options.objectOrReference,\n    options.context,\n    // We split out this property so we can pass different values\n    // independently without modifying options.context itself.\n    options.context.canonizeResults,\n  ];\n}\n\nexport class StoreReader {\n  // cached version of executeSelectionSet\n  private executeSelectionSet: OptimisticWrapperFunction<\n    [ExecSelectionSetOptions], // Actual arguments tuple type.\n    ExecResult, // Actual return type.\n    ExecSelectionSetKeyArgs\n  >;\n\n  // cached version of executeSubSelectedArray\n  private executeSubSelectedArray: OptimisticWrapperFunction<\n    [ExecSubSelectedArrayOptions],\n    ExecResult<any>,\n    [ExecSubSelectedArrayOptions]>;\n\n  private config: {\n    cache: InMemoryCache,\n    addTypename: boolean;\n    resultCacheMaxSize?: number;\n    canonizeResults: boolean;\n    fragments?: InMemoryCacheConfig[\"fragments\"];\n  };\n\n  private knownResults = new (\n    canUseWeakMap ? WeakMap : Map\n  )<Record<string, any>, SelectionSetNode>();\n\n  public canon: ObjectCanon;\n  public resetCanon() {\n    this.canon = new ObjectCanon;\n  }\n\n  constructor(config: StoreReaderConfig) {\n    this.config = compact(config, {\n      addTypename: config.addTypename !== false,\n      canonizeResults: shouldCanonizeResults(config),\n    });\n\n    this.canon = config.canon || new ObjectCanon;\n\n    this.executeSelectionSet = wrap(options => {\n      const { canonizeResults } = options.context;\n\n      const peekArgs = execSelectionSetKeyArgs(options);\n\n      // Negate this boolean option so we can find out if we've already read\n      // this result using the other boolean value.\n      peekArgs[3] = !canonizeResults;\n\n      const other = this.executeSelectionSet.peek(...peekArgs);\n\n      if (other) {\n        if (canonizeResults) {\n          return {\n            ...other,\n            // If we previously read this result without canonizing it, we can\n            // reuse that result simply by canonizing it now.\n            result: this.canon.admit(other.result),\n          };\n        }\n        // If we previously read this result with canonization enabled, we can\n        // return that canonized result as-is.\n        return other;\n      }\n\n      maybeDependOnExistenceOfEntity(\n        options.context.store,\n        options.enclosingRef.__ref,\n      );\n\n      // Finally, if we didn't find any useful previous results, run the real\n      // execSelectionSetImpl method with the given options.\n      return this.execSelectionSetImpl(options);\n\n    }, {\n      max: this.config.resultCacheMaxSize,\n      keyArgs: execSelectionSetKeyArgs,\n      // Note that the parameters of makeCacheKey are determined by the\n      // array returned by keyArgs.\n      makeCacheKey(selectionSet, parent, context, canonizeResults) {\n        if (supportsResultCaching(context.store)) {\n          return context.store.makeCacheKey(\n            selectionSet,\n            isReference(parent) ? parent.__ref : parent,\n            context.varString,\n            canonizeResults,\n          );\n        }\n      }\n    });\n\n    this.executeSubSelectedArray = wrap((options: ExecSubSelectedArrayOptions) => {\n      maybeDependOnExistenceOfEntity(\n        options.context.store,\n        options.enclosingRef.__ref,\n      );\n      return this.execSubSelectedArrayImpl(options);\n    }, {\n      max: this.config.resultCacheMaxSize,\n      makeCacheKey({ field, array, context }) {\n        if (supportsResultCaching(context.store)) {\n          return context.store.makeCacheKey(\n            field,\n            array,\n            context.varString,\n          );\n        }\n      }\n    });\n  }\n\n  /**\n   * Given a store and a query, return as much of the result as possible and\n   * identify if any data was missing from the store.\n   * @param  {DocumentNode} query A parsed GraphQL query document\n   * @param  {Store} store The Apollo Client store object\n   * @return {result: Object, complete: [boolean]}\n   */\n  public diffQueryAgainstStore<T>({\n    store,\n    query,\n    rootId = 'ROOT_QUERY',\n    variables,\n    returnPartialData = true,\n    canonizeResults = this.config.canonizeResults,\n  }: DiffQueryAgainstStoreOptions): Cache.DiffResult<T> {\n    const policies = this.config.cache.policies;\n\n    variables = {\n      ...getDefaultValues(getQueryDefinition(query)),\n      ...variables!,\n    };\n\n    const rootRef = makeReference(rootId);\n    const execResult = this.executeSelectionSet({\n      selectionSet: getMainDefinition(query).selectionSet,\n      objectOrReference: rootRef,\n      enclosingRef: rootRef,\n      context: {\n        store,\n        query,\n        policies,\n        variables,\n        varString: canonicalStringify(variables),\n        canonizeResults,\n        ...extractFragmentContext(query, this.config.fragments),\n      },\n    });\n\n    let missing: MissingFieldError[] | undefined;\n    if (execResult.missing) {\n      // For backwards compatibility we still report an array of\n      // MissingFieldError objects, even though there will only ever be at most\n      // one of them, now that all missing field error messages are grouped\n      // together in the execResult.missing tree.\n      missing = [new MissingFieldError(\n        firstMissing(execResult.missing)!,\n        execResult.missing,\n        query,\n        variables,\n      )];\n      if (!returnPartialData) {\n        throw missing[0];\n      }\n    }\n\n    return {\n      result: execResult.result,\n      complete: !missing,\n      missing,\n    };\n  }\n\n  public isFresh(\n    result: Record<string, any>,\n    parent: StoreObject | Reference,\n    selectionSet: SelectionSetNode,\n    context: ReadMergeModifyContext,\n  ): boolean {\n    if (supportsResultCaching(context.store) &&\n        this.knownResults.get(result) === selectionSet) {\n      const latest = this.executeSelectionSet.peek(\n        selectionSet,\n        parent,\n        context,\n        // If result is canonical, then it could only have been previously\n        // cached by the canonizing version of executeSelectionSet, so we can\n        // avoid checking both possibilities here.\n        this.canon.isKnown(result),\n      );\n      if (latest && result === latest.result) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // Uncached version of executeSelectionSet.\n  private execSelectionSetImpl({\n    selectionSet,\n    objectOrReference,\n    enclosingRef,\n    context,\n  }: ExecSelectionSetOptions): ExecResult {\n    if (isReference(objectOrReference) &&\n        !context.policies.rootTypenamesById[objectOrReference.__ref] &&\n        !context.store.has(objectOrReference.__ref)) {\n      return {\n        result: this.canon.empty,\n        missing: `Dangling reference to missing ${objectOrReference.__ref} object`,\n      };\n    }\n\n    const { variables, policies, store } = context;\n    const typename = store.getFieldValue<string>(objectOrReference, \"__typename\");\n\n    const objectsToMerge: Record<string, any>[] = [];\n    let missing: MissingTree | undefined;\n    const missingMerger = new DeepMerger();\n\n    if (this.config.addTypename &&\n        typeof typename === \"string\" &&\n        !policies.rootIdsByTypename[typename]) {\n      // Ensure we always include a default value for the __typename\n      // field, if we have one, and this.config.addTypename is true. Note\n      // that this field can be overridden by other merged objects.\n      objectsToMerge.push({ __typename: typename });\n    }\n\n    function handleMissing<T>(result: ExecResult<T>, resultName: string): T {\n      if (result.missing) {\n        missing = missingMerger.merge(missing, { [resultName]: result.missing });\n      }\n      return result.result;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      // Omit fields with directives @skip(if: <truthy value>) or\n      // @include(if: <falsy value>).\n      if (!shouldInclude(selection, variables)) return;\n\n      if (isField(selection)) {\n        let fieldValue = policies.readField({\n          fieldName: selection.name.value,\n          field: selection,\n          variables: context.variables,\n          from: objectOrReference,\n        }, context);\n\n        const resultName = resultKeyNameFromField(selection);\n\n        if (fieldValue === void 0) {\n          if (!addTypenameToDocument.added(selection)) {\n            missing = missingMerger.merge(missing, {\n              [resultName]: `Can't find field '${\n                selection.name.value\n              }' on ${\n                isReference(objectOrReference)\n                  ? objectOrReference.__ref + \" object\"\n                  : \"object \" + JSON.stringify(objectOrReference, null, 2)\n              }`\n            });\n          }\n\n        } else if (isArray(fieldValue)) {\n          fieldValue = handleMissing(this.executeSubSelectedArray({\n            field: selection,\n            array: fieldValue,\n            enclosingRef,\n            context,\n          }), resultName);\n\n        } else if (!selection.selectionSet) {\n          // If the field does not have a selection set, then we handle it\n          // as a scalar value. To keep this.canon from canonicalizing\n          // this value, we use this.canon.pass to wrap fieldValue in a\n          // Pass object that this.canon.admit will later unwrap as-is.\n          if (context.canonizeResults) {\n            fieldValue = this.canon.pass(fieldValue);\n          }\n\n        } else if (fieldValue != null) {\n          // In this case, because we know the field has a selection set,\n          // it must be trying to query a GraphQLObjectType, which is why\n          // fieldValue must be != null.\n          fieldValue = handleMissing(this.executeSelectionSet({\n            selectionSet: selection.selectionSet,\n            objectOrReference: fieldValue as StoreObject | Reference,\n            enclosingRef: isReference(fieldValue) ? fieldValue : enclosingRef,\n            context,\n          }), resultName);\n        }\n\n        if (fieldValue !== void 0) {\n          objectsToMerge.push({ [resultName]: fieldValue });\n        }\n\n      } else {\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.lookupFragment,\n        );\n\n        if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n          throw newInvariantError(`No fragment named %s`, selection.name.value);\n        }\n\n        if (fragment && policies.fragmentMatches(fragment, typename)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    const result = mergeDeepArray(objectsToMerge);\n    const finalResult: ExecResult = { result, missing };\n    const frozen = context.canonizeResults\n      ? this.canon.admit(finalResult)\n      // Since this.canon is normally responsible for freezing results (only in\n      // development), freeze them manually if canonization is disabled.\n      : maybeDeepFreeze(finalResult);\n\n    // Store this result with its selection set so that we can quickly\n    // recognize it again in the StoreReader#isFresh method.\n    if (frozen.result) {\n      this.knownResults.set(frozen.result, selectionSet);\n    }\n\n    return frozen;\n  }\n\n  // Uncached version of executeSubSelectedArray.\n  private execSubSelectedArrayImpl({\n    field,\n    array,\n    enclosingRef,\n    context,\n  }: ExecSubSelectedArrayOptions): ExecResult {\n    let missing: MissingTree | undefined;\n    let missingMerger = new DeepMerger<MissingTree[]>();\n\n    function handleMissing<T>(childResult: ExecResult<T>, i: number): T {\n      if (childResult.missing) {\n        missing = missingMerger.merge(missing, { [i]: childResult.missing });\n      }\n      return childResult.result;\n    }\n\n    if (field.selectionSet) {\n      array = array.filter(context.store.canRead);\n    }\n\n    array = array.map((item, i) => {\n      // null value in array\n      if (item === null) {\n        return null;\n      }\n\n      // This is a nested array, recurse\n      if (isArray(item)) {\n        return handleMissing(this.executeSubSelectedArray({\n          field,\n          array: item,\n          enclosingRef,\n          context,\n        }), i);\n      }\n\n      // This is an object, run the selection set on it\n      if (field.selectionSet) {\n        return handleMissing(this.executeSelectionSet({\n          selectionSet: field.selectionSet,\n          objectOrReference: item,\n          enclosingRef: isReference(item) ? item : enclosingRef,\n          context,\n        }), i);\n      }\n\n      if (__DEV__) {\n        assertSelectionSetForIdValue(context.store, field, item);\n      }\n\n      return item;\n    });\n\n    return {\n      result: context.canonizeResults ? this.canon.admit(array) : array,\n      missing,\n    };\n  }\n}\n\nfunction firstMissing(tree: MissingTree): string | undefined {\n  try {\n    JSON.stringify(tree, (_, value) => {\n      if (typeof value === \"string\") throw value;\n      return value;\n    });\n  } catch (result) {\n    return result;\n  }\n}\n\nfunction assertSelectionSetForIdValue(\n  store: NormalizedCache,\n  field: FieldNode,\n  fieldValue: any,\n) {\n  if (!field.selectionSet) {\n    const workSet = new Set([fieldValue]);\n    workSet.forEach(value => {\n      if (isNonNullObject(value)) {\n        invariant(\n          !isReference(value),\n          `Missing selection set for object of type %s returned for query field %s`,\n          getTypenameFromStoreObject(store, value),\n          field.name.value\n        );\n        Object.values(value).forEach(workSet.add, workSet);\n      }\n    });\n  }\n}\n", "import type { OptimisticDependencyFunction } from \"optimism\";\nimport { dep } from \"optimism\";\nimport { Slot } from \"@wry/context\";\nimport type { InMemoryCache } from \"./inMemoryCache.js\";\nimport type { ApolloCache } from '../../core/index.js';\n\nexport interface ReactiveVar<T> {\n  (newValue?: T): T;\n  onNextChange(listener: ReactiveListener<T>): () => void;\n  attachCache(cache: ApolloCache<any>): this;\n  forgetCache(cache: ApolloCache<any>): boolean;\n}\n\nexport type ReactiveListener<T> = (value: T) => any;\n\n// Contextual Slot that acquires its value when custom read functions are\n// called in Policies#readField.\nexport const cacheSlot = new Slot<ApolloCache<any>>();\n\nconst cacheInfoMap = new WeakMap<ApolloCache<any>, {\n  vars: Set<ReactiveVar<any>>;\n  dep: OptimisticDependencyFunction<ReactiveVar<any>>;\n}>();\n\nfunction getCacheInfo(cache: ApolloCache<any>) {\n  let info = cacheInfoMap.get(cache)!;\n  if (!info) {\n    cacheInfoMap.set(cache, info = {\n      vars: new Set,\n      dep: dep(),\n    });\n  }\n  return info;\n}\n\nexport function forgetCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach(rv => rv.forgetCache(cache));\n}\n\n// Calling forgetCache(cache) serves to silence broadcasts and allows the\n// cache to be garbage collected. However, the varsByCache WeakMap\n// preserves the set of reactive variables that were previously associated\n// with this cache, which makes it possible to \"recall\" the cache at a\n// later time, by reattaching it to those variables. If the cache has been\n// garbage collected in the meantime, because it is no longer reachable,\n// you won't be able to call recallCache(cache), and the cache will\n// automatically disappear from the varsByCache WeakMap.\nexport function recallCache(cache: ApolloCache<any>) {\n  getCacheInfo(cache).vars.forEach(rv => rv.attachCache(cache));\n}\n\nexport function makeVar<T>(value: T): ReactiveVar<T> {\n  const caches = new Set<ApolloCache<any>>();\n  const listeners = new Set<ReactiveListener<T>>();\n\n  const rv: ReactiveVar<T> = function (newValue) {\n    if (arguments.length > 0) {\n      if (value !== newValue) {\n        value = newValue!;\n        caches.forEach(cache => {\n          // Invalidate any fields with custom read functions that\n          // consumed this variable, so query results involving those\n          // fields will be recomputed the next time we read them.\n          getCacheInfo(cache).dep.dirty(rv);\n          // Broadcast changes to any caches that have previously read\n          // from this variable.\n          broadcast(cache);\n        });\n        // Finally, notify any listeners added via rv.onNextChange.\n        const oldListeners = Array.from(listeners);\n        listeners.clear();\n        oldListeners.forEach(listener => listener(value));\n      }\n    } else {\n      // When reading from the variable, obtain the current cache from\n      // context via cacheSlot. This isn't entirely foolproof, but it's\n      // the same system that powers varDep.\n      const cache = cacheSlot.getValue();\n      if (cache) {\n        attach(cache);\n        getCacheInfo(cache).dep(rv);\n      }\n    }\n\n    return value;\n  };\n\n  rv.onNextChange = listener => {\n    listeners.add(listener);\n    return () => {\n      listeners.delete(listener);\n    };\n  };\n\n  const attach = rv.attachCache = cache => {\n    caches.add(cache);\n    getCacheInfo(cache).vars.add(rv);\n    return rv;\n  };\n\n  rv.forgetCache = cache => caches.delete(cache);\n\n  return rv;\n}\n\ntype Broadcastable = ApolloCache<any> & {\n  // This method is protected in InMemoryCache, which we are ignoring, but\n  // we still want some semblance of type safety when we call it.\n  broadcastWatches?: InMemoryCache[\"broadcastWatches\"];\n};\n\nfunction broadcast(cache: Broadcastable) {\n  if (cache.broadcastWatches) {\n    cache.broadcastWatches();\n  }\n}\n", "import { invariant } from \"../../utilities/globals/index.js\";\n\nimport {\n  argumentsObjectFromField,\n  DeepMerger,\n  isNonEmptyArray,\n  isNonNullObject,\n} from \"../../utilities/index.js\";\n\nimport { hasOwn, isArray } from \"./helpers.js\";\nimport type {\n  KeySpecifier,\n  KeyFieldsFunction,\n  KeyArgsFunction,\n} from \"./policies.js\";\n\n// Mapping from JSON-encoded KeySpecifier strings to associated information.\nconst specifierInfoCache: Record<string, {\n  paths?: string[][];\n  keyFieldsFn?: KeyFieldsFunction;\n  keyArgsFn?: KeyArgsFunction;\n}> = Object.create(null);\n\nfunction lookupSpecifierInfo(spec: KeySpecifier) {\n  // It's safe to encode KeySpecifier arrays with JSON.stringify, since they're\n  // just arrays of strings or nested KeySpecifier arrays, and the order of the\n  // array elements is important (and suitably preserved by JSON.stringify).\n  const cacheKey = JSON.stringify(spec);\n  return specifierInfoCache[cacheKey] ||\n    (specifierInfoCache[cacheKey] = Object.create(null));\n}\n\nexport function keyFieldsFnFromSpecifier(\n  specifier: KeySpecifier,\n): KeyFieldsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return info.keyFieldsFn || (info.keyFieldsFn = (\n    object,\n    context,\n  ) => {\n    const extract: typeof extractKey =\n      (from, key) => context.readField(key, from);\n\n    const keyObject = context.keyObject = collectSpecifierPaths(\n      specifier,\n      schemaKeyPath => {\n        let extracted = extractKeyPath(\n          context.storeObject,\n          schemaKeyPath,\n          // Using context.readField to extract paths from context.storeObject\n          // allows the extraction to see through Reference objects and respect\n          // custom read functions.\n          extract,\n        );\n\n        if (\n          extracted === void 0 &&\n          object !== context.storeObject &&\n          hasOwn.call(object, schemaKeyPath[0])\n        ) {\n          // If context.storeObject fails to provide a value for the requested\n          // path, fall back to the raw result object, if it has a top-level key\n          // matching the first key in the path (schemaKeyPath[0]). This allows\n          // key fields included in the written data to be saved in the cache\n          // even if they are not selected explicitly in context.selectionSet.\n          // Not being mentioned by context.selectionSet is convenient here,\n          // since it means these extra fields cannot be affected by field\n          // aliasing, which is why we can use extractKey instead of\n          // context.readField for this extraction.\n          extracted = extractKeyPath(object, schemaKeyPath, extractKey);\n        }\n\n        invariant(\n          extracted !== void 0,\n          `Missing field '%s' while extracting keyFields from %s`,\n          schemaKeyPath.join('.'),\n          object,\n        );\n\n        return extracted;\n      },\n    );\n\n    return `${context.typename}:${JSON.stringify(keyObject)}`;\n  });\n}\n\n// The keyArgs extraction process is roughly analogous to keyFields extraction,\n// but there are no aliases involved, missing fields are tolerated (by merely\n// omitting them from the key), and drawing from field.directives or variables\n// is allowed (in addition to drawing from the field's arguments object).\n// Concretely, these differences mean passing a different key path extractor\n// function to collectSpecifierPaths, reusing the shared extractKeyPath helper\n// wherever possible.\nexport function keyArgsFnFromSpecifier(specifier: KeySpecifier): KeyArgsFunction {\n  const info = lookupSpecifierInfo(specifier);\n\n  return info.keyArgsFn || (info.keyArgsFn = (args, {\n    field,\n    variables,\n    fieldName,\n  }) => {\n    const collected = collectSpecifierPaths(specifier, keyPath => {\n      const firstKey = keyPath[0];\n      const firstChar = firstKey.charAt(0);\n\n      if (firstChar === \"@\") {\n        if (field && isNonEmptyArray(field.directives)) {\n          const directiveName = firstKey.slice(1);\n          // If the directive appears multiple times, only the first\n          // occurrence's arguments will be used. TODO Allow repetition?\n          // TODO Cache this work somehow, a la aliasMap?\n          const d = field.directives.find(d => d.name.value === directiveName);\n          // Fortunately argumentsObjectFromField works for DirectiveNode!\n          const directiveArgs = d && argumentsObjectFromField(d, variables);\n          // For directives without arguments (d defined, but directiveArgs ===\n          // null), the presence or absence of the directive still counts as\n          // part of the field key, so we return null in those cases. If no\n          // directive with this name was found for this field (d undefined and\n          // thus directiveArgs undefined), we return undefined, which causes\n          // this value to be omitted from the key object returned by\n          // collectSpecifierPaths.\n          return directiveArgs && extractKeyPath(\n            directiveArgs,\n            // If keyPath.length === 1, this code calls extractKeyPath with an\n            // empty path, which works because it uses directiveArgs as the\n            // extracted value.\n            keyPath.slice(1),\n          );\n        }\n        // If the key started with @ but there was no corresponding directive,\n        // we want to omit this value from the key object, not fall through to\n        // treating @whatever as a normal argument name.\n        return;\n      }\n\n      if (firstChar === \"$\") {\n        const variableName = firstKey.slice(1);\n        if (variables && hasOwn.call(variables, variableName)) {\n          const varKeyPath = keyPath.slice(0);\n          varKeyPath[0] = variableName;\n          return extractKeyPath(variables, varKeyPath);\n        }\n        // If the key started with $ but there was no corresponding variable, we\n        // want to omit this value from the key object, not fall through to\n        // treating $whatever as a normal argument name.\n        return;\n      }\n\n      if (args) {\n        return extractKeyPath(args, keyPath);\n      }\n    });\n\n    const suffix = JSON.stringify(collected);\n\n    // If no arguments were passed to this field, and it didn't have any other\n    // field key contributions from directives or variables, hide the empty\n    // :{} suffix from the field key. However, a field passed no arguments can\n    // still end up with a non-empty :{...} suffix if its key configuration\n    // refers to directives or variables.\n    if (args || suffix !== \"{}\") {\n      fieldName += \":\" + suffix;\n    }\n\n    return fieldName;\n  });\n}\n\nexport function collectSpecifierPaths(\n  specifier: KeySpecifier,\n  extractor: (path: string[]) => any,\n): Record<string, any> {\n  // For each path specified by specifier, invoke the extractor, and repeatedly\n  // merge the results together, with appropriate ancestor context.\n  const merger = new DeepMerger;\n  return getSpecifierPaths(specifier).reduce((collected, path) => {\n    let toMerge = extractor(path);\n    if (toMerge !== void 0) {\n      // This path is not expected to contain array indexes, so the toMerge\n      // reconstruction will not contain arrays. TODO Fix this?\n      for (let i = path.length - 1; i >= 0; --i) {\n        toMerge = { [path[i]]: toMerge };\n      }\n      collected = merger.merge(collected, toMerge);\n    }\n    return collected;\n  }, Object.create(null));\n}\n\nexport function getSpecifierPaths(spec: KeySpecifier): string[][] {\n  const info = lookupSpecifierInfo(spec);\n\n  if (!info.paths) {\n    const paths: string[][] = info.paths = [];\n    const currentPath: string[] = [];\n\n    spec.forEach((s, i) => {\n      if (isArray(s)) {\n        getSpecifierPaths(s).forEach(p => paths.push(currentPath.concat(p)));\n        currentPath.length = 0;\n      } else {\n        currentPath.push(s);\n        if (!isArray(spec[i + 1])) {\n          paths.push(currentPath.slice(0));\n          currentPath.length = 0;\n        }\n      }\n    });\n  }\n\n  return info.paths!;\n}\n\nfunction extractKey<\n  TObj extends Record<string, any>,\n  TKey extends string,\n>(object: TObj, key: TKey): TObj[TKey] | undefined {\n  return object[key];\n}\n\nexport function extractKeyPath(\n  object: Record<string, any>,\n  path: string[],\n  extract?: typeof extractKey,\n): any {\n  // For each key in path, extract the corresponding child property from obj,\n  // flattening arrays if encountered (uncommon for keyFields and keyArgs, but\n  // possible). The final result of path.reduce is normalized so unexpected leaf\n  // objects have their keys safely sorted. That final result is difficult to\n  // type as anything other than any. You're welcome to try to improve the\n  // return type, but keep in mind extractKeyPath is not a public function\n  // (exported only for testing), so the effort may not be worthwhile unless the\n  // limited set of actual callers (see above) pass arguments that TypeScript\n  // can statically type. If we know only that path is some array of strings\n  // (and not, say, a specific tuple of statically known strings), any (or\n  // possibly unknown) is the honest answer.\n  extract = extract || extractKey;\n  return normalize(path.reduce(function reducer(obj, key): any {\n    return isArray(obj)\n      ? obj.map(child => reducer(child, key))\n      : obj && extract!(obj, key);\n  }, object));\n}\n\nfunction normalize<T>(value: T): T {\n  // Usually the extracted value will be a scalar value, since most primary\n  // key fields are scalar, but just in case we get an object or an array, we\n  // need to do some normalization of the order of (nested) keys.\n  if (isNonNullObject(value)) {\n    if (isArray(value)) {\n      return value.map(normalize) as any;\n    }\n    return collectSpecifierPaths(\n      Object.keys(value).sort(),\n      path => extractKeyPath(value, path),\n    ) as T;\n  }\n  return value;\n}\n", "import { invariant, newInvariantError } from '../../utilities/globals/index.js';\n\nimport type {\n  InlineFragmentNode,\n  FragmentDefinitionNode,\n  SelectionSetNode,\n  FieldNode,\n} from 'graphql';\n\nimport type {\n  FragmentMap,\n  StoreValue,\n  StoreObject,\n  Reference} from '../../utilities/index.js';\nimport {\n  storeKeyNameFromField,\n  argumentsObjectFromField,\n  isReference,\n  getStoreKeyName,\n  isNonNullObject,\n  stringifyForDisplay,\n} from '../../utilities/index.js';\nimport type {\n  IdGetter,\n  MergeInfo,\n  NormalizedCache,\n  ReadMergeModifyContext,\n} from \"./types.js\";\nimport {\n  hasOwn,\n  fieldNameFromStoreName,\n  storeValueIsStoreObject,\n  selectionSetMatchesResult,\n  TypeOrFieldNameRegExp,\n  defaultDataIdFromObject,\n  isArray,\n} from './helpers.js';\nimport { cacheSlot } from './reactiveVars.js';\nimport type { InMemoryCache } from './inMemoryCache.js';\nimport type {\n  SafeReadonly,\n  FieldSpecifier,\n  ToReferenceFunction,\n  ReadFieldFunction,\n  ReadFieldOptions,\n  CanReadFunction,\n} from '../core/types/common.js';\nimport type { WriteContext } from './writeToStore.js';\n\n// Upgrade to a faster version of the default stable JSON.stringify function\n// used by getStoreKeyName. This function is used when computing storeFieldName\n// strings (when no keyArgs has been configured for a field).\nimport { canonicalStringify } from './object-canon.js';\nimport { keyArgsFnFromSpecifier, keyFieldsFnFromSpecifier } from './key-extractor.js';\n\ngetStoreKeyName.setStringify(canonicalStringify);\n\nexport type TypePolicies = {\n  [__typename: string]: TypePolicy;\n}\n\n// TypeScript 3.7 will allow recursive type aliases, so this should work:\n// type KeySpecifier = (string | KeySpecifier)[]\nexport type KeySpecifier = ReadonlyArray<string | KeySpecifier>;\n\nexport type KeyFieldsContext = {\n  // The __typename of the incoming object, even if the __typename field was\n  // aliased to another name in the raw result object. May be undefined when\n  // dataIdFromObject is called for objects without __typename fields.\n  typename: string | undefined;\n\n  // The object to be identified, after processing to remove aliases and\n  // normalize identifiable child objects with references.\n  storeObject: StoreObject;\n\n  // Handy tool for reading additional fields from context.storeObject, either\n  // readField(\"fieldName\") to read storeObject[fieldName], or readField(\"name\",\n  // objectOrReference) to read from another object or Reference. If you read a\n  // field with a read function, that function will be invoked.\n  readField: ReadFieldFunction;\n\n  // If you are writing a custom keyFields function, and you plan to use the raw\n  // result object passed as the first argument, you may also need access to the\n  // selection set and available fragments for this object, just in case any\n  // fields have aliases. Since this logic is tricky to get right, and these\n  // context properties are not even always provided (for example, they are\n  // omitted when calling cache.identify(object), where object is assumed to be\n  // a StoreObject), we recommend you use context.storeObject (which has already\n  // been de-aliased) and context.readField (which can read from references as\n  // well as objects) instead of the raw result object in your keyFields\n  // functions, or just rely on the internal implementation of keyFields:[...]\n  // syntax to get these details right for you.\n  selectionSet?: SelectionSetNode;\n  fragmentMap?: FragmentMap;\n\n  // Internal. May be set by the KeyFieldsFunction to report fields that were\n  // involved in computing the ID. Never passed in by the caller.\n  keyObject?: Record<string, any>;\n};\n\nexport type KeyFieldsFunction = (\n  object: Readonly<StoreObject>,\n  context: KeyFieldsContext,\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\ntype KeyFieldsResult = Exclude<ReturnType<KeyFieldsFunction>, KeySpecifier>;\n\n// TODO Should TypePolicy be a generic type, with a TObject or TEntity\n// type parameter?\nexport type TypePolicy = {\n  // Allows defining the primary key fields for this type, either using an\n  // array of field names or a function that returns an arbitrary string.\n  keyFields?: KeySpecifier | KeyFieldsFunction | false;\n\n  // Allows defining a merge function (or merge:true/false shorthand) to\n  // be used for merging objects of this type wherever they appear, unless\n  // the parent field also defines a merge function/boolean (that is,\n  // parent field merge functions take precedence over type policy merge\n  // functions). In many cases, defining merge:true for a given type\n  // policy can save you from specifying merge:true for all the field\n  // policies where that type might be encountered.\n  merge?: FieldMergeFunction | boolean;\n\n  // In the rare event that your schema happens to use a different\n  // __typename for the root Query, Mutation, and/or Schema types, you can\n  // express your deviant preferences by enabling one of these options.\n  queryType?: true,\n  mutationType?: true,\n  subscriptionType?: true,\n\n  fields?: {\n    [fieldName: string]:\n      | FieldPolicy<any>\n      | FieldReadFunction<any>;\n  }\n};\n\nexport type KeyArgsFunction = (\n  args: Record<string, any> | null,\n  context: {\n    typename: string;\n    fieldName: string;\n    field: FieldNode | null;\n    variables?: Record<string, any>;\n  },\n) => KeySpecifier | false | ReturnType<IdGetter>;\n\nexport type FieldPolicy<\n  // The internal representation used to store the field's data in the\n  // cache. Must be JSON-serializable if you plan to serialize the result\n  // of cache.extract() using JSON.\n  TExisting = any,\n  // The type of the incoming parameter passed to the merge function,\n  // typically matching the GraphQL response format, but with Reference\n  // objects substituted for any identifiable child objects. Often the\n  // same as TExisting, but not necessarily.\n  TIncoming = TExisting,\n  // The type that the read function actually returns, using TExisting\n  // data and options.args as input. Usually the same as TIncoming.\n  TReadResult = TIncoming,\n  // Allows FieldFunctionOptions definition to be overwritten by the\n  // developer\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = {\n  keyArgs?: KeySpecifier | KeyArgsFunction | false;\n  read?: FieldReadFunction<TExisting, TReadResult, TOptions>;\n  merge?: FieldMergeFunction<TExisting, TIncoming, TOptions> | boolean;\n};\n\nexport type StorageType = Record<string, any>;\n\nfunction argsFromFieldSpecifier(spec: FieldSpecifier) {\n  return spec.args !== void 0 ? spec.args :\n    spec.field ? argumentsObjectFromField(spec.field, spec.variables) : null;\n}\n\nexport interface FieldFunctionOptions<\n  TArgs = Record<string, any>,\n  TVars = Record<string, any>,\n> {\n  args: TArgs | null;\n\n  // The name of the field, equal to options.field.name.value when\n  // options.field is available. Useful if you reuse the same function for\n  // multiple fields, and you need to know which field you're currently\n  // processing. Always a string, even when options.field is null.\n  fieldName: string;\n\n  // The full field key used internally, including serialized key arguments.\n  storeFieldName: string;\n\n  // The FieldNode object used to read this field. Useful if you need to\n  // know about other attributes of the field, such as its directives. This\n  // option will be null when a string was passed to options.readField.\n  field: FieldNode | null;\n\n  variables?: TVars;\n\n  // Utilities for dealing with { __ref } objects.\n  isReference: typeof isReference;\n  toReference: ToReferenceFunction;\n\n  // A handy place to put field-specific data that you want to survive\n  // across multiple read function calls. Useful for field-level caching,\n  // if your read function does any expensive work.\n  storage: StorageType;\n\n  cache: InMemoryCache;\n\n  // Helper function for reading other fields within the current object.\n  // If a foreign object or reference is provided, the field will be read\n  // from that object instead of the current object, so this function can\n  // be used (together with isReference) to examine the cache outside the\n  // current object. If a FieldNode is passed instead of a string, and\n  // that FieldNode has arguments, the same options.variables will be used\n  // to compute the argument values. Note that this function will invoke\n  // custom read functions for other fields, if defined. Always returns\n  // immutable data (enforced with Object.freeze in development).\n  readField: ReadFieldFunction;\n\n  // Returns true for non-normalized StoreObjects and non-dangling\n  // References, indicating that readField(name, objOrRef) has a chance of\n  // working. Useful for filtering out dangling references from lists.\n  canRead: CanReadFunction;\n\n  // Instead of just merging objects with { ...existing, ...incoming }, this\n  // helper function can be used to merge objects in a way that respects any\n  // custom merge functions defined for their fields.\n  mergeObjects: MergeObjectsFunction;\n}\n\ntype MergeObjectsFunction = <T extends StoreObject | Reference>(\n  existing: T,\n  incoming: T,\n) => T;\n\nexport type FieldReadFunction<\n  TExisting = any,\n  TReadResult = TExisting,\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = (\n  // When reading a field, one often needs to know about any existing\n  // value stored for that field. If the field is read before any value\n  // has been written to the cache, this existing parameter will be\n  // undefined, which makes it easy to use a default parameter expression\n  // to supply the initial value. This parameter is positional (rather\n  // than one of the named options) because that makes it possible for the\n  // developer to annotate it with a type, without also having to provide\n  // a whole new type for the options object.\n  existing: SafeReadonly<TExisting> | undefined,\n  options: TOptions,\n) => TReadResult | undefined;\n\nexport type FieldMergeFunction<\n  TExisting = any,\n  TIncoming = TExisting,\n  // Passing the whole FieldFunctionOptions makes the current definition\n  // independent from its implementation\n  TOptions extends FieldFunctionOptions = FieldFunctionOptions\n> = (\n  existing: SafeReadonly<TExisting> | undefined,\n  // The incoming parameter needs to be positional as well, for the same\n  // reasons discussed in FieldReadFunction above.\n  incoming: SafeReadonly<TIncoming>,\n  options: TOptions,\n) => SafeReadonly<TExisting>;\n\nconst nullKeyFieldsFn: KeyFieldsFunction = () => void 0;\nconst simpleKeyArgsFn: KeyArgsFunction = (_args, context) => context.fieldName;\n\n// These merge functions can be selected by specifying merge:true or\n// merge:false in a field policy.\nconst mergeTrueFn: FieldMergeFunction<any> =\n  (existing, incoming, { mergeObjects }) => mergeObjects(existing, incoming);\nconst mergeFalseFn: FieldMergeFunction<any> = (_, incoming) => incoming;\n\nexport type PossibleTypesMap = {\n  [supertype: string]: string[];\n};\n\nexport class Policies {\n  private typePolicies: {\n    [__typename: string]: {\n      keyFn?: KeyFieldsFunction;\n      merge?: FieldMergeFunction<any>;\n      fields: {\n        [fieldName: string]: {\n          keyFn?: KeyArgsFunction;\n          read?: FieldReadFunction<any>;\n          merge?: FieldMergeFunction<any>;\n        };\n      };\n    };\n  } = Object.create(null);\n\n  private toBeAdded: {\n    [__typename: string]: TypePolicy[];\n  } = Object.create(null);\n\n  // Map from subtype names to sets of supertype names. Note that this\n  // representation inverts the structure of possibleTypes (whose keys are\n  // supertypes and whose values are arrays of subtypes) because it tends\n  // to be much more efficient to search upwards than downwards.\n  private supertypeMap = new Map<string, Set<string>>();\n\n  // Any fuzzy subtypes specified by possibleTypes will be converted to\n  // RegExp objects and recorded here. Every key of this map can also be\n  // found in supertypeMap. In many cases this Map will be empty, which\n  // means no fuzzy subtype checking will happen in fragmentMatches.\n  private fuzzySubtypes = new Map<string, RegExp>();\n\n  public readonly cache: InMemoryCache;\n\n  public readonly rootIdsByTypename: Record<string, string> = Object.create(null);\n  public readonly rootTypenamesById: Record<string, string> = Object.create(null);\n\n  public readonly usingPossibleTypes = false;\n\n  constructor(private config: {\n    cache: InMemoryCache;\n    dataIdFromObject?: KeyFieldsFunction;\n    possibleTypes?: PossibleTypesMap;\n    typePolicies?: TypePolicies;\n  }) {\n    this.config = {\n      dataIdFromObject: defaultDataIdFromObject,\n      ...config,\n    };\n\n    this.cache = this.config.cache;\n\n    this.setRootTypename(\"Query\");\n    this.setRootTypename(\"Mutation\");\n    this.setRootTypename(\"Subscription\");\n\n    if (config.possibleTypes) {\n      this.addPossibleTypes(config.possibleTypes);\n    }\n\n    if (config.typePolicies) {\n      this.addTypePolicies(config.typePolicies);\n    }\n  }\n\n  public identify(\n    object: StoreObject,\n    partialContext?: Partial<KeyFieldsContext>,\n  ): [string?, StoreObject?] {\n    const policies = this;\n\n    const typename = partialContext && (\n      partialContext.typename ||\n      partialContext.storeObject?.__typename\n    ) || object.__typename;\n\n    // It should be possible to write root Query fields with writeFragment,\n    // using { __typename: \"Query\", ... } as the data, but it does not make\n    // sense to allow the same identification behavior for the Mutation and\n    // Subscription types, since application code should never be writing\n    // directly to (or reading directly from) those root objects.\n    if (typename === this.rootTypenamesById.ROOT_QUERY) {\n      return [\"ROOT_QUERY\"];\n    }\n\n    // Default context.storeObject to object if not otherwise provided.\n    const storeObject = partialContext && partialContext.storeObject || object;\n\n    const context: KeyFieldsContext = {\n      ...partialContext,\n      typename,\n      storeObject,\n      readField: partialContext && partialContext.readField || function () {\n        const options = normalizeReadFieldOptions(arguments, storeObject);\n        return policies.readField(options, {\n          store: policies.cache[\"data\"],\n          variables: options.variables,\n        });\n      },\n    };\n\n    let id: KeyFieldsResult;\n\n    const policy = typename && this.getTypePolicy(typename);\n    let keyFn = policy && policy.keyFn || this.config.dataIdFromObject;\n    while (keyFn) {\n      const specifierOrId = keyFn({...object, ...storeObject}, context);\n      if (isArray(specifierOrId)) {\n        keyFn = keyFieldsFnFromSpecifier(specifierOrId);\n      } else {\n        id = specifierOrId;\n        break;\n      }\n    }\n\n    id = id ? String(id) : void 0;\n    return context.keyObject ? [id, context.keyObject] : [id];\n  }\n\n  public addTypePolicies(typePolicies: TypePolicies) {\n    Object.keys(typePolicies).forEach(typename => {\n      const {\n        queryType,\n        mutationType,\n        subscriptionType,\n        ...incoming\n      } = typePolicies[typename];\n\n      // Though {query,mutation,subscription}Type configurations are rare,\n      // it's important to call setRootTypename as early as possible,\n      // since these configurations should apply consistently for the\n      // entire lifetime of the cache. Also, since only one __typename can\n      // qualify as one of these root types, these three properties cannot\n      // be inherited, unlike the rest of the incoming properties. That\n      // restriction is convenient, because the purpose of this.toBeAdded\n      // is to delay the processing of type/field policies until the first\n      // time they're used, allowing policies to be added in any order as\n      // long as all relevant policies (including policies for supertypes)\n      // have been added by the time a given policy is used for the first\n      // time. In other words, since inheritance doesn't matter for these\n      // properties, there's also no need to delay their processing using\n      // the this.toBeAdded queue.\n      if (queryType) this.setRootTypename(\"Query\", typename);\n      if (mutationType) this.setRootTypename(\"Mutation\", typename);\n      if (subscriptionType) this.setRootTypename(\"Subscription\", typename);\n\n      if (hasOwn.call(this.toBeAdded, typename)) {\n        this.toBeAdded[typename].push(incoming);\n      } else {\n        this.toBeAdded[typename] = [incoming];\n      }\n    });\n  }\n\n  private updateTypePolicy(typename: string, incoming: TypePolicy) {\n    const existing = this.getTypePolicy(typename);\n    const { keyFields, fields } = incoming;\n\n    function setMerge(\n      existing: { merge?: FieldMergeFunction | boolean; },\n      merge?: FieldMergeFunction | boolean,\n    ) {\n      existing.merge =\n        typeof merge === \"function\" ? merge :\n        // Pass merge:true as a shorthand for a merge implementation\n        // that returns options.mergeObjects(existing, incoming).\n        merge === true ? mergeTrueFn :\n        // Pass merge:false to make incoming always replace existing\n        // without any warnings about data clobbering.\n        merge === false ? mergeFalseFn :\n        existing.merge;\n    }\n\n    // Type policies can define merge functions, as an alternative to\n    // using field policies to merge child objects.\n    setMerge(existing, incoming.merge);\n\n    existing.keyFn =\n      // Pass false to disable normalization for this typename.\n      keyFields === false ? nullKeyFieldsFn :\n      // Pass an array of strings to use those fields to compute a\n      // composite ID for objects of this typename.\n      isArray(keyFields) ? keyFieldsFnFromSpecifier(keyFields) :\n      // Pass a function to take full control over identification.\n      typeof keyFields === \"function\" ? keyFields :\n      // Leave existing.keyFn unchanged if above cases fail.\n      existing.keyFn;\n\n    if (fields) {\n      Object.keys(fields).forEach(fieldName => {\n        const existing = this.getFieldPolicy(typename, fieldName, true)!;\n        const incoming = fields[fieldName];\n\n        if (typeof incoming === \"function\") {\n          existing.read = incoming;\n        } else {\n          const { keyArgs, read, merge } = incoming;\n\n          existing.keyFn =\n            // Pass false to disable argument-based differentiation of\n            // field identities.\n            keyArgs === false ? simpleKeyArgsFn :\n            // Pass an array of strings to use named arguments to\n            // compute a composite identity for the field.\n            isArray(keyArgs) ? keyArgsFnFromSpecifier(keyArgs) :\n            // Pass a function to take full control over field identity.\n            typeof keyArgs === \"function\" ? keyArgs :\n            // Leave existing.keyFn unchanged if above cases fail.\n            existing.keyFn;\n\n          if (typeof read === \"function\") {\n            existing.read = read;\n          }\n\n          setMerge(existing, merge);\n        }\n\n        if (existing.read && existing.merge) {\n          // If we have both a read and a merge function, assume\n          // keyArgs:false, because read and merge together can take\n          // responsibility for interpreting arguments in and out. This\n          // default assumption can always be overridden by specifying\n          // keyArgs explicitly in the FieldPolicy.\n          existing.keyFn = existing.keyFn || simpleKeyArgsFn;\n        }\n      });\n    }\n  }\n\n  private setRootTypename(\n    which: \"Query\" | \"Mutation\" | \"Subscription\",\n    typename: string = which,\n  ) {\n    const rootId = \"ROOT_\" + which.toUpperCase();\n    const old = this.rootTypenamesById[rootId];\n    if (typename !== old) {\n      invariant(!old || old === which, `Cannot change root %s __typename more than once`, which);\n      // First, delete any old __typename associated with this rootId from\n      // rootIdsByTypename.\n      if (old) delete this.rootIdsByTypename[old];\n      // Now make this the only __typename that maps to this rootId.\n      this.rootIdsByTypename[typename] = rootId;\n      // Finally, update the __typename associated with this rootId.\n      this.rootTypenamesById[rootId] = typename;\n    }\n  }\n\n  public addPossibleTypes(possibleTypes: PossibleTypesMap) {\n    (this.usingPossibleTypes as boolean) = true;\n    Object.keys(possibleTypes).forEach(supertype => {\n      // Make sure all types have an entry in this.supertypeMap, even if\n      // their supertype set is empty, so we can return false immediately\n      // from policies.fragmentMatches for unknown supertypes.\n      this.getSupertypeSet(supertype, true);\n\n      possibleTypes[supertype].forEach(subtype => {\n        this.getSupertypeSet(subtype, true)!.add(supertype);\n        const match = subtype.match(TypeOrFieldNameRegExp);\n        if (!match || match[0] !== subtype) {\n          // TODO Don't interpret just any invalid typename as a RegExp.\n          this.fuzzySubtypes.set(subtype, new RegExp(subtype));\n        }\n      });\n    });\n  }\n\n  private getTypePolicy(typename: string): Policies[\"typePolicies\"][string] {\n    if (!hasOwn.call(this.typePolicies, typename)) {\n      const policy: Policies[\"typePolicies\"][string] =\n        this.typePolicies[typename] = Object.create(null);\n      policy.fields = Object.create(null);\n\n      // When the TypePolicy for typename is first accessed, instead of\n      // starting with an empty policy object, inherit any properties or\n      // fields from the type policies of the supertypes of typename.\n      //\n      // Any properties or fields defined explicitly within the TypePolicy\n      // for typename will take precedence, and if there are multiple\n      // supertypes, the properties of policies whose types were added\n      // later via addPossibleTypes will take precedence over those of\n      // earlier supertypes. TODO Perhaps we should warn about these\n      // conflicts in development, and recommend defining the property\n      // explicitly in the subtype policy?\n      //\n      // Field policy inheritance is atomic/shallow: you can't inherit a\n      // field policy and then override just its read function, since read\n      // and merge functions often need to cooperate, so changing only one\n      // of them would be a recipe for inconsistency.\n      //\n      // Once the TypePolicy for typename has been accessed, its properties can\n      // still be updated directly using addTypePolicies, but future changes to\n      // inherited supertype policies will not be reflected in this subtype\n      // policy, because this code runs at most once per typename.\n      let supertypes = this.supertypeMap.get(typename);\n      if (!supertypes && this.fuzzySubtypes.size) {\n        // To make the inheritance logic work for unknown typename strings that\n        // may have fuzzy supertypes, we give this typename an empty supertype\n        // set and then populate it with any fuzzy supertypes that match.\n        supertypes = this.getSupertypeSet(typename, true)!;\n        // This only works for typenames that are directly matched by a fuzzy\n        // supertype. What if there is an intermediate chain of supertypes?\n        // While possible, that situation can only be solved effectively by\n        // specifying the intermediate relationships via possibleTypes, manually\n        // and in a non-fuzzy way.\n        this.fuzzySubtypes.forEach((regExp, fuzzy) => {\n          if (regExp.test(typename)) {\n            // The fuzzy parameter is just the original string version of regExp\n            // (not a valid __typename string), but we can look up the\n            // associated supertype(s) in this.supertypeMap.\n            const fuzzySupertypes = this.supertypeMap.get(fuzzy);\n            if (fuzzySupertypes) {\n              fuzzySupertypes.forEach(supertype => supertypes!.add(supertype));\n            }\n          }\n        });\n      }\n      if (supertypes && supertypes.size) {\n        supertypes.forEach(supertype => {\n          const { fields, ...rest } = this.getTypePolicy(supertype);\n          Object.assign(policy, rest);\n          Object.assign(policy.fields, fields);\n        });\n      }\n    }\n\n    const inbox = this.toBeAdded[typename];\n    if (inbox && inbox.length) {\n      // Merge the pending policies into this.typePolicies, in the order they\n      // were originally passed to addTypePolicy.\n      inbox.splice(0).forEach(policy => {\n        this.updateTypePolicy(typename, policy);\n      });\n    }\n\n    return this.typePolicies[typename];\n  }\n\n  private getFieldPolicy(\n    typename: string | undefined,\n    fieldName: string,\n    createIfMissing: boolean,\n  ): {\n    keyFn?: KeyArgsFunction;\n    read?: FieldReadFunction<any>;\n    merge?: FieldMergeFunction<any>;\n  } | undefined {\n    if (typename) {\n      const fieldPolicies = this.getTypePolicy(typename).fields;\n      return fieldPolicies[fieldName] || (\n        createIfMissing && (fieldPolicies[fieldName] = Object.create(null)));\n    }\n  }\n\n  private getSupertypeSet(\n    subtype: string,\n    createIfMissing: boolean,\n  ): Set<string> | undefined {\n    let supertypeSet = this.supertypeMap.get(subtype);\n    if (!supertypeSet && createIfMissing) {\n      this.supertypeMap.set(subtype, supertypeSet = new Set<string>());\n    }\n    return supertypeSet;\n  }\n\n  public fragmentMatches(\n    fragment: InlineFragmentNode | FragmentDefinitionNode,\n    typename: string | undefined,\n    result?: Record<string, any>,\n    variables?: Record<string, any>,\n  ): boolean {\n    if (!fragment.typeCondition) return true;\n\n    // If the fragment has a type condition but the object we're matching\n    // against does not have a __typename, the fragment cannot match.\n    if (!typename) return false;\n\n    const supertype = fragment.typeCondition.name.value;\n    // Common case: fragment type condition and __typename are the same.\n    if (typename === supertype) return true;\n\n    if (this.usingPossibleTypes &&\n        this.supertypeMap.has(supertype)) {\n      const typenameSupertypeSet = this.getSupertypeSet(typename, true)!;\n      const workQueue = [typenameSupertypeSet];\n      const maybeEnqueue = (subtype: string) => {\n        const supertypeSet = this.getSupertypeSet(subtype, false);\n        if (supertypeSet &&\n            supertypeSet.size &&\n            workQueue.indexOf(supertypeSet) < 0) {\n          workQueue.push(supertypeSet);\n        }\n      };\n\n      // We need to check fuzzy subtypes only if we encountered fuzzy\n      // subtype strings in addPossibleTypes, and only while writing to\n      // the cache, since that's when selectionSetMatchesResult gives a\n      // strong signal of fragment matching. The StoreReader class calls\n      // policies.fragmentMatches without passing a result object, so\n      // needToCheckFuzzySubtypes is always false while reading.\n      let needToCheckFuzzySubtypes = !!(result && this.fuzzySubtypes.size);\n      let checkingFuzzySubtypes = false;\n\n      // It's important to keep evaluating workQueue.length each time through\n      // the loop, because the queue can grow while we're iterating over it.\n      for (let i = 0; i < workQueue.length; ++i) {\n        const supertypeSet = workQueue[i];\n\n        if (supertypeSet.has(supertype)) {\n          if (!typenameSupertypeSet.has(supertype)) {\n            if (checkingFuzzySubtypes) {\n              invariant.warn(`Inferring subtype %s of supertype %s`, typename, supertype);\n            }\n            // Record positive results for faster future lookup.\n            // Unfortunately, we cannot safely cache negative results,\n            // because new possibleTypes data could always be added to the\n            // Policies class.\n            typenameSupertypeSet.add(supertype);\n          }\n          return true;\n        }\n\n        supertypeSet.forEach(maybeEnqueue);\n\n        if (needToCheckFuzzySubtypes &&\n            // Start checking fuzzy subtypes only after exhausting all\n            // non-fuzzy subtypes (after the final iteration of the loop).\n            i === workQueue.length - 1 &&\n            // We could wait to compare fragment.selectionSet to result\n            // after we verify the supertype, but this check is often less\n            // expensive than that search, and we will have to do the\n            // comparison anyway whenever we find a potential match.\n            selectionSetMatchesResult(fragment.selectionSet, result!, variables)) {\n          // We don't always need to check fuzzy subtypes (if no result\n          // was provided, or !this.fuzzySubtypes.size), but, when we do,\n          // we only want to check them once.\n          needToCheckFuzzySubtypes = false;\n          checkingFuzzySubtypes = true;\n\n          // If we find any fuzzy subtypes that match typename, extend the\n          // workQueue to search through the supertypes of those fuzzy\n          // subtypes. Otherwise the for-loop will terminate and we'll\n          // return false below.\n          this.fuzzySubtypes.forEach((regExp, fuzzyString) => {\n            const match = typename.match(regExp);\n            if (match && match[0] === typename) {\n              maybeEnqueue(fuzzyString);\n            }\n          });\n        }\n      }\n    }\n\n    return false;\n  }\n\n  public hasKeyArgs(typename: string | undefined, fieldName: string) {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return !!(policy && policy.keyFn);\n  }\n\n  public getStoreFieldName(fieldSpec: FieldSpecifier): string {\n    const { typename, fieldName } = fieldSpec;\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    let storeFieldName: Exclude<ReturnType<KeyArgsFunction>, KeySpecifier>;\n\n    let keyFn = policy && policy.keyFn;\n    if (keyFn && typename) {\n      const context: Parameters<KeyArgsFunction>[1] = {\n        typename,\n        fieldName,\n        field: fieldSpec.field || null,\n        variables: fieldSpec.variables,\n      };\n      const args = argsFromFieldSpecifier(fieldSpec);\n      while (keyFn) {\n        const specifierOrString = keyFn(args, context);\n        if (isArray(specifierOrString)) {\n          keyFn = keyArgsFnFromSpecifier(specifierOrString);\n        } else {\n          // If the custom keyFn returns a falsy value, fall back to\n          // fieldName instead.\n          storeFieldName = specifierOrString || fieldName;\n          break;\n        }\n      }\n    }\n\n    if (storeFieldName === void 0) {\n      storeFieldName = fieldSpec.field\n        ? storeKeyNameFromField(fieldSpec.field, fieldSpec.variables)\n        : getStoreKeyName(fieldName, argsFromFieldSpecifier(fieldSpec));\n    }\n\n    // Returning false from a keyArgs function is like configuring\n    // keyArgs: false, but more dynamic.\n    if (storeFieldName === false) {\n      return fieldName;\n    }\n\n    // Make sure custom field names start with the actual field.name.value\n    // of the field, so we can always figure out which properties of a\n    // StoreObject correspond to which original field names.\n    return fieldName === fieldNameFromStoreName(storeFieldName)\n      ? storeFieldName\n      : fieldName + \":\" + storeFieldName;\n  }\n\n  public readField<V = StoreValue>(\n    options: ReadFieldOptions,\n    context: ReadMergeModifyContext,\n  ): SafeReadonly<V> | undefined {\n    const objectOrReference = options.from;\n    if (!objectOrReference) return;\n\n    const nameOrField = options.field || options.fieldName;\n    if (!nameOrField) return;\n\n    if (options.typename === void 0) {\n      const typename = context.store.getFieldValue<string>(objectOrReference, \"__typename\");\n      if (typename) options.typename = typename;\n    }\n\n    const storeFieldName = this.getStoreFieldName(options);\n    const fieldName = fieldNameFromStoreName(storeFieldName);\n    const existing = context.store.getFieldValue<V>(objectOrReference, storeFieldName);\n    const policy = this.getFieldPolicy(options.typename, fieldName, false);\n    const read = policy && policy.read;\n\n    if (read) {\n      const readOptions = makeFieldFunctionOptions(\n        this,\n        objectOrReference,\n        options,\n        context,\n        context.store.getStorage(\n          isReference(objectOrReference)\n            ? objectOrReference.__ref\n            : objectOrReference,\n          storeFieldName,\n        ),\n      );\n\n      // Call read(existing, readOptions) with cacheSlot holding this.cache.\n      return cacheSlot.withValue(\n        this.cache,\n        read,\n        [existing, readOptions],\n      ) as SafeReadonly<V>;\n    }\n\n    return existing;\n  }\n\n  public getReadFunction(\n    typename: string | undefined,\n    fieldName: string,\n  ): FieldReadFunction | undefined {\n    const policy = this.getFieldPolicy(typename, fieldName, false);\n    return policy && policy.read;\n  }\n\n  public getMergeFunction(\n    parentTypename: string | undefined,\n    fieldName: string,\n    childTypename: string | undefined,\n  ): FieldMergeFunction | undefined {\n    let policy:\n      | Policies[\"typePolicies\"][string]\n      | Policies[\"typePolicies\"][string][\"fields\"][string]\n      | undefined =\n      this.getFieldPolicy(parentTypename, fieldName, false);\n    let merge = policy && policy.merge;\n    if (!merge && childTypename) {\n      policy = this.getTypePolicy(childTypename);\n      merge = policy && policy.merge;\n    }\n    return merge;\n  }\n\n  public runMergeFunction(\n    existing: StoreValue,\n    incoming: StoreValue,\n    { field, typename, merge }: MergeInfo,\n    context: WriteContext,\n    storage?: StorageType,\n  ) {\n    if (merge === mergeTrueFn) {\n      // Instead of going to the trouble of creating a full\n      // FieldFunctionOptions object and calling mergeTrueFn, we can\n      // simply call mergeObjects, as mergeTrueFn would.\n      return makeMergeObjectsFunction(\n        context.store,\n      )(existing as StoreObject,\n        incoming as StoreObject);\n    }\n\n    if (merge === mergeFalseFn) {\n      // Likewise for mergeFalseFn, whose implementation is even simpler.\n      return incoming;\n    }\n\n    // If cache.writeQuery or cache.writeFragment was called with\n    // options.overwrite set to true, we still call merge functions, but\n    // the existing data is always undefined, so the merge function will\n    // not attempt to combine the incoming data with the existing data.\n    if (context.overwrite) {\n      existing = void 0;\n    }\n\n    return merge(existing, incoming, makeFieldFunctionOptions(\n      this,\n      // Unlike options.readField for read functions, we do not fall\n      // back to the current object if no foreignObjOrRef is provided,\n      // because it's not clear what the current object should be for\n      // merge functions: the (possibly undefined) existing object, or\n      // the incoming object? If you think your merge function needs\n      // to read sibling fields in order to produce a new value for\n      // the current field, you might want to rethink your strategy,\n      // because that's a recipe for making merge behavior sensitive\n      // to the order in which fields are written into the cache.\n      // However, readField(name, ref) is useful for merge functions\n      // that need to deduplicate child objects and references.\n      void 0,\n      { typename,\n        fieldName: field.name.value,\n        field,\n        variables: context.variables },\n      context,\n      storage || Object.create(null),\n    ));\n  }\n}\n\nfunction makeFieldFunctionOptions(\n  policies: Policies,\n  objectOrReference: StoreObject | Reference | undefined,\n  fieldSpec: FieldSpecifier,\n  context: ReadMergeModifyContext,\n  storage: StorageType,\n): FieldFunctionOptions {\n  const storeFieldName = policies.getStoreFieldName(fieldSpec);\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const variables = fieldSpec.variables || context.variables;\n  const { toReference, canRead } = context.store;\n\n  return {\n    args: argsFromFieldSpecifier(fieldSpec),\n    field: fieldSpec.field || null,\n    fieldName,\n    storeFieldName,\n    variables,\n    isReference,\n    toReference,\n    storage,\n    cache: policies.cache,\n    canRead,\n    readField<T>() {\n      return policies.readField<T>(\n        normalizeReadFieldOptions(arguments, objectOrReference, variables),\n        context,\n      );\n    },\n    mergeObjects: makeMergeObjectsFunction(context.store),\n  };\n}\n\nexport function normalizeReadFieldOptions(\n  readFieldArgs: IArguments,\n  objectOrReference: StoreObject | Reference | undefined,\n  variables?: ReadMergeModifyContext[\"variables\"],\n): ReadFieldOptions {\n  const {\n    0: fieldNameOrOptions,\n    1: from,\n    length: argc,\n  } = readFieldArgs;\n\n  let options: ReadFieldOptions;\n\n  if (typeof fieldNameOrOptions === \"string\") {\n    options = {\n      fieldName: fieldNameOrOptions,\n      // Default to objectOrReference only when no second argument was\n      // passed for the from parameter, not when undefined is explicitly\n      // passed as the second argument.\n      from: argc > 1 ? from : objectOrReference,\n    };\n  } else {\n    options = { ...fieldNameOrOptions };\n    // Default to objectOrReference only when fieldNameOrOptions.from is\n    // actually omitted, rather than just undefined.\n    if (!hasOwn.call(options, \"from\")) {\n      options.from = objectOrReference;\n    }\n  }\n\n  if (__DEV__ && options.from === void 0) {\n    invariant.warn(`Undefined 'from' passed to readField with arguments %s`, stringifyForDisplay(Array.from(readFieldArgs)));\n  }\n\n  if (void 0 === options.variables) {\n    options.variables = variables;\n  }\n\n  return options;\n}\n\nfunction makeMergeObjectsFunction(\n  store: NormalizedCache,\n): MergeObjectsFunction {\n  return function mergeObjects(existing, incoming) {\n    if (isArray(existing) || isArray(incoming)) {\n      throw newInvariantError(\"Cannot automatically merge arrays\");\n    }\n\n    // These dynamic checks are necessary because the parameters of a\n    // custom merge function can easily have the any type, so the type\n    // system cannot always enforce the StoreObject | Reference parameter\n    // types of options.mergeObjects.\n    if (isNonNullObject(existing) &&\n        isNonNullObject(incoming)) {\n      const eType = store.getFieldValue(existing, \"__typename\");\n      const iType = store.getFieldValue(incoming, \"__typename\");\n      const typesDiffer = eType && iType && eType !== iType;\n\n      if (typesDiffer) {\n        return incoming;\n      }\n\n      if (isReference(existing) &&\n          storeValueIsStoreObject(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // existing.__ref, preferring/overwriting any fields contributed by the\n        // newer incoming StoreObject.\n        store.merge(existing.__ref, incoming);\n        return existing;\n      }\n\n      if (storeValueIsStoreObject(existing) &&\n          isReference(incoming)) {\n        // Update the normalized EntityStore for the entity identified by\n        // incoming.__ref, taking fields from the older existing object only if\n        // those fields are not already present in the newer StoreObject\n        // identified by incoming.__ref.\n        store.merge(existing, incoming.__ref);\n        return incoming;\n      }\n\n      if (storeValueIsStoreObject(existing) &&\n          storeValueIsStoreObject(incoming)) {\n        return { ...existing, ...incoming };\n      }\n    }\n\n    return incoming;\n  };\n}\n", "import { invariant, newInvariantError } from '../../utilities/globals/index.js';\nimport { equal } from '@wry/equality';\nimport { Trie } from '@wry/trie';\nimport type {\n  SelectionSetNode,\n  FieldNode} from 'graphql';\nimport {\n  Kind,\n} from 'graphql';\n\nimport type {\n  FragmentMap,\n  FragmentMapFunction,\n  StoreValue,\n  StoreObject,\n  Reference} from '../../utilities/index.js';\nimport {\n  getFragmentFromSelection,\n  getDefaultValues,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  isReference,\n  shouldInclude,\n  cloneDeep,\n  addTypenameToDocument,\n  isNonEmptyArray,\n  argumentsObjectFromField,\n} from '../../utilities/index.js';\n\nimport type { NormalizedCache, ReadMergeModifyContext, MergeTree, InMemoryCacheConfig } from './types.js';\nimport { isArray, makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject, extractFragmentContext } from './helpers.js';\nimport type { StoreReader } from './readFromStore.js';\nimport type { InMemoryCache } from './inMemoryCache.js';\nimport type { EntityStore } from './entityStore.js';\nimport type { Cache } from '../../core/index.js';\nimport { canonicalStringify } from './object-canon.js';\nimport { normalizeReadFieldOptions } from './policies.js';\nimport type { ReadFieldFunction } from '../core/types/common.js';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap: FragmentMap;\n  lookupFragment: FragmentMapFunction;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n  // If true, merge functions will be called with undefined existing data.\n  overwrite: boolean;\n  incomingById: Map<string, {\n    storeObject: StoreObject;\n    mergeTree?: MergeTree;\n    fieldNodeSet: Set<FieldNode>;\n  }>;\n  // Directive metadata for @client and @defer. We could use a bitfield for this\n  // information to save some space, and use that bitfield number as the keys in\n  // the context.flavors Map.\n  clientOnly: boolean;\n  deferred: boolean;\n  flavors: Map<string, FlavorableWriteContext>;\n};\n\ntype FlavorableWriteContext = Pick<\n  WriteContext,\n  | \"clientOnly\"\n  | \"deferred\"\n  | \"flavors\"\n>;\n\n// Since there are only four possible combinations of context.clientOnly and\n// context.deferred values, we should need at most four \"flavors\" of any given\n// WriteContext. To avoid creating multiple copies of the same context, we cache\n// the contexts in the context.flavors Map (shared by all flavors) according to\n// their clientOnly and deferred values (always in that order).\nfunction getContextFlavor<TContext extends FlavorableWriteContext>(\n  context: TContext,\n  clientOnly: TContext[\"clientOnly\"],\n  deferred: TContext[\"deferred\"],\n): TContext {\n  const key = `${clientOnly}${deferred}`;\n  let flavored = context.flavors.get(key);\n  if (!flavored) {\n    context.flavors.set(key, flavored = (\n      context.clientOnly === clientOnly &&\n      context.deferred === deferred\n    ) ? context : {\n      ...context,\n      clientOnly,\n      deferred,\n    });\n  }\n  return flavored as TContext;\n}\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n    private fragments?: InMemoryCacheConfig[\"fragments\"],\n  ) {}\n\n  public writeToStore(store: NormalizedCache, {\n    query,\n    result,\n    dataId,\n    variables,\n    overwrite,\n  }: Cache.WriteOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const context: WriteContext = {\n      store,\n      written: Object.create(null),\n      merge<T>(existing: T, incoming: T) {\n        return merger.merge(existing, incoming) as T;\n      },\n      variables,\n      varString: canonicalStringify(variables),\n      ...extractFragmentContext(query, this.fragments),\n      overwrite: !!overwrite,\n      incomingById: new Map,\n      clientOnly: false,\n      deferred: false,\n      flavors: new Map,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context,\n    });\n\n    if (!isReference(ref)) {\n      throw newInvariantError(`Could not identify object %s`, result);\n    }\n\n    // So far, the store has not been modified, so now it's time to process\n    // context.incomingById and merge those incoming fields into context.store.\n    context.incomingById.forEach(({ storeObject, mergeTree, fieldNodeSet }, dataId) => {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree && mergeTree.map.size) {\n        const applied = this.applyMerges(mergeTree, entityRef, storeObject, context);\n        if (isReference(applied)) {\n          // Assume References returned by applyMerges have already been merged\n          // into the store. See makeMergeObjectsFunction in policies.ts for an\n          // example of how this can happen.\n          return;\n        }\n        // Otherwise, applyMerges returned a StoreObject, whose fields we should\n        // merge into the store (see store.merge statement below).\n        storeObject = applied;\n      }\n\n      if (__DEV__ && !context.overwrite) {\n        const fieldsWithSelectionSets: Record<string, true> = Object.create(null);\n        fieldNodeSet.forEach(field => {\n          if (field.selectionSet) {\n            fieldsWithSelectionSets[field.name.value] = true;\n          }\n        });\n\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets[\n            fieldNameFromStoreName(storeFieldName)\n          ] === true;\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree && mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(storeObject).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              storeObject,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      store.merge(dataId, storeObject);\n    });\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incoming: StoreObject = Object.create(null);\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incoming.__typename = typename;\n    }\n\n    // This readField function will be passed as context.readField in the\n    // KeyFieldsContext object created within policies.identify (called below).\n    // In addition to reading from the existing context.store (thanks to the\n    // policies.readField(options, context) line at the very bottom), this\n    // version of readField can read from Reference objects that are currently\n    // pending in context.incomingById, which is important whenever keyFields\n    // need to be extracted from a child object that processSelectionSet has\n    // turned into a Reference.\n    const readField: ReadFieldFunction = function (this: void) {\n      const options = normalizeReadFieldOptions(\n        arguments,\n        incoming,\n        context.variables,\n      );\n\n      if (isReference(options.from)) {\n        const info = context.incomingById.get(options.from.__ref);\n        if (info) {\n          const result = policies.readField({\n            ...options,\n            from: info.storeObject\n          }, context);\n\n          if (result !== void 0) {\n            return result;\n          }\n        }\n      }\n\n      return policies.readField(options, context);\n    };\n\n    const fieldNodeSet = new Set<FieldNode>();\n\n    this.flattenFields(\n      selectionSet,\n      result,\n      // This WriteContext will be the default context value for fields returned\n      // by the flattenFields method, but some fields may be assigned a modified\n      // context, depending on the presence of @client and other directives.\n      context,\n      typename,\n    ).forEach((context, field) => {\n      const resultFieldKey = resultKeyNameFromField(field);\n      const value = result[resultFieldKey];\n\n      fieldNodeSet.add(field);\n\n      if (value !== void 0) {\n        const storeFieldName = policies.getStoreFieldName({\n          typename,\n          fieldName: field.name.value,\n          field,\n          variables: context.variables,\n        });\n\n        const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n        let incomingValue = this.processFieldValue(\n          value,\n          field,\n          // Reset context.clientOnly and context.deferred to their default\n          // values before processing nested selection sets.\n          field.selectionSet\n            ? getContextFlavor(context, false, false)\n            : context,\n          childTree,\n        );\n\n        // To determine if this field holds a child object with a merge function\n        // defined in its type policy (see PR #7070), we need to figure out the\n        // child object's __typename.\n        let childTypename: string | undefined;\n\n        // The field's value can be an object that has a __typename only if the\n        // field has a selection set. Otherwise incomingValue is scalar.\n        if (field.selectionSet &&\n            (isReference(incomingValue) ||\n             storeValueIsStoreObject(incomingValue))) {\n          childTypename = readField<string>(\"__typename\", incomingValue);\n        }\n\n        const merge = policies.getMergeFunction(\n          typename,\n          field.name.value,\n          childTypename,\n        );\n\n        if (merge) {\n          childTree.info = {\n            // TODO Check compatibility against any existing childTree.field?\n            field,\n            typename,\n            merge,\n          };\n        } else {\n          maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n        }\n\n        incoming = context.merge(incoming, {\n          [storeFieldName]: incomingValue,\n        });\n\n      } else if (\n        __DEV__ &&\n        !context.clientOnly &&\n        !context.deferred &&\n        !addTypenameToDocument.added(field) &&\n        // If the field has a read function, it may be a synthetic field or\n        // provide a default value, so its absence from the written data should\n        // not be cause for alarm.\n        !policies.getReadFunction(typename, field.name.value)\n      ) {\n        invariant.error(`Missing field '%s' while writing result %o`, resultKeyNameFromField(field), result);\n      }\n    });\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    try {\n      const [id, keyObject] = policies.identify(result, {\n        typename,\n        selectionSet,\n        fragmentMap: context.fragmentMap,\n        storeObject: incoming,\n        readField,\n      });\n\n      // If dataId was not provided, fall back to the id just generated by\n      // policies.identify.\n      dataId = dataId || id;\n\n      // Write any key fields that were used during identification, even if\n      // they were not mentioned in the original query.\n      if (keyObject) {\n        // TODO Reverse the order of the arguments?\n        incoming = context.merge(incoming, keyObject);\n      }\n    } catch (e) {\n      // If dataId was provided, tolerate failure of policies.identify.\n      if (!dataId) throw e;\n    }\n\n    if (\"string\" === typeof dataId) {\n      const dataRef = makeReference(dataId);\n\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      if (sets.indexOf(selectionSet) >= 0) return dataRef;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        dataRef,\n        selectionSet,\n        context,\n      )) {\n        return dataRef;\n      }\n\n      const previous = context.incomingById.get(dataId);\n      if (previous) {\n        previous.storeObject = context.merge(previous.storeObject, incoming);\n        previous.mergeTree = mergeMergeTrees(previous.mergeTree, mergeTree);\n        fieldNodeSet.forEach(field => previous.fieldNodeSet.add(field));\n      } else {\n        context.incomingById.set(dataId, {\n          storeObject: incoming,\n          // Save a reference to mergeTree only if it is not empty, because\n          // empty MergeTrees may be recycled by maybeRecycleChildMergeTree and\n          // reused for entirely different parts of the result tree.\n          mergeTree: mergeTreeIsEmpty(mergeTree) ? void 0 : mergeTree,\n          fieldNodeSet,\n        });\n      }\n\n      return dataRef;\n    }\n\n    return incoming;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return __DEV__ ? cloneDeep(value) : value;\n    }\n\n    if (isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  // Implements https://spec.graphql.org/draft/#sec-Field-Collection, but with\n  // some additions for tracking @client and @defer directives.\n  private flattenFields<TContext extends Pick<\n    WriteContext,\n    | \"clientOnly\"\n    | \"deferred\"\n    | \"flavors\"\n    | \"fragmentMap\"\n    | \"lookupFragment\"\n    | \"variables\"\n  >>(\n    selectionSet: SelectionSetNode,\n    result: Record<string, any>,\n    context: TContext,\n    typename = getTypenameFromResult(result, selectionSet, context.fragmentMap),\n  ): Map<FieldNode, TContext> {\n    const fieldMap = new Map<FieldNode, TContext>();\n    const { policies } = this.cache;\n\n    const limitingTrie = new Trie<{\n      // Tracks whether (selectionSet, clientOnly, deferred) has been flattened\n      // before. The GraphQL specification only uses the fragment name for\n      // skipping previously visited fragments, but the top-level fragment\n      // selection set corresponds 1:1 with the fagment name (and is slightly\n      // easier too work with), and we need to consider clientOnly and deferred\n      // values as well, potentially revisiting selection sets that were\n      // previously visited with different inherited configurations of those\n      // directives.\n      visited?: boolean;\n    }>(false); // No need for WeakMap, since limitingTrie does not escape.\n\n    (function flatten(\n      this: void,\n      selectionSet: SelectionSetNode,\n      inheritedContext: TContext,\n    ) {\n      const visitedNode = limitingTrie.lookup(\n        selectionSet,\n        // Because we take inheritedClientOnly and inheritedDeferred into\n        // consideration here (in addition to selectionSet), it's possible for\n        // the same selection set to be flattened more than once, if it appears\n        // in the query with different @client and/or @directive configurations.\n        inheritedContext.clientOnly,\n        inheritedContext.deferred,\n      );\n      if (visitedNode.visited) return;\n      visitedNode.visited = true;\n\n      selectionSet.selections.forEach(selection => {\n        if (!shouldInclude(selection, context.variables)) return;\n\n        let { clientOnly, deferred } = inheritedContext;\n        if (\n          // Since the presence of @client or @defer on this field can only\n          // cause clientOnly or deferred to become true, we can skip the\n          // forEach loop if both clientOnly and deferred are already true.\n          !(clientOnly && deferred) &&\n          isNonEmptyArray(selection.directives)\n        ) {\n          selection.directives.forEach(dir => {\n            const name = dir.name.value;\n            if (name === \"client\") clientOnly = true;\n            if (name === \"defer\") {\n              const args = argumentsObjectFromField(dir, context.variables);\n              // The @defer directive takes an optional args.if boolean\n              // argument, similar to @include(if: boolean). Note that\n              // @defer(if: false) does not make context.deferred false, but\n              // instead behaves as if there was no @defer directive.\n              if (!args || (args as { if?: boolean }).if !== false) {\n                deferred = true;\n              }\n              // TODO In the future, we may want to record args.label using\n              // context.deferred, if a label is specified.\n            }\n          });\n        }\n\n        if (isField(selection)) {\n          const existing = fieldMap.get(selection);\n          if (existing) {\n            // If this field has been visited along another recursive path\n            // before, the final context should have clientOnly or deferred set\n            // to true only if *all* paths have the directive (hence the &&).\n            clientOnly = clientOnly && existing.clientOnly;\n            deferred = deferred && existing.deferred;\n          }\n\n          fieldMap.set(\n            selection,\n            getContextFlavor(context, clientOnly, deferred),\n          );\n\n        } else {\n          const fragment = getFragmentFromSelection(\n            selection,\n            context.lookupFragment,\n          );\n\n          if (!fragment && selection.kind === Kind.FRAGMENT_SPREAD) {\n            throw newInvariantError(`No fragment named %s`, selection.name.value);\n          }\n\n          if (fragment &&\n              policies.fragmentMatches(\n                fragment, typename, result, context.variables)) {\n\n            flatten(\n              fragment.selectionSet,\n              getContextFlavor(context, clientOnly, deferred),\n            );\n          }\n        }\n      });\n    })(selectionSet, context);\n\n    return fieldMap;\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: WriteContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T | Reference {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        // If we have no incoming data, leave any existing data untouched.\n        if (void 0 === iVal) return;\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction mergeMergeTrees(\n  left: MergeTree | undefined,\n  right: MergeTree | undefined,\n): MergeTree {\n  if (left === right || !right || mergeTreeIsEmpty(right)) return left!;\n  if (!left || mergeTreeIsEmpty(left)) return right;\n\n  const info = left.info && right.info ? {\n    ...left.info,\n    ...right.info,\n  } : left.info || right.info;\n\n  const needToMergeMaps = left.map.size && right.map.size;\n  const map = needToMergeMaps ? new Map :\n    left.map.size ? left.map : right.map;\n\n  const merged = { info, map };\n\n  if (needToMergeMaps) {\n    const remainingRightKeys = new Set(right.map.keys());\n\n    left.map.forEach((leftTree, key) => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(leftTree, right.map.get(key)),\n      );\n      remainingRightKeys.delete(key);\n    });\n\n    remainingRightKeys.forEach(key => {\n      merged.map.set(\n        key,\n        mergeMergeTrees(\n          right.map.get(key),\n          left.map.get(key),\n        ),\n      );\n    });\n  }\n\n  return merged;\n}\n\nfunction mergeTreeIsEmpty(tree: MergeTree | undefined): boolean {\n  return !tree || !(tree.info || tree.map.size);\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree && mergeTreeIsEmpty(childTree)) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!isArray(existing) &&\n      !isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the %s field of a %s object.\n\nThis could cause additional (usually avoidable) network requests to fetch data that were otherwise cached.\n\nTo address this problem (which is not a bug in Apollo Client), %sdefine a custom merge function for the %s field, so InMemoryCache can safely merge these objects:\n\n  existing: %s\n  incoming: %s\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`,\n  fieldName,\n  parentType,\n  childTypenames.length\n    ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\",\n  typeDotName,\n  existing,\n  incoming\n);\n}\n", "import { invariant } from '../../utilities/globals/index.js';\n\n// Make builtins like Map and Set safe to use with non-extensible objects.\nimport './fixPolyfills.js';\n\nimport type { DocumentNode } from 'graphql';\nimport type { OptimisticWrapperFunction} from 'optimism';\nimport { wrap } from 'optimism';\nimport { equal } from '@wry/equality';\n\nimport { ApolloCache } from '../core/cache.js';\nimport type { Cache } from '../core/types/Cache.js';\nimport { MissingFieldError } from '../core/types/common.js';\nimport type {\n  StoreObject,\n  Reference} from '../../utilities/index.js';\nimport {\n  addTypenameToDocument,\n  isReference,\n  DocumentTransform,\n} from '../../utilities/index.js';\nimport type {\n  InMemoryCacheConfig,\n  NormalizedCacheObject,\n} from './types.js';\nimport { StoreReader } from './readFromStore.js';\nimport { StoreWriter } from './writeToStore.js';\nimport { EntityStore, supportsResultCaching } from './entityStore.js';\nimport { makeVar, forgetCache, recallCache } from './reactiveVars.js';\nimport { Policies } from './policies.js';\nimport { hasOwn, normalizeConfig, shouldCanonizeResults } from './helpers.js';\nimport { canonicalStringify } from './object-canon.js';\nimport type { OperationVariables } from '../../core/index.js';\n\ntype BroadcastOptions = Pick<\n  Cache.BatchOptions<InMemoryCache>,\n  | \"optimistic\"\n  | \"onWatchUpdated\"\n>\n\nexport class InMemoryCache extends ApolloCache<NormalizedCacheObject> {\n  private data: EntityStore;\n  private optimisticData: EntityStore;\n\n  protected config: InMemoryCacheConfig;\n  private watches = new Set<Cache.WatchOptions>();\n  private addTypename: boolean;\n\n  private storeReader: StoreReader;\n  private storeWriter: StoreWriter;\n  private addTypenameTransform = new DocumentTransform(addTypenameToDocument);\n\n  private maybeBroadcastWatch: OptimisticWrapperFunction<\n    [Cache.WatchOptions, BroadcastOptions?],\n    any,\n    [Cache.WatchOptions]>;\n\n  // Override the default value, since InMemoryCache result objects are frozen\n  // in development and expected to remain logically immutable in production.\n  public readonly assumeImmutableResults = true;\n\n  // Dynamically imported code can augment existing typePolicies or\n  // possibleTypes by calling cache.policies.addTypePolicies or\n  // cache.policies.addPossibletypes.\n  public readonly policies: Policies;\n\n  public readonly makeVar = makeVar;\n\n  constructor(config: InMemoryCacheConfig = {}) {\n    super();\n    this.config = normalizeConfig(config);\n    this.addTypename = !!this.config.addTypename;\n\n    this.policies = new Policies({\n      cache: this,\n      dataIdFromObject: this.config.dataIdFromObject,\n      possibleTypes: this.config.possibleTypes,\n      typePolicies: this.config.typePolicies,\n    });\n\n    this.init();\n  }\n\n  private init() {\n    // Passing { resultCaching: false } in the InMemoryCache constructor options\n    // will completely disable dependency tracking, which will improve memory\n    // usage but worsen the performance of repeated reads.\n    const rootStore = this.data = new EntityStore.Root({\n      policies: this.policies,\n      resultCaching: this.config.resultCaching,\n    });\n\n    // When no optimistic writes are currently active, cache.optimisticData ===\n    // cache.data, so there are no additional layers on top of the actual data.\n    // When an optimistic update happens, this.optimisticData will become a\n    // linked list of EntityStore Layer objects that terminates with the\n    // original this.data cache object.\n    this.optimisticData = rootStore.stump;\n\n    this.resetResultCache();\n  }\n\n  private resetResultCache(resetResultIdentities?: boolean) {\n    const previousReader = this.storeReader;\n    const { fragments } = this.config;\n\n    // The StoreWriter is mostly stateless and so doesn't really need to be\n    // reset, but it does need to have its writer.storeReader reference updated,\n    // so it's simpler to update this.storeWriter as well.\n    this.storeWriter = new StoreWriter(\n      this,\n      this.storeReader = new StoreReader({\n        cache: this,\n        addTypename: this.addTypename,\n        resultCacheMaxSize: this.config.resultCacheMaxSize,\n        canonizeResults: shouldCanonizeResults(this.config),\n        canon: resetResultIdentities\n          ? void 0\n          : previousReader && previousReader.canon,\n        fragments,\n      }),\n      fragments,\n    );\n\n    this.maybeBroadcastWatch = wrap((\n      c: Cache.WatchOptions,\n      options?: BroadcastOptions,\n    ) => {\n      return this.broadcastWatch(c, options);\n    }, {\n      max: this.config.resultCacheMaxSize,\n      makeCacheKey: (c: Cache.WatchOptions) => {\n        // Return a cache key (thus enabling result caching) only if we're\n        // currently using a data store that can track cache dependencies.\n        const store = c.optimistic ? this.optimisticData : this.data;\n        if (supportsResultCaching(store)) {\n          const { optimistic, id, variables } = c;\n          return store.makeCacheKey(\n            c.query,\n            // Different watches can have the same query, optimistic\n            // status, rootId, and variables, but if their callbacks are\n            // different, the (identical) result needs to be delivered to\n            // each distinct callback. The easiest way to achieve that\n            // separation is to include c.callback in the cache key for\n            // maybeBroadcastWatch calls. See issue #5733.\n            c.callback,\n            canonicalStringify({ optimistic, id, variables }),\n          );\n        }\n      }\n    });\n\n    // Since we have thrown away all the cached functions that depend on the\n    // CacheGroup dependencies maintained by EntityStore, we should also reset\n    // all CacheGroup dependency information.\n    new Set([\n      this.data.group,\n      this.optimisticData.group,\n    ]).forEach(group => group.resetCaching());\n  }\n\n  public restore(data: NormalizedCacheObject): this {\n    this.init();\n    // Since calling this.init() discards/replaces the entire StoreReader, along\n    // with the result caches it maintains, this.data.replace(data) won't have\n    // to bother deleting the old data.\n    if (data) this.data.replace(data);\n    return this;\n  }\n\n  public extract(optimistic: boolean = false): NormalizedCacheObject {\n    return (optimistic ? this.optimisticData : this.data).extract();\n  }\n\n  public read<T>(options: Cache.ReadOptions): T | null {\n    const {\n      // Since read returns data or null, without any additional metadata\n      // about whether/where there might have been missing fields, the\n      // default behavior cannot be returnPartialData = true (like it is\n      // for the diff method), since defaulting to true would violate the\n      // integrity of the T in the return type. However, partial data may\n      // be useful in some cases, so returnPartialData:true may be\n      // specified explicitly.\n      returnPartialData = false,\n    } = options;\n    try {\n      return this.storeReader.diffQueryAgainstStore<T>({\n        ...options,\n        store: options.optimistic ? this.optimisticData : this.data,\n        config: this.config,\n        returnPartialData,\n      }).result || null;\n    } catch (e) {\n      if (e instanceof MissingFieldError) {\n        // Swallow MissingFieldError and return null, so callers do not need to\n        // worry about catching \"normal\" exceptions resulting from incomplete\n        // cache data. Unexpected errors will be re-thrown. If you need more\n        // information about which fields were missing, use cache.diff instead,\n        // and examine diffResult.missing.\n        return null;\n      }\n      throw e;\n    }\n  }\n\n  public write(options: Cache.WriteOptions): Reference | undefined {\n    try {\n      ++this.txCount;\n      return this.storeWriter.writeToStore(this.data, options);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public modify<Entity extends Record<string, any> = Record<string, any>>(options: Cache.ModifyOptions<Entity>): boolean {\n    if (hasOwn.call(options, \"id\") && !options.id) {\n      // To my knowledge, TypeScript does not currently provide a way to\n      // enforce that an optional property?:type must *not* be undefined\n      // when present. That ability would be useful here, because we want\n      // options.id to default to ROOT_QUERY only when no options.id was\n      // provided. If the caller attempts to pass options.id with a\n      // falsy/undefined value (perhaps because cache.identify failed), we\n      // should not assume the goal was to modify the ROOT_QUERY object.\n      // We could throw, but it seems natural to return false to indicate\n      // that nothing was modified.\n      return false;\n    }\n    const store = options.optimistic // Defaults to false.\n      ? this.optimisticData\n      : this.data;\n    try {\n      ++this.txCount;\n      return store.modify(options.id || \"ROOT_QUERY\", options.fields);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public diff<TData, TVariables extends OperationVariables = any>(\n    options: Cache.DiffOptions<TData, TVariables>,\n  ): Cache.DiffResult<TData> {\n    return this.storeReader.diffQueryAgainstStore({\n      ...options,\n      store: options.optimistic ? this.optimisticData : this.data,\n      rootId: options.id || \"ROOT_QUERY\",\n      config: this.config,\n    });\n  }\n\n  public watch<TData = any, TVariables = any>(\n    watch: Cache.WatchOptions<TData, TVariables>,\n  ): () => void {\n    if (!this.watches.size) {\n      // In case we previously called forgetCache(this) because\n      // this.watches became empty (see below), reattach this cache to any\n      // reactive variables on which it previously depended. It might seem\n      // paradoxical that we're able to recall something we supposedly\n      // forgot, but the point of calling forgetCache(this) is to silence\n      // useless broadcasts while this.watches is empty, and to allow the\n      // cache to be garbage collected. If, however, we manage to call\n      // recallCache(this) here, this cache object must not have been\n      // garbage collected yet, and should resume receiving updates from\n      // reactive variables, now that it has a watcher to notify.\n      recallCache(this);\n    }\n    this.watches.add(watch);\n    if (watch.immediate) {\n      this.maybeBroadcastWatch(watch);\n    }\n    return () => {\n      // Once we remove the last watch from this.watches, cache.broadcastWatches\n      // no longer does anything, so we preemptively tell the reactive variable\n      // system to exclude this cache from future broadcasts.\n      if (this.watches.delete(watch) && !this.watches.size) {\n        forgetCache(this);\n      }\n      // Remove this watch from the LRU cache managed by the\n      // maybeBroadcastWatch OptimisticWrapperFunction, to prevent memory\n      // leaks involving the closure of watch.callback.\n      this.maybeBroadcastWatch.forget(watch);\n    };\n  }\n\n  public gc(options?: {\n    // If true, also free non-essential result cache memory by bulk-releasing\n    // this.{store{Reader,Writer},maybeBroadcastWatch}. Defaults to false.\n    resetResultCache?: boolean;\n    // If resetResultCache is true, this.storeReader.canon will be preserved by\n    // default, but can also be discarded by passing resetResultIdentities:true.\n    // Defaults to false.\n    resetResultIdentities?: boolean;\n  }) {\n    canonicalStringify.reset();\n    const ids = this.optimisticData.gc();\n    if (options && !this.txCount) {\n      if (options.resetResultCache) {\n        this.resetResultCache(options.resetResultIdentities);\n      } else if (options.resetResultIdentities) {\n        this.storeReader.resetCanon();\n      }\n    }\n    return ids;\n  }\n\n  // Call this method to ensure the given root ID remains in the cache after\n  // garbage collection, along with its transitive child entities. Note that\n  // the cache automatically retains all directly written entities. By default,\n  // the retainment persists after optimistic updates are removed. Pass true\n  // for the optimistic argument if you would prefer for the retainment to be\n  // discarded when the top-most optimistic layer is removed. Returns the\n  // resulting (non-negative) retainment count.\n  public retain(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).retain(rootId);\n  }\n\n  // Call this method to undo the effect of the retain method, above. Once the\n  // retainment count falls to zero, the given ID will no longer be preserved\n  // during garbage collection, though it may still be preserved by other safe\n  // entities that refer to it. Returns the resulting (non-negative) retainment\n  // count, in case that's useful.\n  public release(rootId: string, optimistic?: boolean): number {\n    return (optimistic ? this.optimisticData : this.data).release(rootId);\n  }\n\n  // Returns the canonical ID for a given StoreObject, obeying typePolicies\n  // and keyFields (and dataIdFromObject, if you still use that). At minimum,\n  // the object must contain a __typename and any primary key fields required\n  // to identify entities of that type. If you pass a query result object, be\n  // sure that none of the primary key fields have been renamed by aliasing.\n  // If you pass a Reference object, its __ref ID string will be returned.\n  public identify(object: StoreObject | Reference): string | undefined {\n    if (isReference(object)) return object.__ref;\n    try {\n      return this.policies.identify(object)[0];\n    } catch (e) {\n      invariant.warn(e);\n    }\n  }\n\n  public evict(options: Cache.EvictOptions): boolean {\n    if (!options.id) {\n      if (hasOwn.call(options, \"id\")) {\n        // See comment in modify method about why we return false when\n        // options.id exists but is falsy/undefined.\n        return false;\n      }\n      options = { ...options, id: \"ROOT_QUERY\" };\n    }\n    try {\n      // It's unlikely that the eviction will end up invoking any other\n      // cache update operations while it's running, but {in,de}crementing\n      // this.txCount still seems like a good idea, for uniformity with\n      // the other update methods.\n      ++this.txCount;\n      // Pass this.data as a limit on the depth of the eviction, so evictions\n      // during optimistic updates (when this.data is temporarily set equal to\n      // this.optimisticData) do not escape their optimistic Layer.\n      return this.optimisticData.evict(options, this.data);\n    } finally {\n      if (!--this.txCount && options.broadcast !== false) {\n        this.broadcastWatches();\n      }\n    }\n  }\n\n  public reset(options?: Cache.ResetOptions): Promise<void> {\n    this.init();\n\n    canonicalStringify.reset();\n\n    if (options && options.discardWatches) {\n      // Similar to what happens in the unsubscribe function returned by\n      // cache.watch, applied to all current watches.\n      this.watches.forEach(watch => this.maybeBroadcastWatch.forget(watch));\n      this.watches.clear();\n      forgetCache(this);\n    } else {\n      // Calling this.init() above unblocks all maybeBroadcastWatch caching, so\n      // this.broadcastWatches() triggers a broadcast to every current watcher\n      // (letting them know their data is now missing). This default behavior is\n      // convenient because it means the watches do not have to be manually\n      // reestablished after resetting the cache. To prevent this broadcast and\n      // cancel all watches, pass true for options.discardWatches.\n      this.broadcastWatches();\n    }\n\n    return Promise.resolve();\n  }\n\n  public removeOptimistic(idToRemove: string) {\n    const newOptimisticData = this.optimisticData.removeLayer(idToRemove);\n    if (newOptimisticData !== this.optimisticData) {\n      this.optimisticData = newOptimisticData;\n      this.broadcastWatches();\n    }\n  }\n\n  private txCount = 0;\n\n  public batch<TUpdateResult>(\n    options: Cache.BatchOptions<InMemoryCache, TUpdateResult>,\n  ): TUpdateResult {\n    const {\n      update,\n      optimistic = true,\n      removeOptimistic,\n      onWatchUpdated,\n    } = options;\n\n    let updateResult: TUpdateResult;\n    const perform = (layer?: EntityStore): TUpdateResult => {\n      const { data, optimisticData } = this;\n      ++this.txCount;\n      if (layer) {\n        this.data = this.optimisticData = layer;\n      }\n      try {\n        return updateResult = update(this);\n      } finally {\n        --this.txCount;\n        this.data = data;\n        this.optimisticData = optimisticData;\n      }\n    };\n\n    const alreadyDirty = new Set<Cache.WatchOptions>();\n\n    if (onWatchUpdated && !this.txCount) {\n      // If an options.onWatchUpdated callback is provided, we want to call it\n      // with only the Cache.WatchOptions objects affected by options.update,\n      // but there might be dirty watchers already waiting to be broadcast that\n      // have nothing to do with the update. To prevent including those watchers\n      // in the post-update broadcast, we perform this initial broadcast to\n      // collect the dirty watchers, so we can re-dirty them later, after the\n      // post-update broadcast, allowing them to receive their pending\n      // broadcasts the next time broadcastWatches is called, just as they would\n      // if we never called cache.batch.\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch) {\n          alreadyDirty.add(watch);\n          return false;\n        },\n      });\n    }\n\n    if (typeof optimistic === 'string') {\n      // Note that there can be multiple layers with the same optimistic ID.\n      // When removeOptimistic(id) is called for that id, all matching layers\n      // will be removed, and the remaining layers will be reapplied.\n      this.optimisticData = this.optimisticData.addLayer(optimistic, perform);\n    } else if (optimistic === false) {\n      // Ensure both this.data and this.optimisticData refer to the root\n      // (non-optimistic) layer of the cache during the update. Note that\n      // this.data could be a Layer if we are currently executing an optimistic\n      // update function, but otherwise will always be an EntityStore.Root\n      // instance.\n      perform(this.data);\n    } else {\n      // Otherwise, leave this.data and this.optimisticData unchanged and run\n      // the update with broadcast batching.\n      perform();\n    }\n\n    if (typeof removeOptimistic === \"string\") {\n      this.optimisticData = this.optimisticData.removeLayer(removeOptimistic);\n    }\n\n    // Note: if this.txCount > 0, then alreadyDirty.size === 0, so this code\n    // takes the else branch and calls this.broadcastWatches(options), which\n    // does nothing when this.txCount > 0.\n    if (onWatchUpdated && alreadyDirty.size) {\n      this.broadcastWatches({\n        ...options,\n        onWatchUpdated(watch, diff) {\n          const result = onWatchUpdated.call(this, watch, diff);\n          if (result !== false) {\n            // Since onWatchUpdated did not return false, this diff is\n            // about to be broadcast to watch.callback, so we don't need\n            // to re-dirty it with the other alreadyDirty watches below.\n            alreadyDirty.delete(watch);\n          }\n          return result;\n        }\n      });\n      // Silently re-dirty any watches that were already dirty before the update\n      // was performed, and were not broadcast just now.\n      if (alreadyDirty.size) {\n        alreadyDirty.forEach(watch => this.maybeBroadcastWatch.dirty(watch));\n      }\n    } else {\n      // If alreadyDirty is empty or we don't have an onWatchUpdated\n      // function, we don't need to go to the trouble of wrapping\n      // options.onWatchUpdated.\n      this.broadcastWatches(options);\n    }\n\n    return updateResult!;\n  }\n\n  public performTransaction(\n    update: (cache: InMemoryCache) => any,\n    optimisticId?: string | null,\n  ) {\n    return this.batch({\n      update,\n      optimistic: optimisticId || (optimisticId !== null),\n    });\n  }\n\n  public transformDocument(document: DocumentNode): DocumentNode {\n    return this.addTypenameToDocument(this.addFragmentsToDocument(document));\n  }\n\n  protected broadcastWatches(options?: BroadcastOptions) {\n    if (!this.txCount) {\n      this.watches.forEach(c => this.maybeBroadcastWatch(c, options));\n    }\n  }\n\n  private addFragmentsToDocument(document: DocumentNode) {\n    const { fragments } = this.config;\n    return fragments\n      ? fragments.transform(document)\n      : document;\n  }\n\n  private addTypenameToDocument(document: DocumentNode) {\n    if (this.addTypename) {\n      return this.addTypenameTransform.transformDocument(document);\n    }\n    return document;\n  }\n\n  // This method is wrapped by maybeBroadcastWatch, which is called by\n  // broadcastWatches, so that we compute and broadcast results only when\n  // the data that would be broadcast might have changed. It would be\n  // simpler to check for changes after recomputing a result but before\n  // broadcasting it, but this wrapping approach allows us to skip both\n  // the recomputation and the broadcast, in most cases.\n  private broadcastWatch(\n    c: Cache.WatchOptions,\n    options?: BroadcastOptions,\n  ) {\n    const { lastDiff } = c;\n\n    // Both WatchOptions and DiffOptions extend ReadOptions, and DiffOptions\n    // currently requires no additional properties, so we can use c (a\n    // WatchOptions object) as DiffOptions, without having to allocate a new\n    // object, and without having to enumerate the relevant properties (query,\n    // variables, etc.) explicitly. There will be some additional properties\n    // (lastDiff, callback, etc.), but cache.diff ignores them.\n    const diff = this.diff<any>(c);\n\n    if (options) {\n      if (c.optimistic &&\n          typeof options.optimistic === \"string\") {\n        diff.fromOptimisticTransaction = true;\n      }\n\n      if (options.onWatchUpdated &&\n          options.onWatchUpdated.call(this, c, diff, lastDiff) === false) {\n        // Returning false from the onWatchUpdated callback will prevent\n        // calling c.callback(diff) for this watcher.\n        return;\n      }\n    }\n\n    if (!lastDiff || !equal(lastDiff.result, diff.result)) {\n      c.callback(c.lastDiff = diff, lastDiff);\n    }\n  }\n}\n", "import type {\n  DocumentNode,\n  ASTNode,\n  FragmentDefinitionNode,\n  FragmentSpreadNode} from \"graphql\";\nimport {\n  visit,\n} from \"graphql\";\n\nimport { wrap } from \"optimism\";\n\nimport type { FragmentMap} from \"../../utilities/index.js\";\nimport { getFragmentDefinitions } from \"../../utilities/index.js\";\n\nexport interface FragmentRegistryAPI {\n  register(...fragments: DocumentNode[]): this;\n  lookup(fragmentName: string): FragmentDefinitionNode | null;\n  transform<D extends DocumentNode>(document: D): D;\n}\n\n// As long as createFragmentRegistry is not imported or used, the\n// FragmentRegistry example implementation provided below should not be bundled\n// (by tree-shaking bundlers like Rollup), because the implementation of\n// InMemoryCache refers only to the TypeScript interface FragmentRegistryAPI,\n// never the concrete implementation FragmentRegistry (which is deliberately not\n// exported from this module).\nexport function createFragmentRegistry(\n  ...fragments: DocumentNode[]\n): FragmentRegistryAPI {\n  return new FragmentRegistry(...fragments);\n}\n\nconst { forEach: arrayLikeForEach } = Array.prototype;\n\nclass FragmentRegistry implements FragmentRegistryAPI {\n  private registry: FragmentMap = Object.create(null);\n\n  // Call static method FragmentRegistry.from(...) instead of invoking the\n  // FragmentRegistry constructor directly. This reserves the constructor for\n  // future configuration of the FragmentRegistry.\n  constructor(...fragments: DocumentNode[]) {\n    this.resetCaches();\n    if (fragments.length) {\n      this.register.apply(this, fragments);\n    }\n  }\n\n  public register(): this {\n    const definitions = new Map<string, FragmentDefinitionNode>();\n    arrayLikeForEach.call(arguments, (doc: DocumentNode) => {\n      getFragmentDefinitions(doc).forEach(node => {\n        definitions.set(node.name.value, node);\n      });\n    });\n\n    definitions.forEach((node, name) => {\n      if (node !== this.registry[name]) {\n        this.registry[name] = node;\n        this.invalidate(name);\n      }\n    });\n\n    return this;\n  }\n\n  // Overridden in the resetCaches method below.\n  private invalidate(name: string) {}\n\n  public resetCaches() {\n    this.invalidate = (\n      this.lookup = this.cacheUnaryMethod(\"lookup\")\n    ).dirty; // This dirty function is bound to the wrapped lookup method.\n    this.transform = this.cacheUnaryMethod(\"transform\");\n    this.findFragmentSpreads = this.cacheUnaryMethod(\"findFragmentSpreads\");\n  }\n\n  private cacheUnaryMethod<TName extends keyof Pick<FragmentRegistry,\n    | \"lookup\"\n    | \"transform\"\n    | \"findFragmentSpreads\"\n  >>(name: TName) {\n    const registry = this;\n    const originalMethod = FragmentRegistry.prototype[name];\n    return wrap(function () {\n      return originalMethod.apply(registry, arguments);\n    }, {\n      makeCacheKey: arg => arg,\n    });\n  }\n\n  public lookup(fragmentName: string): FragmentDefinitionNode | null {\n    return this.registry[fragmentName] || null;\n  }\n\n  public transform<D extends DocumentNode>(document: D): D {\n    const defined = new Map<string, FragmentDefinitionNode>();\n    getFragmentDefinitions(document).forEach(def => {\n      defined.set(def.name.value, def);\n    });\n\n    const unbound = new Set<string>();\n    const enqueue = (spreadName: string) => {\n      if (!defined.has(spreadName)) {\n        unbound.add(spreadName);\n      }\n    };\n\n    const enqueueChildSpreads = (node: ASTNode) => Object.keys(\n      this.findFragmentSpreads(node)\n    ).forEach(enqueue);\n\n    enqueueChildSpreads(document);\n\n    const missing: string[] = [];\n    const map: FragmentMap = Object.create(null);\n\n    // This Set forEach loop can be extended during iteration by adding\n    // additional strings to the unbound set.\n    unbound.forEach(fragmentName => {\n      const knownFragmentDef = defined.get(fragmentName);\n      if (knownFragmentDef) {\n        enqueueChildSpreads(map[fragmentName] = knownFragmentDef);\n      } else {\n        missing.push(fragmentName);\n        const def = this.lookup(fragmentName);\n        if (def) {\n          enqueueChildSpreads(map[fragmentName] = def);\n        }\n      }\n    });\n\n    if (missing.length) {\n      const defsToAppend: FragmentDefinitionNode[] = [];\n      missing.forEach(name => {\n        const def = map[name];\n        if (def) {\n          defsToAppend.push(def);\n        }\n      });\n\n      if (defsToAppend.length) {\n        document = {\n          ...document,\n          definitions: document.definitions.concat(defsToAppend),\n        };\n      }\n    }\n\n    return document;\n  }\n\n  public findFragmentSpreads(root: ASTNode): FragmentSpreadMap {\n    const spreads: FragmentSpreadMap = Object.create(null);\n\n    visit(root, {\n      FragmentSpread(node) {\n        spreads[node.name.value] = node;\n      },\n    });\n\n    return spreads;\n  }\n}\n\ninterface FragmentSpreadMap {\n  [fragmentSpreadName: string]: FragmentSpreadNode;\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAOA,SAAS,iBAAc;AAAI;AAErB,IAAO,QAAP,MAAY;EAKhB,YACU,MAAM,UACP,UAAsC,gBAAc;AADnD,SAAA,MAAA;AACD,SAAA,UAAA;AAND,SAAA,MAAM,oBAAI,IAAG;AACb,SAAA,SAA4B;AAC5B,SAAA,SAA4B;EAKjC;EAEI,IAAI,KAAM;AACf,WAAO,KAAK,IAAI,IAAI,GAAG;EACzB;EAEO,IAAI,KAAM;AACf,UAAM,OAAO,KAAK,QAAQ,GAAG;AAC7B,WAAO,QAAQ,KAAK;EACtB;EAEQ,QAAQ,KAAM;AACpB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAE7B,QAAI,QAAQ,SAAS,KAAK,QAAQ;AAChC,YAAM,EAAE,OAAO,MAAK,IAAK;AAEzB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,UAAI,OAAO;AACT,cAAM,QAAQ;;AAGhB,WAAK,QAAQ,KAAK;AAClB,WAAK,MAAO,QAAQ;AAEpB,WAAK,QAAQ;AACb,WAAK,SAAS;AAEd,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS;;;AAIlB,WAAO;EACT;EAEO,IAAI,KAAQ,OAAQ;AACzB,QAAI,OAAO,KAAK,QAAQ,GAAG;AAC3B,QAAI,MAAM;AACR,aAAO,KAAK,QAAQ;;AAGtB,WAAO;MACL;MACA;MACA,OAAO;MACP,OAAO,KAAK;;AAGd,QAAI,KAAK,QAAQ;AACf,WAAK,OAAO,QAAQ;;AAGtB,SAAK,SAAS;AACd,SAAK,SAAS,KAAK,UAAU;AAE7B,SAAK,IAAI,IAAI,KAAK,IAAI;AAEtB,WAAO,KAAK;EACd;EAEO,QAAK;AACV,WAAO,KAAK,UAAU,KAAK,IAAI,OAAO,KAAK,KAAK;AAC9C,WAAK,OAAO,KAAK,OAAO,GAAG;;EAE/B;EAEO,OAAO,KAAM;AAClB,UAAM,OAAO,KAAK,IAAI,IAAI,GAAG;AAC7B,QAAI,MAAM;AACR,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,SAAS,KAAK,QAAQ;AACxB,aAAK,SAAS,KAAK;;AAGrB,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,UAAI,KAAK,OAAO;AACd,aAAK,MAAM,QAAQ,KAAK;;AAG1B,WAAK,IAAI,OAAO,GAAG;AACnB,WAAK,QAAQ,KAAK,OAAO,GAAG;AAE5B,aAAO;;AAGT,WAAO;EACT;;;;ACzGF,IAAI,iBAAiC;AAIrC,IAAM,gBAAqB,CAAA;AAE3B,IAAI,YAAY;AAKhB,IAAM,gBAAgB,MAAM,MAAM,KAAI;EAAV,cAAA;AAIV,SAAA,KAAK;MACnB;MACA;MACA,KAAK,IAAG;MACR,KAAK,OAAM,EAAG,SAAS,EAAE,EAAE,MAAM,CAAC;MAClC,KAAK,GAAG;EA+FZ;EA7FS,WAAQ;AACb,aAAS,UAAU,gBAAgB,SAAS,UAAU,QAAQ,QAAQ;AAGpE,UAAI,KAAK,MAAM,QAAQ,OAAO;AAC5B,cAAM,QAAQ,QAAQ,MAAM,KAAK,EAAE;AACnC,YAAI,UAAU;AAAe;AAC7B,YAAI,YAAY,gBAAgB;AAI9B,yBAAgB,MAAM,KAAK,EAAE,IAAI;;AAEnC,eAAO;;;AAGX,QAAI,gBAAgB;AAIlB,qBAAe,MAAM,KAAK,EAAE,IAAI;;AAElC,WAAO;EACT;EAEO,WAAQ;AACb,QAAI,KAAK,SAAQ,GAAI;AACnB,aAAO,eAAgB,MAAM,KAAK,EAAE;;EAExC;EAEO,UACL,OACA,UAGA,MACA,SAAe;AAEf,UAAM,QAAQ;MACZ,WAAW;MACX,CAAC,KAAK,EAAE,GAAG;;AAEb,UAAM,SAAS;AACf,qBAAiB,EAAE,QAAQ,MAAK;AAChC,QAAI;AAGF,aAAO,SAAS,MAAM,SAAU,IAAK;;AAErC,uBAAiB;;EAErB;;;EAIA,OAAO,KACL,UAAkD;AAElD,UAAM,UAAU;AAChB,WAAO,WAAA;AACL,YAAM,QAAQ;AACd,UAAI;AACF,yBAAiB;AACjB,eAAO,SAAS,MAAM,MAAM,SAAgB;;AAE5C,yBAAiB;;IAErB;EACF;;EAGA,OAAO,UACL,UAGA,MACA,SAAe;AAEf,QAAI,gBAAgB;AAClB,YAAM,QAAQ;AACd,UAAI;AACF,yBAAiB;AAGjB,eAAO,SAAS,MAAM,SAAU,IAAK;;AAErC,yBAAiB;;WAEd;AACL,aAAO,SAAS,MAAM,SAAU,IAAK;;EAEzC;;AAGF,SAAS,MAAS,IAAW;AAC3B,MAAI;AACF,WAAO,GAAE;WACF,SAAS;EAAA;AACpB;AAUA,IAAM,YAAY;AAElB,IAAM;;;EAGJ,MAAM,MAAM,UAAU;;;EAItB,MAAM,MAAM,MAAM;;;EAIlB,uBAAO,OAAO,IAAI;;AAIpB,IAAM,aAEF;AAEG,IAAM,OACX,WAAW,SAAS;;AAGnB,MAA4B,SAAS,KACrC,SAAUA,OAAI;AACb,MAAI;AACF,WAAO,eAAe,YAAY,WAAW;MAC3C,OAAOA;MACP,YAAY;MACZ,UAAU;;;;;;;MAOV,cAAc;KACf;;AAED,WAAOA;;AAEX,EAAG,cAAa,CAAE;;;ACpLb,IAAM,EAAE,MAAM,UAAS,IAAK;;;ACC5B,IAAM,kBAAkB,IAAI,KAAI;;;ACHhC,IAAM,EACX,eAAc,IACZ,OAAO;AAEJ,IAAM,eACX,MAAM,QACN,SAAU,KAAG;AACX,QAAM,QAAe,CAAA;AACrB,MAAI,QAAQ,UAAQ,MAAM,KAAK,IAAI,CAAC;AACpC,SAAO;AACT;AAMI,SAAU,iBAAiB,YAA0B;AACzD,QAAM,EAAE,YAAW,IAAK;AACxB,MAAI,OAAO,gBAAgB,YAAY;AACrC,eAAW,cAAc;AACzB,gBAAW;;AAEf;;;ACjBA,IAAM,eAA2B,CAAA;AACjC,IAAM,mBAAmB;AAIzB,SAAS,OAAO,WAAgB,iBAAwB;AACtD,MAAI,CAAE,WAAW;AACf,UAAM,IAAI,MAAM,mBAAmB,mBAAmB;;AAE1D;AASA,SAAS,QAAQ,GAAe,GAAa;AAC3C,QAAM,MAAM,EAAE;AACd;;IAEE,MAAM;IAEN,QAAQ,EAAE;IAEV,EAAE,MAAM,CAAC,MAAM,EAAE,MAAM,CAAC;;AAE5B;AAEA,SAAS,SAAY,OAAe;AAClC,UAAQ,MAAM,QAAQ;IACpB,KAAK;AAAG,YAAM,IAAI,MAAM,eAAe;IACvC,KAAK;AAAG,aAAO,MAAM,CAAC;IACtB,KAAK;AAAG,YAAM,MAAM,CAAC;;AAEzB;AAEA,SAAS,UAAa,OAAe;AACnC,SAAO,MAAM,MAAM,CAAC;AACtB;AAIM,IAAO,QAAP,MAAO,OAAK;EAkBhB,YACkB,IAA8B;AAA9B,SAAA,KAAA;AAbF,SAAA,UAAU,oBAAI,IAAG;AACjB,SAAA,cAAc,oBAAI,IAAG;AAK9B,SAAA,gBAAsC;AAEtC,SAAA,QAAQ;AACR,SAAA,cAAc;AACL,SAAA,QAAuB,CAAA;AAwE/B,SAAA,OAA6B;AAnEnC,MAAE,OAAM;EACV;EAEO,OAAI;AACT,QAAI,KAAK,MAAM,WAAW,KAAK,CAAC,aAAa,IAAI,GAAG;AAClD,qBAAe,IAAI;AACnB,aAAO,KAAK,MAAM,CAAC;;EAEvB;;;;;;;EAQO,UAAU,MAAW;AAC1B,WAAO,CAAE,KAAK,aAAa,qBAAqB;AAChD,mBAAe,IAAI;AACnB,WAAO,aAAa,IAAI,IACpB,gBAAgB,MAAM,IAAI,IAC1B,SAAS,KAAK,KAAK;EACzB;EAEO,WAAQ;AACb,QAAI,KAAK;AAAO;AAChB,SAAK,QAAQ;AACb,SAAK,MAAM,SAAS;AACpB,gBAAY,IAAI;AAIhB,qBAAiB,IAAI;EACvB;EAEO,UAAO;AACZ,SAAK,SAAQ;AAKb,mBAAe,IAAI;AAanB,eAAW,MAAM,CAAC,QAAQ,UAAS;AACjC,aAAO,SAAQ;AACf,kBAAY,QAAQ,IAAI;IAC1B,CAAC;EACH;EAEO,SAAM;AAIX,SAAK,QAAO;EACd;EAIO,SAASC,MAAa;AAC3B,IAAAA,KAAI,IAAI,IAAI;AACZ,QAAI,CAAE,KAAK,MAAM;AACf,WAAK,OAAO,aAAa,IAAG,KAAM,oBAAI,IAAG;;AAE3C,SAAK,KAAK,IAAIA,IAAG;EACnB;EAEO,aAAU;AACf,QAAI,KAAK,MAAM;AACb,mBAAa,KAAK,IAAI,EAAE,QAAQ,CAAAA,SAAOA,KAAI,OAAO,IAAI,CAAC;AACvD,WAAK,KAAK,MAAK;AACf,mBAAa,KAAK,KAAK,IAAI;AAC3B,WAAK,OAAO;;EAEhB;;AAxGc,MAAA,QAAQ;AA2GxB,SAAS,eAAe,OAAe;AACrC,QAAM,SAAS,gBAAgB,SAAQ;AACvC,MAAI,QAAQ;AACV,UAAM,QAAQ,IAAI,MAAM;AAExB,QAAI,CAAE,OAAO,YAAY,IAAI,KAAK,GAAG;AACnC,aAAO,YAAY,IAAI,OAAO,CAAA,CAAE;;AAGlC,QAAI,aAAa,KAAK,GAAG;AACvB,uBAAiB,QAAQ,KAAK;WACzB;AACL,uBAAiB,QAAQ,KAAK;;AAGhC,WAAO;;AAEX;AAEA,SAAS,gBAAgB,OAAiB,MAAW;AACnD,iBAAe,KAAK;AAGpB,kBAAgB,UAAU,OAAO,mBAAmB,CAAC,OAAO,IAAI,CAAC;AAEjE,MAAI,eAAe,OAAO,IAAI,GAAG;AAG/B,aAAS,KAAK;;AAGhB,SAAO,SAAS,MAAM,KAAK;AAC7B;AAEA,SAAS,kBAAkB,OAAiB,MAAW;AACrD,QAAM,cAAc;AAEpB,QAAM,MAAM,SAAS;AACrB,MAAI;AAEF,UAAM,MAAM,CAAC,IAAI,MAAM,GAAG,MAAM,MAAM,IAAI;WACnC,GAAG;AAEV,UAAM,MAAM,CAAC,IAAI;;AAGnB,QAAM,cAAc;AACtB;AAEA,SAAS,aAAa,OAAe;AACnC,SAAO,MAAM,SAAS,CAAC,EAAE,MAAM,iBAAiB,MAAM,cAAc;AACtE;AAEA,SAAS,SAAS,OAAe;AAC/B,QAAM,QAAQ;AAEd,MAAI,aAAa,KAAK,GAAG;AAGvB;;AAGF,cAAY,KAAK;AACnB;AAEA,SAAS,YAAY,OAAe;AAClC,aAAW,OAAO,gBAAgB;AACpC;AAEA,SAAS,YAAY,OAAe;AAClC,aAAW,OAAO,gBAAgB;AACpC;AAEA,SAAS,WACP,OACA,UAAoD;AAEpD,QAAM,cAAc,MAAM,QAAQ;AAClC,MAAI,aAAa;AACf,UAAM,UAAU,aAAa,MAAM,OAAO;AAC1C,aAAS,IAAI,GAAG,IAAI,aAAa,EAAE,GAAG;AACpC,eAAS,QAAQ,CAAC,GAAG,KAAK;;;AAGhC;AAGA,SAAS,iBAAiB,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI,KAAK,CAAC;AACpC,SAAO,aAAa,KAAK,CAAC;AAC1B,QAAM,iBAAiB,CAAC,aAAa,MAAM;AAE3C,MAAI,CAAE,OAAO,eAAe;AAC1B,WAAO,gBAAgB,aAAa,IAAG,KAAM,oBAAI;aAExC,OAAO,cAAc,IAAI,KAAK,GAAG;AAI1C;;AAGF,SAAO,cAAc,IAAI,KAAK;AAI9B,MAAI,gBAAgB;AAClB,gBAAY,MAAM;;AAEtB;AAGA,SAAS,iBAAiB,QAAkB,OAAe;AAGzD,SAAO,OAAO,YAAY,IAAI,KAAK,CAAC;AACpC,SAAO,CAAE,aAAa,KAAK,CAAC;AAE5B,QAAM,aAAa,OAAO,YAAY,IAAI,KAAK;AAC/C,MAAI,WAAW,WAAW,GAAG;AAC3B,WAAO,YAAY,IAAI,OAAO,UAAU,MAAM,KAAK,CAAC;aAC3C,CAAE,QAAQ,YAAY,MAAM,KAAK,GAAG;AAC7C,WAAO,SAAQ;;AAGjB,mBAAiB,QAAQ,KAAK;AAE9B,MAAI,aAAa,MAAM,GAAG;AACxB;;AAGF,cAAY,MAAM;AACpB;AAEA,SAAS,iBAAiB,QAAkB,OAAe;AACzD,QAAM,KAAK,OAAO;AAClB,MAAI,IAAI;AACN,OAAG,OAAO,KAAK;AACf,QAAI,GAAG,SAAS,GAAG;AACjB,UAAI,aAAa,SAAS,kBAAkB;AAC1C,qBAAa,KAAK,EAAE;;AAEtB,aAAO,gBAAgB;;;AAG7B;AAIA,SAAS,eAAe,QAAgB;AACtC,MAAI,OAAO,YAAY,OAAO,GAAG;AAC/B,WAAO,YAAY,QAAQ,CAAC,QAAQ,UAAS;AAC3C,kBAAY,QAAQ,KAAK;IAC3B,CAAC;;AAKH,SAAO,WAAU;AAIjB,SAAO,OAAO,kBAAkB,IAAI;AACtC;AAEA,SAAS,YAAY,QAAkB,OAAe;AACpD,QAAM,QAAQ,OAAO,MAAM;AAC3B,SAAO,YAAY,OAAO,KAAK;AAC/B,mBAAiB,QAAQ,KAAK;AAChC;AAEA,SAAS,eAAe,OAAiB,MAAW;AAClD,MAAI,OAAO,MAAM,cAAc,YAAY;AACzC,QAAI;AACF,uBAAiB,KAAK;AACtB,YAAM,cAAc,MAAM,UAAU,MAAM,MAAM,IAAI;aAC7C,GAAG;AAKV,YAAM,SAAQ;AACd,aAAO;;;AAMX,SAAO;AACT;;;ACjVA,IAAM,eAAe;EACnB,UAAU;EACV,SAAS;EACT,QAAQ;;;AAYJ,SAAU,IAAU,SAEzB;AACC,QAAM,YAAY,oBAAI,IAAG;AACzB,QAAM,YAAY,WAAW,QAAQ;AAErC,WAAS,OAAO,KAAS;AACvB,UAAM,SAAS,gBAAgB,SAAQ;AACvC,QAAI,QAAQ;AACV,UAAIC,OAAM,UAAU,IAAI,GAAG;AAC3B,UAAI,CAACA,MAAK;AACR,kBAAU,IAAI,KAAKA,OAAM,oBAAI,KAAgB;;AAE/C,aAAO,SAASA,IAAG;AACnB,UAAI,OAAO,cAAc,YAAY;AACnC,yBAAiBA,IAAG;AACpB,QAAAA,KAAI,cAAc,UAAU,GAAG;;;EAGrC;AAEA,SAAO,QAAQ,SAAS,MACtB,KACA,iBAAiC;AAEjC,UAAMA,OAAM,UAAU,IAAI,GAAG;AAC7B,QAAIA,MAAK;AACP,YAAM,IACJ,mBACA,eAAe,KAAK,cAAc,eAAe,IAC/C,kBAAkB;AAItB,mBAAaA,IAAG,EAAE,QAAQ,WAAS,MAAM,CAAC,EAAC,CAAE;AAC7C,gBAAU,OAAO,GAAG;AACpB,uBAAiBA,IAAG;;EAExB;AAEA,SAAO;AACT;;;AClCA,IAAI;AACE,SAAU,uBAAuB,MAAW;AAChD,QAAM,OAAO,mBACX,iBAAiB,IAAI,KAAK,OAAO,YAAY,UAAU;AAEzD,SAAO,KAAK,YAAY,IAAI;AAC9B;AAuEA,IAAM,SAAS,oBAAI,IAAG;AAEhB,SAAU,KAKd,kBAA+C,EAC/C,MAAM,KAAK,IAAI,GAAG,EAAE,GACpB,eAAe,qBACf,SACA,UAAS,IACiC,uBAAO,OAAO,IAAI,GAAC;AAC7D,QAAM,QAAQ,IAAI,MAChB,KACA,WAAS,MAAM,QAAO,CAAE;AAG1B,QAAM,aAAa,WAAA;AACjB,UAAM,MAAM,aAAa,MACvB,MACA,UAAU,QAAQ,MAAM,MAAM,SAAgB,IAAI,SAAgB;AAGpE,QAAI,QAAQ,QAAQ;AAClB,aAAO,iBAAiB,MAAM,MAAM,SAAgB;;AAGtD,QAAI,QAAQ,MAAM,IAAI,GAAG;AACzB,QAAI,CAAC,OAAO;AACV,YAAM,IAAI,KAAK,QAAQ,IAAI,MAAM,gBAAgB,CAAC;AAClD,YAAM,YAAY;AAGlB,YAAM,SAAS,MAAM,MAAM,OAAO,GAAG;;AAGvC,UAAM,QAAQ,MAAM,UAClB,MAAM,UAAU,MAAM,KAAK,SAAS,CAAU;AAKhD,UAAM,IAAI,KAAK,KAAK;AAEpB,WAAO,IAAI,KAAK;AAKhB,QAAI,CAAE,gBAAgB,SAAQ,GAAI;AAChC,aAAO,QAAQ,CAAAC,WAASA,OAAM,MAAK,CAAE;AACrC,aAAO,MAAK;;AAGd,WAAO;EACT;AAEA,SAAO,eAAe,YAAY,QAAQ;IACxC,MAAG;AACD,aAAO,MAAM,KAAK,EAAE;IACtB;IACA,cAAc;IACd,YAAY;GACb;AAED,SAAO,OAAO,WAAW,UAAU;IACjC;IACA;IACA;IACA;GACD;AAED,WAAS,SAAS,KAAc;AAC9B,UAAM,QAAQ,MAAM,IAAI,GAAG;AAC3B,QAAI,OAAO;AACT,YAAM,SAAQ;;EAElB;AACA,aAAW,WAAW;AACtB,aAAW,QAAQ,SAAS,QAAK;AAC/B,aAAS,aAAa,MAAM,MAAM,SAAgB,CAAC;EACrD;AAEA,WAAS,QAAQ,KAAc;AAC7B,UAAM,QAAQ,MAAM,IAAI,GAAG;AAC3B,QAAI,OAAO;AACT,aAAO,MAAM,KAAI;;EAErB;AACA,aAAW,UAAU;AACrB,aAAW,OAAO,SAAS,OAAI;AAC7B,WAAO,QAAQ,aAAa,MAAM,MAAM,SAAgB,CAAC;EAC3D;AAEA,WAAS,UAAU,KAAc;AAC/B,WAAO,MAAM,OAAO,GAAG;EACzB;AACA,aAAW,YAAY;AACvB,aAAW,SAAS,SAAS,SAAM;AACjC,WAAO,UAAU,aAAa,MAAM,MAAM,SAAgB,CAAC;EAC7D;AAEA,aAAW,eAAe;AAC1B,aAAW,SAAS,UAAU,SAAS,SAAM;AAC3C,WAAO,aAAa,MAAM,MAAM,QAAQ,MAAM,MAAM,SAAgB,CAAC;EACvE,IAAI;AAEJ,SAAO,OAAO,OAAO,UAAU;AACjC;;;AC7MA,IAAA,cAAA,WAAA;AAAA,WAAAC,eAAA;AACkB,SAAA,yBAAkC;AAkI1C,SAAA,iBAAiB,KAAK,wBAAwB;EAoExD;AAhJS,EAAAA,aAAA,UAAA,QAAP,SAAgB,SAAoC;AAApD,QAAA,QAAA;AACE,QAAM,eACJ,OAAO,QAAQ,eAAe,WAAW,QAAQ,aACjD,QAAQ,eAAe,QAAQ,OAAO;AACxC,QAAI;AACJ,SAAK,mBACH,WAAA;AAAM,aAAA,eAAe,QAAQ,OAAO,KAAI;IAAlC,GACN,YAAY;AAEd,WAAO;EACT;AAcO,EAAAA,aAAA,UAAA,8BAAP,SACE,aACA,cAAoB;AAEpB,SAAK,mBAAmB,aAAa,YAAY;EACnD;AAMO,EAAAA,aAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,WAAO;EACT;AAIO,EAAAA,aAAA,UAAA,mBAAP,SAAwB,UAAsB;AAC5C,WAAO;EACT;AAEO,EAAAA,aAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C;EACF;AAEO,EAAAA,aAAA,UAAA,KAAP,WAAA;AACE,WAAO,CAAA;EACT;AAEO,EAAAA,aAAA,UAAA,SAAP,SAAwE,SAAoC;AAC1G,WAAO;EACT;AAQO,EAAAA,aAAA,UAAA,YAAP,SACE,SACA,YAAiC;AAAjC,QAAA,eAAA,QAAA;AAAA,mBAAA,CAAc,CAAC,QAAQ;IAAU;AAEjC,WAAO,KAAK,KAAI,SAAA,SAAA,CAAA,GACX,OAAO,GAAA,EACV,QAAQ,QAAQ,MAAM,cACtB,WAAU,CAAA,CAAA;EAEd;AAMO,EAAAA,aAAA,UAAA,eAAP,SACE,SACA,YAAiC;AAAjC,QAAA,eAAA,QAAA;AAAA,mBAAA,CAAc,CAAC,QAAQ;IAAU;AAEjC,WAAO,KAAK,KAAI,SAAA,SAAA,CAAA,GACX,OAAO,GAAA,EACV,OAAO,KAAK,eAAe,QAAQ,UAAU,QAAQ,YAAY,GACjE,QAAQ,QAAQ,IAChB,WAAU,CAAA,CAAA;EAEd;AAEO,EAAAA,aAAA,UAAA,aAAP,SAAiD,IAIJ;AAH3C,QAAA,KAAE,GAAA,IACF,OAAI,GAAA,MACD,UAAO,OAAA,IAHqC,CAAA,MAAA,MAAA,CAIhD;AACC,WAAO,KAAK,MAAM,OAAO,OAAO,SAAS;MACvC,QAAQ,MAAM;MACd,QAAQ;KACT,CAAC;EACJ;AAEO,EAAAA,aAAA,UAAA,gBAAP,SAAoD,IAMJ;AAL9C,QAAA,KAAE,GAAA,IACF,OAAI,GAAA,MACJ,WAAQ,GAAA,UACR,eAAY,GAAA,cACT,UAAO,OAAA,IALwC,CAAA,MAAA,QAAA,YAAA,cAAA,CAMnD;AACC,WAAO,KAAK,MAAM,OAAO,OAAO,SAAS;MACvC,OAAO,KAAK,eAAe,UAAU,YAAY;MACjD,QAAQ;MACR,QAAQ;KACT,CAAC;EACJ;AAEO,EAAAA,aAAA,UAAA,cAAP,SACE,SACA,QAAmD;AAEnD,WAAO,KAAK,MAAM;MAChB,QAAM,SAAC,OAAK;AACV,YAAM,QAAQ,MAAM,UAA6B,OAAO;AACxD,YAAM,OAAO,OAAO,KAAK;AACzB,YAAI,SAAS,UAAU,SAAS;AAAM,iBAAO;AAC7C,cAAM,WAAU,SAAA,SAAA,CAAA,GAAyB,OAAO,GAAA,EAAE,KAAI,CAAA,CAAA;AACtD,eAAO;MACT;KACD;EACH;AAEO,EAAAA,aAAA,UAAA,iBAAP,SACE,SACA,QAAmD;AAEnD,WAAO,KAAK,MAAM;MAChB,QAAM,SAAC,OAAK;AACV,YAAM,QAAQ,MAAM,aAAgC,OAAO;AAC3D,YAAM,OAAO,OAAO,KAAK;AACzB,YAAI,SAAS,UAAU,SAAS;AAAM,iBAAO;AAC7C,cAAM,cAAa,SAAA,SAAA,CAAA,GAAyB,OAAO,GAAA,EAAE,KAAI,CAAA,CAAA;AACzD,eAAO;MACT;KACD;EACH;AACF,SAAAA;AAAA,EAvMA;;;ACVM,IAAWC;AAAjB,0BAAiBA,QAAK;AA0GtB,GA1GiBA,WAAAA,SAAK,CAAA,EAAA;;;ACoBtB,IAAA,oBAAA,SAAA,QAAA;AAAuC,YAAAC,oBAAA,MAAA;AACrC,WAAAA,mBACkB,SACA,MACA,OACA,WAA+B;;AAJjD,QAAA,QAOE,OAAA,KAAA,MAAM,OAAO,KAAC;AANE,UAAA,UAAA;AACA,UAAA,OAAA;AACA,UAAA,QAAA;AACA,UAAA,YAAA;AAKhB,QAAI,MAAM,QAAQ,MAAK,IAAI,GAAG;AAC5B,YAAK,UAAU,MAAK;AACpB,eAAS,IAAI,MAAK,KAAK,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AAC9C,cAAK,WAAO,KAAA,CAAA,GAAK,GAAC,MAAK,KAAK,CAAC,CAAC,IAAG,MAAK,SAAO;;WAE1C;AACL,YAAK,UAAU,MAAK;;AAKrB,UAAa,YAAYA,mBAAkB;;EAC9C;AAGF,SAAAA;AAAA,EAzBuC,KAAK;;;ACxB5C,IAAM,EAAE,UAAU,gBAAAC,gBAAc,IAAK,OAAO;AAC5C,IAAM,UAAU,SAAS,UAAU;AACnC,IAAM,sBAAsB,oBAAI,IAAG;AAK7B,SAAU,MAAM,GAAQ,GAAM;AAClC,MAAI;AACF,WAAO,MAAM,GAAG,CAAC;;AAEjB,wBAAoB,MAAK;;AAE7B;AAGA,IAAA,cAAe;AAEf,SAAS,MAAM,GAAQ,GAAM;AAE3B,MAAI,MAAM,GAAG;AACX,WAAO;;AAKT,QAAM,OAAO,SAAS,KAAK,CAAC;AAC5B,QAAM,OAAO,SAAS,KAAK,CAAC;AAK5B,MAAI,SAAS,MAAM;AACjB,WAAO;;AAGT,UAAQ,MAAM;IACZ,KAAK;AAGH,UAAI,EAAE,WAAW,EAAE;AAAQ,eAAO;IAEpC,KAAK,mBAAmB;AACtB,UAAI,mBAAmB,GAAG,CAAC;AAAG,eAAO;AAErC,YAAM,QAAQ,YAAY,CAAC;AAC3B,YAAM,QAAQ,YAAY,CAAC;AAI3B,YAAM,WAAW,MAAM;AACvB,UAAI,aAAa,MAAM;AAAQ,eAAO;AAGtC,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,YAAI,CAACA,gBAAe,KAAK,GAAG,MAAM,CAAC,CAAC,GAAG;AACrC,iBAAO;;;AAKX,eAAS,IAAI,GAAG,IAAI,UAAU,EAAE,GAAG;AACjC,cAAM,MAAM,MAAM,CAAC;AACnB,YAAI,CAAC,MAAM,EAAE,GAAG,GAAG,EAAE,GAAG,CAAC,GAAG;AAC1B,iBAAO;;;AAIX,aAAO;;IAGT,KAAK;AACH,aAAO,EAAE,SAAS,EAAE,QAAQ,EAAE,YAAY,EAAE;IAE9C,KAAK;AAEH,UAAI,MAAM;AAAG,eAAO,MAAM;IAE5B,KAAK;IACL,KAAK;AACH,aAAO,CAAC,MAAM,CAAC;IAEjB,KAAK;IACL,KAAK;AACH,aAAO,KAAK,GAAG,CAAC;IAElB,KAAK;IACL,KAAK,gBAAgB;AACnB,UAAI,EAAE,SAAS,EAAE;AAAM,eAAO;AAC9B,UAAI,mBAAmB,GAAG,CAAC;AAAG,eAAO;AAErC,YAAM,YAAY,EAAE,QAAO;AAC3B,YAAM,QAAQ,SAAS;AAEvB,aAAO,MAAM;AACX,cAAM,OAAO,UAAU,KAAI;AAC3B,YAAI,KAAK;AAAM;AAGf,cAAM,CAAC,MAAM,MAAM,IAAI,KAAK;AAG5B,YAAI,CAAC,EAAE,IAAI,IAAI,GAAG;AAChB,iBAAO;;AAKT,YAAI,SAAS,CAAC,MAAM,QAAQ,EAAE,IAAI,IAAI,CAAC,GAAG;AACxC,iBAAO;;;AAIX,aAAO;;IAGT,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK;AAGH,UAAI,IAAI,WAAW,CAAC;AACpB,UAAI,IAAI,WAAW,CAAC;IAEtB,KAAK,qBAAqB;AACxB,UAAI,MAAM,EAAE;AACZ,UAAI,QAAQ,EAAE,YAAY;AACxB,eAAO,SAAS,EAAE,GAAG,MAAM,EAAE,GAAG,GAAG;;;AAIrC,aAAO,QAAQ;;IAGjB,KAAK;IACL,KAAK;IACL,KAAK;IACL,KAAK,qBAAqB;AACxB,YAAM,QAAQ,QAAQ,KAAK,CAAC;AAC5B,UAAI,UAAU,QAAQ,KAAK,CAAC,GAAG;AAC7B,eAAO;;AA0BT,aAAO,CAAC,SAAS,OAAO,gBAAgB;;;AAK5C,SAAO;AACT;AAEA,SAAS,YAAoC,KAAY;AAGvD,SAAO,OAAO,KAAK,GAAG,EAAE,OAAO,cAAc,GAAG;AAClD;AACA,SAAS,aAEP,KAAkB;AAElB,SAAO,KAAK,GAAG,MAAM;AACvB;AAEA,IAAM,mBAAmB;AAEzB,SAAS,SAAS,MAAc,QAAc;AAC5C,QAAM,YAAY,KAAK,SAAS,OAAO;AACvC,SAAO,aAAa,KAClB,KAAK,QAAQ,QAAQ,SAAS,MAAM;AACxC;AAEA,SAAS,mBAAmB,GAAW,GAAS;AAS9C,MAAI,OAAO,oBAAoB,IAAI,CAAC;AACpC,MAAI,MAAM;AAGR,QAAI,KAAK,IAAI,CAAC;AAAG,aAAO;SACnB;AACL,wBAAoB,IAAI,GAAG,OAAO,oBAAI,KAAG;;AAE3C,OAAK,IAAI,CAAC;AACV,SAAO;AACT;;;AC3LE,IAAgB,SACd,OAAO,UAAS;AAEd,SAAU,UAAU,OAAU;AAClC,SAAO,UAAU,QAAQ,UAAU;AACrC;AAIM,SAAU,wBACd,IACA,SAA0B;MADxB,aAAU,GAAA,YAAE,KAAE,GAAA,IAAE,MAAG,GAAA;AAGrB,MAAI,OAAO,eAAe,UAAU;AAClC,QAAI,SAAS;AACX,cAAQ,YACN,CAAC,UAAU,EAAE,IAAI,EAAE,GAAE,IACrB,CAAC,UAAU,GAAG,IAAI,EAAE,IAAG,IACvB;;AAIJ,QAAI,UAAU,EAAE,KAAK,CAAC,UAAU,GAAG,GAAG;AACpC,WAAK;;AAGP,QAAI,CAAC,UAAU,EAAE,GAAG;AAClB,aAAO,GAAA,OAAG,YAAU,GAAA,EAAA,OAClB,OAAO,OAAO,YACd,OAAO,OAAO,WACZ,KAAK,KAAK,UAAU,EAAE,CAAC;;;AAGjC;AAEA,IAAM,gBAAgB;EACpB,kBAAkB;EAClB,aAAa;EACb,eAAe;EAGf,iBAAiB;;AAGb,SAAU,gBAAgB,QAA2B;AACzD,SAAO,QAAQ,eAAe,MAAM;AACtC;AAEM,SAAU,sBACd,QAAoD;AAEpD,MAAM,QAAQ,OAAO;AACrB,SAAO,UAAU,SAAS,cAAc,kBAAkB;AAC5D;AAEM,SAAU,2BACd,OACA,mBAA0C;AAE1C,SAAO,YAAY,iBAAiB,IAChC,MAAM,IAAI,kBAAkB,OAAO,YAAY,IAC/C,qBAAqB,kBAAkB;AAC7C;AAEO,IAAM,wBAAwB;AAE/B,SAAU,uBAAuB,gBAAsB;AAC3D,MAAM,QAAQ,eAAe,MAAM,qBAAqB;AACxD,SAAO,QAAQ,MAAM,CAAC,IAAI;AAC5B;AAEM,SAAU,0BACd,cACA,QACA,WAA+B;AAE/B,MAAI,gBAAgB,MAAM,GAAG;AAC3B,WAAO,QAAQ,MAAM,IACjB,OAAO,MAAM,SAAA,MAAI;AAAI,aAAA,0BAA0B,cAAc,MAAM,SAAS;IAAvD,CAAwD,IAC7E,aAAa,WAAW,MAAM,SAAA,OAAK;AACnC,UAAI,QAAQ,KAAK,KAAK,cAAc,OAAO,SAAS,GAAG;AACrD,YAAM,MAAM,uBAAuB,KAAK;AACxC,eAAO,OAAO,KAAK,QAAQ,GAAG,MAC3B,CAAC,MAAM,gBACP,0BAA0B,MAAM,cAAc,OAAO,GAAG,GAAG,SAAS;;AAOzE,aAAO;IACT,CAAC;;AAEL,SAAO;AACT;AAEM,SAAU,wBACd,OAAiB;AAEjB,SAAO,gBAAgB,KAAK,KAC1B,CAAC,YAAY,KAAK,KAClB,CAAC,QAAQ,KAAK;AAClB;AAEM,SAAU,4BAAyB;AACvC,SAAO,IAAI;AACb;AAEM,SAAU,uBACd,UACA,WAA+B;AAO/B,MAAM,cAAc,kBAAkB,uBAAuB,QAAQ,CAAC;AACtE,SAAO;IACL;IACA,gBAAc,SAAC,MAAI;AACjB,UAAI,MAAqC,YAAY,IAAI;AACzD,UAAI,CAAC,OAAO,WAAW;AACrB,cAAM,UAAU,OAAO,IAAI;;AAE7B,aAAO,OAAO;IAChB;;AAEJ;;;AC7HA,IAAM,SAAyB,uBAAO,OAAO,IAAI;AACjD,IAAM,cAA6B,WAAA;AAAM,SAAA;AAAA;AACzC,IAAM,aAAiC,uBAAO,OAAO,IAAI;AAEzD,IAAA,cAAA,WAAA;AAGE,WAAAC,aACkB,UACA,OAAiB;AAFnC,QAAA,QAAA;AACkB,SAAA,WAAA;AACA,SAAA,QAAA;AAJR,SAAA,OAA8B,uBAAO,OAAO,IAAI;AAqUlD,SAAA,UAEJ,uBAAO,OAAO,IAAI;AA0Dd,SAAA,OAEJ,uBAAO,OAAO,IAAI;AA6Cf,SAAA,gBAAgB,SACrB,mBACA,gBAAsB;AACnB,aAAA,gBACH,YAAY,iBAAiB,IACzB,MAAK,IAAI,kBAAkB,OAAO,cAAc,IAChD,qBAAqB,kBAAkB,cAAc,CAAC;IAHvD;AASE,SAAA,UAA2B,SAAA,UAAQ;AACxC,aAAO,YAAY,QAAQ,IACvB,MAAK,IAAI,SAAS,KAAK,IACvB,OAAO,aAAa;IAC1B;AAMO,SAAA,cAAmC,SACxC,cACA,gBAAc;AAEd,UAAI,OAAO,iBAAiB,UAAU;AACpC,eAAO,cAAc,YAAY;;AAGnC,UAAI,YAAY,YAAY,GAAG;AAC7B,eAAO;;AAGF,UAAA,KAAM,MAAK,SAAS,SAAS,YAAY,EAAC,CAAA;AAEjD,UAAI,IAAI;AACN,YAAM,MAAM,cAAc,EAAE;AAC5B,YAAI,gBAAgB;AAClB,gBAAK,MAAM,IAAI,YAAY;;AAE7B,eAAO;;IAEX;EAtdG;AAaI,EAAAA,aAAA,UAAA,WAAP,WAAA;AACE,WAAA,SAAA,CAAA,GAAY,KAAK,IAAI;EACvB;AAEO,EAAAA,aAAA,UAAA,MAAP,SAAW,QAAc;AACvB,WAAO,KAAK,OAAO,QAAQ,IAAI,MAAM;EACvC;AAEO,EAAAA,aAAA,UAAA,MAAP,SAAW,QAAgB,WAAiB;AAC1C,SAAK,MAAM,OAAO,QAAQ,SAAS;AACnC,QAAI,OAAO,KAAK,KAAK,MAAM,MAAM,GAAG;AAClC,UAAM,cAAc,KAAK,KAAK,MAAM;AACpC,UAAI,eAAe,OAAO,KAAK,aAAa,SAAS,GAAG;AACtD,eAAO,YAAY,SAAS;;;AAGhC,QAAI,cAAc,gBACd,OAAO,KAAK,KAAK,SAAS,mBAAmB,MAAM,GAAG;AACxD,aAAO,KAAK,SAAS,kBAAkB,MAAM;;AAE/C,QAAI,gBAAgB,OAAO;AACzB,aAAO,KAAK,OAAO,IAAI,QAAQ,SAAS;;EAE5C;AAEU,EAAAA,aAAA,UAAA,SAAV,SAAiB,QAAgB,mBAA2B;AAM1D,QAAI;AAAmB,WAAK,MAAM,OAAO,QAAQ,UAAU;AAE3D,QAAI,OAAO,KAAK,KAAK,MAAM,MAAM,GAAG;AAClC,aAAO,KAAK,KAAK,MAAM;;AAGzB,QAAI,gBAAgB,OAAO;AACzB,aAAO,KAAK,OAAO,OAAO,QAAQ,iBAAiB;;AAGrD,QAAI,KAAK,SAAS,kBAAkB,MAAM,GAAG;AAC3C,aAAO,uBAAO,OAAO,IAAI;;EAE7B;AAEO,EAAAA,aAAA,UAAA,QAAP,SACE,OACA,OAA2B;AAF7B,QAAA,QAAA;AAIE,QAAI;AAGJ,QAAI,YAAY,KAAK;AAAG,cAAQ,MAAM;AACtC,QAAI,YAAY,KAAK;AAAG,cAAQ,MAAM;AAEtC,QAAM,WACJ,OAAO,UAAU,WACb,KAAK,OAAO,SAAS,KAAK,IAC1B;AAEN,QAAM,WACJ,OAAO,UAAU,WACb,KAAK,OAAO,SAAS,KAAK,IAC1B;AAIN,QAAI,CAAC;AAAU;AAEf,cACE,OAAO,WAAW,UAClB,CAAA;AAGF,QAAM,SACJ,IAAI,WAAW,qBAAqB,EAAE,MAAM,UAAU,QAAQ;AAIhE,SAAK,KAAK,MAAM,IAAI;AAEpB,QAAI,WAAW,UAAU;AACvB,aAAO,KAAK,KAAK,MAAM;AACvB,UAAI,KAAK,MAAM,SAAS;AACtB,YAAM,kBAAmC,uBAAO,OAAO,IAAI;AAK3D,YAAI,CAAC;AAAU,0BAAc,WAAW;AAIxC,eAAO,KAAK,QAAQ,EAAE,QAAQ,SAAA,gBAAc;AAC1C,cAAI,CAAC,YAAY,SAAS,cAAc,MAAM,OAAO,cAAc,GAAG;AAGpE,4BAAc,cAAc,IAAI;AAShC,gBAAM,YAAY,uBAAuB,cAAc;AACvD,gBAAI,cAAc,kBACd,CAAC,MAAK,SAAS,WAAW,OAAO,YAAY,SAAS,GAAG;AAC3D,8BAAc,SAAS,IAAI;;AAM7B,gBAAI,OAAO,cAAc,MAAM,UAAU,EAAE,iBAAgB,QAAQ;AACjE,qBAAO,OAAO,cAAc;;;QAGlC,CAAC;AAED,YAAI,gBAAc,cACd,EAAE,YAAY,SAAS,eAKvB,KAAK,SAAS,kBAAkB,MAAM,MAAM,OAAO,YAAY;AACjE,iBAAO,gBAAc;;AAGvB,eAAO,KAAK,eAAa,EAAE,QACzB,SAAA,WAAS;AAAI,iBAAA,MAAK,MAAM,MAAM,QAAkB,SAAS;QAA5C,CAA6C;;;EAGlE;AAEO,EAAAA,aAAA,UAAA,SAAP,SACE,QACA,QAAsD;AAFxD,QAAA,QAAA;AAIE,QAAM,cAAc,KAAK,OAAO,MAAM;AAEtC,QAAI,aAAa;AACf,UAAM,kBAAqC,uBAAO,OAAO,IAAI;AAC7D,UAAI,gBAAc;AAClB,UAAI,eAAa;AAEjB,UAAM,kBAAgB;QACpB;QACA;QACA;QACA,aAAa,KAAK;QAClB,SAAS,KAAK;QACd,WAAW,SACT,oBACA,MAA8B;AAC3B,iBAAA,MAAK,SAAS,UACjB,OAAO,uBAAuB,WAAW;YACvC,WAAW;YACX,MAAM,QAAQ,cAAc,MAAM;cAChC,oBACJ,EAAE,OAAO,MAAI,CAAE;QALZ;;AASP,aAAO,KAAK,WAAW,EAAE,QAAQ,SAAA,gBAAc;AAC7C,YAAM,YAAY,uBAAuB,cAAc;AACvD,YAAI,aAAa,YAAY,cAAc;AAC3C,YAAI,eAAe;AAAQ;AAC3B,YAAM,SAA2C,OAAO,WAAW,aAC/D,SACA,OAAO,cAAc,KAAK,OAAO,SAAS;AAC9C,YAAI,QAAQ;AACV,cAAI,WAAW,WAAW,cAAc,SACtC,OAAO,gBAAgB,UAAU,GAAC,SAAA,SAAA,CAAA,GAC7B,eAAa,GAAA,EAChB,WACA,gBACA,SAAS,MAAK,WAAW,QAAQ,cAAc,EAAC,CAAA,CAAA;AAEpD,cAAI,aAAa,YAAY;AAC3B,kBAAK,MAAM,MAAM,QAAQ,cAAc;iBAClC;AACL,gBAAI,aAAa;AAAQ,yBAAW;AACpC,gBAAI,aAAa,YAAY;AAC3B,8BAAc,cAAc,IAAI;AAChC,8BAAc;AACd,2BAAa;;;;AAInB,YAAI,eAAe,QAAQ;AACzB,yBAAa;;MAEjB,CAAC;AAED,UAAI,eAAa;AACf,aAAK,MAAM,QAAQ,eAAa;AAEhC,YAAI,cAAY;AACd,cAAI,gBAAgB,OAAO;AACzB,iBAAK,KAAK,MAAM,IAAI;iBACf;AACL,mBAAO,KAAK,KAAK,MAAM;;AAEzB,eAAK,MAAM,MAAM,QAAQ,UAAU;;AAGrC,eAAO;;;AAIX,WAAO;EACT;AAQO,EAAAA,aAAA,UAAA,SAAP,SACE,QACA,WACA,MAA0B;;AAE1B,QAAM,cAAc,KAAK,OAAO,MAAM;AACtC,QAAI,aAAa;AACf,UAAM,WAAW,KAAK,cAAsB,aAAa,YAAY;AACrE,UAAM,iBAAiB,aAAa,OAChC,KAAK,SAAS,kBAAkB,EAAE,UAAU,WAAW,KAAI,CAAE,IAC7D;AACJ,aAAO,KAAK,OAAO,QAAQ,kBAAgB,KAAA,CAAA,GACzC,GAAC,cAAc,IAAG,mBAChB,WAAW;;AAEjB,WAAO;EACT;AAEO,EAAAA,aAAA,UAAA,QAAP,SACE,SACA,OAAkB;AAElB,QAAI,UAAU;AACd,QAAI,QAAQ,IAAI;AACd,UAAI,OAAO,KAAK,KAAK,MAAM,QAAQ,EAAE,GAAG;AACtC,kBAAU,KAAK,OAAO,QAAQ,IAAI,QAAQ,WAAW,QAAQ,IAAI;;AAEnE,UAAI,gBAAgB,SAAS,SAAS,OAAO;AAC3C,kBAAU,KAAK,OAAO,MAAM,SAAS,KAAK,KAAK;;AAMjD,UAAI,QAAQ,aAAa,SAAS;AAChC,aAAK,MAAM,MAAM,QAAQ,IAAI,QAAQ,aAAa,UAAU;;;AAGhE,WAAO;EACT;AAEO,EAAAA,aAAA,UAAA,QAAP,WAAA;AACE,SAAK,QAAQ,IAAI;EACnB;AAEO,EAAAA,aAAA,UAAA,UAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAM,MAAM,KAAK,SAAQ;AACzB,QAAM,eAAyB,CAAA;AAC/B,SAAK,aAAY,EAAG,QAAQ,SAAA,IAAE;AAC5B,UAAI,CAAC,OAAO,KAAK,MAAK,SAAS,mBAAmB,EAAE,GAAG;AACrD,qBAAa,KAAK,EAAE;;IAExB,CAAC;AACD,QAAI,aAAa,QAAQ;AACvB,UAAI,SAAS,EAAE,cAAc,aAAa,KAAI,EAAE;;AAElD,WAAO;EACT;AAEO,EAAAA,aAAA,UAAA,UAAP,SAAe,SAAqC;AAApD,QAAA,QAAA;AACE,WAAO,KAAK,KAAK,IAAI,EAAE,QAAQ,SAAA,QAAM;AACnC,UAAI,EAAE,WAAW,OAAO,KAAK,SAAS,MAAM,IAAI;AAC9C,cAAK,OAAO,MAAM;;IAEtB,CAAC;AACD,QAAI,SAAS;AACH,UAAA,SAAoB,QAAO,QAAhB,SAAI,OAAK,SAAtB,CAAA,QAAA,CAAmB;AACzB,aAAO,KAAK,MAAI,EAAE,QAAQ,SAAA,QAAM;AAC9B,cAAK,MAAM,QAAQ,OAAK,MAAM,CAAgB;MAChD,CAAC;AACD,UAAI,QAAQ;AACV,eAAO,aAAa,QAAQ,KAAK,QAAQ,IAAI;;;EAGnD;AAcO,EAAAA,aAAA,UAAA,SAAP,SAAc,QAAc;AAC1B,WAAO,KAAK,QAAQ,MAAM,KAAK,KAAK,QAAQ,MAAM,KAAK,KAAK;EAC9D;AAEO,EAAAA,aAAA,UAAA,UAAP,SAAe,QAAc;AAC3B,QAAI,KAAK,QAAQ,MAAM,IAAI,GAAG;AAC5B,UAAM,QAAQ,EAAE,KAAK,QAAQ,MAAM;AACnC,UAAI,CAAC;AAAO,eAAO,KAAK,QAAQ,MAAM;AACtC,aAAO;;AAET,WAAO;EACT;AAIO,EAAAA,aAAA,UAAA,eAAP,SAAoB,KAAuB;AAAvB,QAAA,QAAA,QAAA;AAAA,YAAA,oBAAU,IAAG;IAAU;AACzC,WAAO,KAAK,KAAK,OAAO,EAAE,QAAQ,IAAI,KAAK,GAAG;AAC9C,QAAI,gBAAgB,OAAO;AACzB,WAAK,OAAO,aAAa,GAAG;WACvB;AAIL,aAAO,KAAK,KAAK,SAAS,iBAAiB,EAAE,QAAQ,IAAI,KAAK,GAAG;;AAEnE,WAAO;EACT;AAMO,EAAAA,aAAA,UAAA,KAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAM,MAAM,KAAK,aAAY;AAC7B,QAAM,WAAW,KAAK,SAAQ;AAC9B,QAAI,QAAQ,SAAA,IAAE;AACZ,UAAI,OAAO,KAAK,UAAU,EAAE,GAAG;AAI7B,eAAO,KAAK,MAAK,gBAAgB,EAAE,CAAC,EAAE,QAAQ,IAAI,KAAK,GAAG;AAG1D,eAAO,SAAS,EAAE;;IAEtB,CAAC;AACD,QAAM,cAAc,OAAO,KAAK,QAAQ;AACxC,QAAI,YAAY,QAAQ;AACtB,UAAI,SAAoB;AACxB,aAAO,kBAAgB;AAAO,iBAAO,OAAK;AAC1C,kBAAY,QAAQ,SAAA,IAAE;AAAI,eAAA,OAAK,OAAO,EAAE;MAAd,CAAe;;AAE3C,WAAO;EACT;AAOO,EAAAA,aAAA,UAAA,kBAAP,SAAuB,QAAc;AACnC,QAAI,CAAC,OAAO,KAAK,KAAK,MAAM,MAAM,GAAG;AACnC,UAAM,UAAQ,KAAK,KAAK,MAAM,IAAI,uBAAO,OAAO,IAAI;AACpD,UAAM,OAAO,KAAK,KAAK,MAAM;AAC7B,UAAI,CAAC;AAAM,eAAO;AAElB,UAAM,YAAU,oBAAI,IAAkC,CAAC,IAAI,CAAC;AAG5D,gBAAQ,QAAQ,SAAA,KAAG;AACjB,YAAI,YAAY,GAAG,GAAG;AACpB,kBAAM,IAAI,KAAK,IAAI;;AASrB,YAAI,gBAAgB,GAAG,GAAG;AACxB,iBAAO,KAAK,GAAG,EAAE,QAAQ,SAAA,KAAG;AAC1B,gBAAM,QAAQ,IAAI,GAAG;AAGrB,gBAAI,gBAAgB,KAAK,GAAG;AAC1B,wBAAQ,IAAI,KAAK;;UAErB,CAAC;;MAEL,CAAC;;AAEH,WAAO,KAAK,KAAK,MAAM;EACzB;AAIO,EAAAA,aAAA,UAAA,eAAP,WAAA;AACE,WAAO,KAAK,MAAM,SAAS,YAAY,SAAS;EAClD;AAgDF,SAAAA;AAAA,EA7dA;AA8eA,IAAA,aAAA,WAAA;AAOE,WAAAC,YACkB,SACR,QAAgC;AAAhC,QAAA,WAAA,QAAA;AAAA,eAAA;IAAgC;AADxB,SAAA,UAAA;AACR,SAAA,SAAA;AARF,SAAA,IAAiD;AAUvD,SAAK,aAAY;EACnB;AAEO,EAAAA,YAAA,UAAA,eAAP,WAAA;AACE,SAAK,IAAI,KAAK,UAAU,IAAG,IAAa;AACxC,SAAK,WAAW,IAAI,KAAK,aAAa;EACxC;AAEO,EAAAA,YAAA,UAAA,SAAP,SAAc,QAAgB,gBAAsB;AAClD,QAAI,KAAK,GAAG;AACV,WAAK,EAAE,WAAW,QAAQ,cAAc,CAAC;AACzC,UAAM,YAAY,uBAAuB,cAAc;AACvD,UAAI,cAAc,gBAAgB;AAMhC,aAAK,EAAE,WAAW,QAAQ,SAAS,CAAC;;AAEtC,UAAI,KAAK,QAAQ;AACf,aAAK,OAAO,OAAO,QAAQ,cAAc;;;EAG/C;AAEO,EAAAA,YAAA,UAAA,QAAP,SAAa,QAAgB,gBAAsB;AACjD,QAAI,KAAK,GAAG;AACV,WAAK,EAAE,MACL,WAAW,QAAQ,cAAc,GAQjC,mBAAmB,aAAa,WAAW,UAAU;;EAG3D;AACF,SAAAA;AAAA,EApDA;AAsDA,SAAS,WAAW,QAAgB,gBAAsB;AAIxD,SAAO,iBAAiB,MAAM;AAChC;AAEM,SAAU,+BACd,OACA,UAAgB;AAEhB,MAAI,sBAAsB,KAAK,GAAG;AAShC,UAAM,MAAM,OAAO,UAAU,UAAU;;AAE3C;CAEA,SAAiBC,cAAW;AAE1B,MAAA,OAAA,SAAA,QAAA;AAA0B,cAAAC,OAAA,MAAA;AACxB,aAAAA,MAAY,IAQX;UAPC,WAAQ,GAAA,UACR,KAAA,GAAA,eAAA,gBAAa,OAAA,SAAG,OAAI,IACpB,OAAI,GAAA;AAHN,UAAA,QASE,OAAA,KAAA,MAAM,UAAU,IAAI,WAAW,aAAa,CAAC,KAAC;AAIhC,YAAA,QAAQ,IAAI,MAAM,KAAI;AAiBtB,YAAA,cAAc,IAAI,KAAkB,aAAa;AApB/D,UAAI;AAAM,cAAK,QAAQ,IAAI;;IAC7B;AAIO,IAAAA,MAAA,UAAA,WAAP,SACE,SACA,QAAmC;AAKnC,aAAO,KAAK,MAAM,SAAS,SAAS,MAAM;IAC5C;AAEO,IAAAA,MAAA,UAAA,cAAP,WAAA;AAEE,aAAO;IACT;AAGO,IAAAA,MAAA,UAAA,aAAP,WAAA;AACE,aAAO,KAAK,YAAY,YAAY,SAAS;IAC/C;AACF,WAAAA;EAAA,EAnC0BD,YAAW;AAAxB,EAAAA,aAAA,OAAI;AAoCnB,GAtCiB,gBAAA,cAAW,CAAA,EAAA;AA0C5B,IAAA,QAAA,SAAA,QAAA;AAAoB,YAAAE,QAAA,MAAA;AAClB,WAAAA,OACkB,IACA,QACA,QACA,OAAiB;AAJnC,QAAA,QAME,OAAA,KAAA,MAAM,OAAO,UAAU,KAAK,KAAC;AALb,UAAA,KAAA;AACA,UAAA,SAAA;AACA,UAAA,SAAA;AACA,UAAA,QAAA;AAGhB,WAAO,KAAI;;EACb;AAEO,EAAAA,OAAA,UAAA,WAAP,SACE,SACA,QAAmC;AAEnC,WAAO,IAAIA,OAAM,SAAS,MAAM,QAAQ,KAAK,KAAK;EACpD;AAEO,EAAAA,OAAA,UAAA,cAAP,SAAmB,SAAe;AAAlC,QAAA,QAAA;AAEE,QAAM,SAAS,KAAK,OAAO,YAAY,OAAO;AAE9C,QAAI,YAAY,KAAK,IAAI;AACvB,UAAI,KAAK,MAAM,SAAS;AAKtB,eAAO,KAAK,KAAK,IAAI,EAAE,QAAQ,SAAA,QAAM;AACnC,cAAM,iBAAiB,MAAK,KAAK,MAAM;AACvC,cAAM,oBAAoB,OAAO,QAAQ,EAAE,MAAM;AACjD,cAAI,CAAC,mBAAmB;AAMtB,kBAAK,OAAO,MAAM;qBACT,CAAC,gBAAgB;AAK1B,kBAAK,MAAM,MAAM,QAAQ,UAAU;AACnC,mBAAO,KAAK,iBAAiB,EAAE,QAAQ,SAAA,gBAAc;AACnD,oBAAK,MAAM,MAAM,QAAQ,cAAc;YACzC,CAAC;qBACQ,mBAAmB,mBAAmB;AAI/C,mBAAO,KAAK,cAAc,EAAE,QAAQ,SAAA,gBAAc;AAChD,kBAAI,CAAC,MAAM,eAAe,cAAc,GAC7B,kBAAkB,cAAc,CAAC,GAAG;AAC7C,sBAAK,MAAM,MAAM,QAAQ,cAAc;;YAE3C,CAAC;;QAEL,CAAC;;AAGH,aAAO;;AAIT,QAAI,WAAW,KAAK;AAAQ,aAAO;AAGnC,WAAO,OAAO,SAAS,KAAK,IAAI,KAAK,MAAM;EAC7C;AAEO,EAAAA,OAAA,UAAA,WAAP,WAAA;AACE,WAAA,SAAA,SAAA,CAAA,GACK,KAAK,OAAO,SAAQ,CAAE,GACtB,KAAK,IAAI;EAEhB;AAEO,EAAAA,OAAA,UAAA,kBAAP,SAAuB,QAAc;AACnC,QAAM,aAAa,KAAK,OAAO,gBAAgB,MAAM;AACrD,WAAO,OAAO,KAAK,KAAK,MAAM,MAAM,IAAG,SAAA,SAAA,CAAA,GAClC,UAAU,GACV,OAAA,UAAM,gBAAe,KAAA,MAAC,MAAM,CAAC,IAC9B;EACN;AAEO,EAAAA,OAAA,UAAA,aAAP,WAAA;AACE,QAAI,IAAiB,KAAK;AAC1B,WAAQ,EAAY;AAAQ,UAAK,EAAY;AAC7C,WAAO,EAAE,WAAW,MAAM,GAAG,SAAS;EACxC;AACF,SAAAA;AAAA,EA3FoB,WAAW;AAiG/B,IAAA,QAAA,SAAA,QAAA;AAAoB,YAAAC,QAAA,MAAA;AAClB,WAAAA,OAAY,MAAsB;WAChC,OAAA,KAAA,MACE,qBACA,MACA,WAAA;IAAO,GACP,IAAI,WAAW,KAAK,MAAM,SAAS,KAAK,KAAK,CAAC,KAC/C;EACH;AAEO,EAAAA,OAAA,UAAA,cAAP,WAAA;AAEE,WAAO;EACT;AAEO,EAAAA,OAAA,UAAA,QAAP,WAAA;AAME,WAAO,KAAK,OAAO,MAAM,MAAM,KAAK,QAAQ,SAAS;EACvD;AACF,SAAAA;AAAA,EAvBoB,KAAK;AAyBzB,SAAS,sBACP,gBACA,gBACA,UAAgB;AAEhB,MAAM,gBAAgB,eAAe,QAAQ;AAC7C,MAAM,gBAAgB,eAAe,QAAQ;AAM7C,SAAO,MAAM,eAAe,aAAa,IAAI,gBAAgB;AAC/D;AAEM,SAAU,sBAAsB,OAAU;AAE9C,SAAO,CAAC,EAAE,iBAAiB,eAAe,MAAM,MAAM;AACxD;;;AChxBA,SAAS,YAAe,OAAQ;AAC9B,MAAI,gBAAgB,KAAK,GAAG;AAC1B,WAAO,QAAQ,KAAK,IAChB,MAAM,MAAM,CAAC,IACd,SAAA,EAAG,WAAW,OAAO,eAAe,KAAK,EAAC,GAAK,KAAK;;AAEzD,SAAO;AACT;AAyDA,IAAA,cAAA,WAAA;AAAA,WAAAC,eAAA;AAGU,SAAA,QAAQ,KAAK,gBAAgB,UAAU,KAAI;AAG3C,SAAA,OAAO,IAAI,KAIhB,aAAa;AAQR,SAAA,SAAS,oBAAI,QAAO;AAiGpB,SAAA,aAAa,oBAAI,IAAG;AAGZ,SAAA,QAAQ,KAAK,MAAM,CAAA,CAAE;EACvC;AA3GS,EAAAA,aAAA,UAAA,UAAP,SAAe,OAAU;AACvB,WAAO,gBAAgB,KAAK,KAAK,KAAK,MAAM,IAAI,KAAK;EACvD;AAMO,EAAAA,aAAA,UAAA,OAAP,SAAY,OAAU;AACpB,QAAI,gBAAgB,KAAK,GAAG;AAC1B,UAAM,OAAO,YAAY,KAAK;AAC9B,WAAK,OAAO,IAAI,MAAM,KAAK;AAC3B,aAAO;;AAET,WAAO;EACT;AAIO,EAAAA,aAAA,UAAA,QAAP,SAAa,OAAU;AAAvB,QAAA,QAAA;AACE,QAAI,gBAAgB,KAAK,GAAG;AAC1B,UAAM,WAAW,KAAK,OAAO,IAAI,KAAK;AACtC,UAAI;AAAU,eAAO;AAErB,UAAM,QAAQ,OAAO,eAAe,KAAK;AACzC,cAAQ,OAAO;QACb,KAAK,MAAM,WAAW;AACpB,cAAI,KAAK,MAAM,IAAI,KAAK;AAAG,mBAAO;AAClC,cAAM,QAAgB,MAAgB,IAAI,KAAK,OAAO,IAAI;AAI1D,cAAM,OAAO,KAAK,KAAK,YAAY,KAAK;AACxC,cAAI,CAAC,KAAK,OAAO;AACf,iBAAK,MAAM,IAAI,KAAK,QAAQ,KAAK;AAIjC,gBAAI,WAAS,YAAA,OAAA;AACX,qBAAO,OAAO,KAAK;;;AAGvB,iBAAO,KAAK;;QAGd,KAAK;QACL,KAAK,OAAO,WAAW;AACrB,cAAI,KAAK,MAAM,IAAI,KAAK;AAAG,mBAAO;AAClC,cAAM,UAAQ,OAAO,eAAe,KAAK;AACzC,cAAM,UAAQ,CAAC,OAAK;AACpB,cAAM,OAAO,KAAK,WAAW,KAAK;AAClC,kBAAM,KAAK,KAAK,IAAI;AACpB,cAAM,oBAAkB,QAAM;AAC9B,eAAK,OAAO,QAAQ,SAAA,KAAG;AACrB,oBAAM,KAAK,MAAK,MAAO,MAAc,GAAG,CAAC,CAAC;UAC5C,CAAC;AASD,cAAM,OAAO,KAAK,KAAK,YAAY,OAAK;AACxC,cAAI,CAAC,KAAK,QAAQ;AAChB,gBAAM,QAAM,KAAK,SAAS,OAAO,OAAO,OAAK;AAC7C,iBAAK,MAAM,IAAI,KAAG;AAClB,iBAAK,OAAO,QAAQ,SAAC,KAAK,GAAC;AACzB,oBAAI,GAAG,IAAI,QAAM,oBAAkB,CAAC;YACtC,CAAC;AAID,gBAAI,WAAS,YAAA,OAAA;AACX,qBAAO,OAAO,KAAG;;;AAGrB,iBAAO,KAAK;;;;AAIlB,WAAO;EACT;AAMQ,EAAAA,aAAA,UAAA,aAAR,SAAmB,KAAW;AAC5B,QAAM,OAAO,OAAO,KAAK,GAAG;AAC5B,QAAM,OAAO,KAAK,KAAK,YAAY,IAAI;AACvC,QAAI,CAAC,KAAK,MAAM;AACd,WAAK,KAAI;AACT,UAAM,OAAO,KAAK,UAAU,IAAI;AAChC,UAAI,EAAE,KAAK,OAAO,KAAK,WAAW,IAAI,IAAI,IAAI;AAC5C,aAAK,WAAW,IAAI,MAAM,KAAK,OAAO,EAAE,QAAQ,MAAM,KAAI,CAAE;;;AAGhE,WAAO,KAAK;EACd;AAOF,SAAAA;AAAA,EAvHA;AAiIO,IAAM,qBAAqB,OAAO,OAAO,SAAU,OAAU;AAClE,MAAI,gBAAgB,KAAK,GAAG;AAC1B,QAAI,mBAAmB,QAAQ;AAC7B,8BAAuB;;AAEzB,QAAM,YAAY,eAAe,MAAM,KAAK;AAC5C,QAAI,OAAO,eAAe,IAAI,SAAS;AACvC,QAAI,SAAS,QAAQ;AACnB,qBAAe,IACb,WACA,OAAO,KAAK,UAAU,SAAS,CAAC;;AAGpC,WAAO;;AAET,SAAO,KAAK,UAAU,KAAK;AAC7B,GAAG;EACD,OAAO;CACR;AAGD,IAAI;AACJ,IAAI;AAEJ,SAAS,0BAAuB;AAC9B,mBAAiB,IAAI;AACrB,mBAAiB,KAAK,gBAAgB,UAAU,KAAI;AACtD;;;ACpIA,SAAS,wBACP,SAAgC;AAEhC,SAAO;IACL,QAAQ;IACR,QAAQ;IACR,QAAQ;IAGR,QAAQ,QAAQ;;AAEpB;AAEA,IAAA,cAAA,WAAA;AA+BE,WAAAC,aAAY,QAAyB;AAArC,QAAA,QAAA;AATQ,SAAA,eAAe,KACrB,gBAAgB,UAAU,KAC3B;AAQC,SAAK,SAAS,QAAQ,QAAQ;MAC5B,aAAa,OAAO,gBAAgB;MACpC,iBAAiB,sBAAsB,MAAM;KAC9C;AAED,SAAK,QAAQ,OAAO,SAAS,IAAI;AAEjC,SAAK,sBAAsB,KAAK,SAAA,SAAO;;AAC7B,UAAA,kBAAoB,QAAQ,QAAO;AAE3C,UAAM,WAAW,wBAAwB,OAAO;AAIhD,eAAS,CAAC,IAAI,CAAC;AAEf,UAAM,SAAQ,KAAA,MAAK,qBAAoB,KAAI,MAAA,IAAI,QAAQ;AAEvD,UAAI,OAAO;AACT,YAAI,iBAAiB;AACnB,iBAAA,SAAA,SAAA,CAAA,GACK,KAAK,GAAA,EAGR,QAAQ,MAAK,MAAM,MAAM,MAAM,MAAM,EAAC,CAAA;;AAK1C,eAAO;;AAGT,qCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa,KAAK;AAK5B,aAAO,MAAK,qBAAqB,OAAO;IAE1C,GAAG;MACD,KAAK,KAAK,OAAO;MACjB,SAAS;MAGT,cAAY,SAAC,cAAc,QAAQ,SAAS,iBAAe;AACzD,YAAI,sBAAsB,QAAQ,KAAK,GAAG;AACxC,iBAAO,QAAQ,MAAM,aACnB,cACA,YAAY,MAAM,IAAI,OAAO,QAAQ,QACrC,QAAQ,WACR,eAAe;;MAGrB;KACD;AAED,SAAK,0BAA0B,KAAK,SAAC,SAAoC;AACvE,qCACE,QAAQ,QAAQ,OAChB,QAAQ,aAAa,KAAK;AAE5B,aAAO,MAAK,yBAAyB,OAAO;IAC9C,GAAG;MACD,KAAK,KAAK,OAAO;MACjB,cAAY,SAAC,IAAyB;YAAvB,QAAK,GAAA,OAAE,QAAK,GAAA,OAAE,UAAO,GAAA;AAClC,YAAI,sBAAsB,QAAQ,KAAK,GAAG;AACxC,iBAAO,QAAQ,MAAM,aACnB,OACA,OACA,QAAQ,SAAS;;MAGvB;KACD;EACH;AAjFO,EAAAA,aAAA,UAAA,aAAP,WAAA;AACE,SAAK,QAAQ,IAAI;EACnB;AAwFO,EAAAA,aAAA,UAAA,wBAAP,SAAgC,IAOD;QAN7B,QAAK,GAAA,OACL,QAAK,GAAA,OACL,KAAA,GAAA,QAAA,SAAM,OAAA,SAAG,eAAY,IACrB,YAAS,GAAA,WACT,KAAA,GAAA,mBAAA,oBAAiB,OAAA,SAAG,OAAI,IACxB,KAAA,GAAA,iBAAA,kBAAe,OAAA,SAAG,KAAK,OAAO,kBAAe;AAE7C,QAAM,WAAW,KAAK,OAAO,MAAM;AAEnC,gBAAS,SAAA,SAAA,CAAA,GACJ,iBAAiB,mBAAmB,KAAK,CAAC,CAAC,GAC3C,SAAU;AAGf,QAAM,UAAU,cAAc,MAAM;AACpC,QAAM,aAAa,KAAK,oBAAoB;MAC1C,cAAc,kBAAkB,KAAK,EAAE;MACvC,mBAAmB;MACnB,cAAc;MACd,SAAO,SAAA,EACL,OACA,OACA,UACA,WACA,WAAW,mBAAmB,SAAS,GACvC,gBAAe,GACZ,uBAAuB,OAAO,KAAK,OAAO,SAAS,CAAC;KAE1D;AAED,QAAI;AACJ,QAAI,WAAW,SAAS;AAKtB,gBAAU,CAAC,IAAI,kBACb,aAAa,WAAW,OAAO,GAC/B,WAAW,SACX,OACA,SAAS,CACV;AACD,UAAI,CAAC,mBAAmB;AACtB,cAAM,QAAQ,CAAC;;;AAInB,WAAO;MACL,QAAQ,WAAW;MACnB,UAAU,CAAC;MACX;;EAEJ;AAEO,EAAAA,aAAA,UAAA,UAAP,SACE,QACA,QACA,cACA,SAA+B;AAE/B,QAAI,sBAAsB,QAAQ,KAAK,KACnC,KAAK,aAAa,IAAI,MAAM,MAAM,cAAc;AAClD,UAAM,SAAS,KAAK,oBAAoB,KACtC,cACA,QACA,SAIA,KAAK,MAAM,QAAQ,MAAM,CAAC;AAE5B,UAAI,UAAU,WAAW,OAAO,QAAQ;AACtC,eAAO;;;AAGX,WAAO;EACT;AAGQ,EAAAA,aAAA,UAAA,uBAAR,SAA6B,IAKH;AAL1B,QAAA,QAAA;QACE,eAAY,GAAA,cACZ,oBAAiB,GAAA,mBACjB,eAAY,GAAA,cACZ,UAAO,GAAA;AAEP,QAAI,YAAY,iBAAiB,KAC7B,CAAC,QAAQ,SAAS,kBAAkB,kBAAkB,KAAK,KAC3D,CAAC,QAAQ,MAAM,IAAI,kBAAkB,KAAK,GAAG;AAC/C,aAAO;QACL,QAAQ,KAAK,MAAM;QACnB,SAAS,iCAAA,OAAiC,kBAAkB,OAAK,SAAA;;;AAI7D,QAAA,YAA+B,QAAO,WAA3B,WAAoB,QAAO,UAAjB,QAAU,QAAO;AAC9C,QAAM,WAAW,MAAM,cAAsB,mBAAmB,YAAY;AAE5E,QAAM,iBAAwC,CAAA;AAC9C,QAAI;AACJ,QAAM,gBAAgB,IAAI,WAAU;AAEpC,QAAI,KAAK,OAAO,eACZ,OAAO,aAAa,YACpB,CAAC,SAAS,kBAAkB,QAAQ,GAAG;AAIzC,qBAAe,KAAK,EAAE,YAAY,SAAQ,CAAE;;AAG9C,aAAS,cAAiBC,SAAuB,YAAkB;;AACjE,UAAIA,QAAO,SAAS;AAClB,kBAAU,cAAc,MAAM,UAAOC,MAAA,CAAA,GAAIA,IAAC,UAAU,IAAGD,QAAO,SAAOC,IAAA;;AAEvE,aAAOD,QAAO;IAChB;AAEA,QAAM,UAAU,IAAI,IAAI,aAAa,UAAU;AAE/C,YAAQ,QAAQ,SAAA,WAAS;;AAGvB,UAAI,CAAC,cAAc,WAAW,SAAS;AAAG;AAE1C,UAAI,QAAQ,SAAS,GAAG;AACtB,YAAI,aAAa,SAAS,UAAU;UAClC,WAAW,UAAU,KAAK;UAC1B,OAAO;UACP,WAAW,QAAQ;UACnB,MAAM;WACL,OAAO;AAEV,YAAM,aAAa,uBAAuB,SAAS;AAEnD,YAAI,eAAe,QAAQ;AACzB,cAAI,CAAC,sBAAsB,MAAM,SAAS,GAAG;AAC3C,sBAAU,cAAc,MAAM,UAAOC,MAAA,CAAA,GACnCA,IAAC,UAAU,IAAG,qBAAA,OACZ,UAAU,KAAK,OAAK,OAAA,EAAA,OAEpB,YAAY,iBAAiB,IACzB,kBAAkB,QAAQ,YAC1B,YAAY,KAAK,UAAU,mBAAmB,MAAM,CAAC,CAAC;;mBAKvD,QAAQ,UAAU,GAAG;AAC9B,uBAAa,cAAc,MAAK,wBAAwB;YACtD,OAAO;YACP,OAAO;YACP;YACA;WACD,GAAG,UAAU;mBAEL,CAAC,UAAU,cAAc;AAKlC,cAAI,QAAQ,iBAAiB;AAC3B,yBAAa,MAAK,MAAM,KAAK,UAAU;;mBAGhC,cAAc,MAAM;AAI7B,uBAAa,cAAc,MAAK,oBAAoB;YAClD,cAAc,UAAU;YACxB,mBAAmB;YACnB,cAAc,YAAY,UAAU,IAAI,aAAa;YACrD;WACD,GAAG,UAAU;;AAGhB,YAAI,eAAe,QAAQ;AACzB,yBAAe,MAAI,KAAA,CAAA,GAAG,GAAC,UAAU,IAAG,YAAU,GAAA;;aAG3C;AACL,YAAM,WAAW,yBACf,WACA,QAAQ,cAAc;AAGxB,YAAI,CAAC,YAAY,UAAU,SAAS,KAAK,iBAAiB;AACxD,gBAAM,kBAAkB,GAAA,UAAA,KAAA,KAAsB;;AAGhD,YAAI,YAAY,SAAS,gBAAgB,UAAU,QAAQ,GAAG;AAC5D,mBAAS,aAAa,WAAW,QAAQ,QAAQ,KAAK,OAAO;;;IAGnE,CAAC;AAED,QAAM,SAAS,eAAe,cAAc;AAC5C,QAAM,cAA0B,EAAE,QAAQ,QAAO;AACjD,QAAM,SAAS,QAAQ,kBACnB,KAAK,MAAM,MAAM,WAAW,IAG5B,gBAAgB,WAAW;AAI/B,QAAI,OAAO,QAAQ;AACjB,WAAK,aAAa,IAAI,OAAO,QAAQ,YAAY;;AAGnD,WAAO;EACT;AAGQ,EAAAF,aAAA,UAAA,2BAAR,SAAiC,IAKH;AAL9B,QAAA,QAAA;QACE,QAAK,GAAA,OACL,QAAK,GAAA,OACL,eAAY,GAAA,cACZ,UAAO,GAAA;AAEP,QAAI;AACJ,QAAI,gBAAgB,IAAI,WAAU;AAElC,aAAS,cAAiB,aAA4B,GAAS;;AAC7D,UAAI,YAAY,SAAS;AACvB,kBAAU,cAAc,MAAM,UAAOE,MAAA,CAAA,GAAIA,IAAC,CAAC,IAAG,YAAY,SAAOA,IAAA;;AAEnE,aAAO,YAAY;IACrB;AAEA,QAAI,MAAM,cAAc;AACtB,cAAQ,MAAM,OAAO,QAAQ,MAAM,OAAO;;AAG5C,YAAQ,MAAM,IAAI,SAAC,MAAM,GAAC;AAExB,UAAI,SAAS,MAAM;AACjB,eAAO;;AAIT,UAAI,QAAQ,IAAI,GAAG;AACjB,eAAO,cAAc,MAAK,wBAAwB;UAChD;UACA,OAAO;UACP;UACA;SACD,GAAG,CAAC;;AAIP,UAAI,MAAM,cAAc;AACtB,eAAO,cAAc,MAAK,oBAAoB;UAC5C,cAAc,MAAM;UACpB,mBAAmB;UACnB,cAAc,YAAY,IAAI,IAAI,OAAO;UACzC;SACD,GAAG,CAAC;;AAGP,UAAI,WAAS,YAAA,OAAA;AACX,qCAA6B,QAAQ,OAAO,OAAO,IAAI;;AAGzD,aAAO;IACT,CAAC;AAED,WAAO;MACL,QAAQ,QAAQ,kBAAkB,KAAK,MAAM,MAAM,KAAK,IAAI;MAC5D;;EAEJ;AACF,SAAAF;AAAA,EAtYA;AAwYA,SAAS,aAAa,MAAiB;AACrC,MAAI;AACF,SAAK,UAAU,MAAM,SAAC,GAAG,OAAK;AAC5B,UAAI,OAAO,UAAU;AAAU,cAAM;AACrC,aAAO;IACT,CAAC;WACM,QAAQ;AACf,WAAO;;AAEX;AAEA,SAAS,6BACP,OACA,OACA,YAAe;AAEf,MAAI,CAAC,MAAM,cAAc;AACvB,QAAM,YAAU,oBAAI,IAAI,CAAC,UAAU,CAAC;AACpC,cAAQ,QAAQ,SAAA,OAAK;AACnB,UAAI,gBAAgB,KAAK,GAAG;AAC1B;UAMA,CAAA,YAAc,KAAO;UACtB;UACA,2BAAA,OAAA,KAAA;UACJ,MAAA,KAAA;QACF;;;;;;;;AClgBM,IAAM,YAAY,IAAI,KAAI;AAEjC,IAAM,eAAe,oBAAI,QAAO;AAKhC,SAAS,aAAa,OAAuB;AAC3C,MAAI,OAAO,aAAa,IAAI,KAAK;AACjC,MAAI,CAAC,MAAM;AACT,iBAAa,IAAI,OAAO,OAAO;MAC7B,MAAM,oBAAI;MACV,KAAK,IAAG;KACT;;AAEH,SAAO;AACT;AAEM,SAAU,YAAY,OAAuB;AACjD,eAAa,KAAK,EAAE,KAAK,QAAQ,SAAA,IAAE;AAAI,WAAA,GAAG,YAAY,KAAK;EAApB,CAAqB;AAC9D;AAUM,SAAU,YAAY,OAAuB;AACjD,eAAa,KAAK,EAAE,KAAK,QAAQ,SAAA,IAAE;AAAI,WAAA,GAAG,YAAY,KAAK;EAApB,CAAqB;AAC9D;AAEM,SAAU,QAAW,OAAQ;AACjC,MAAMG,UAAS,oBAAI,IAAG;AACtB,MAAM,YAAY,oBAAI,IAAG;AAEzB,MAAM,KAAqB,SAAU,UAAQ;AAC3C,QAAI,UAAU,SAAS,GAAG;AACxB,UAAI,UAAU,UAAU;AACtB,gBAAQ;AACR,QAAAA,QAAO,QAAQ,SAAAC,QAAK;AAIlB,uBAAaA,MAAK,EAAE,IAAI,MAAM,EAAE;AAGhC,oBAAUA,MAAK;QACjB,CAAC;AAED,YAAM,eAAe,MAAM,KAAK,SAAS;AACzC,kBAAU,MAAK;AACf,qBAAa,QAAQ,SAAA,UAAQ;AAAI,iBAAA,SAAS,KAAK;QAAd,CAAe;;WAE7C;AAIL,UAAM,QAAQ,UAAU,SAAQ;AAChC,UAAI,OAAO;AACT,eAAO,KAAK;AACZ,qBAAa,KAAK,EAAE,IAAI,EAAE;;;AAI9B,WAAO;EACT;AAEA,KAAG,eAAe,SAAA,UAAQ;AACxB,cAAU,IAAI,QAAQ;AACtB,WAAO,WAAA;AACL,gBAAU,OAAO,QAAQ;IAC3B;EACF;AAEA,MAAM,SAAS,GAAG,cAAc,SAAA,OAAK;AACnC,IAAAD,QAAO,IAAI,KAAK;AAChB,iBAAa,KAAK,EAAE,KAAK,IAAI,EAAE;AAC/B,WAAO;EACT;AAEA,KAAG,cAAc,SAAA,OAAK;AAAI,WAAAA,QAAO,OAAO,KAAK;EAAnB;AAE1B,SAAO;AACT;AAQA,SAAS,UAAU,OAAoB;AACrC,MAAI,MAAM,kBAAkB;AAC1B,UAAM,iBAAgB;;AAE1B;;;AClGA,IAAM,qBAID,uBAAO,OAAO,IAAI;AAEvB,SAAS,oBAAoB,MAAkB;AAI7C,MAAM,WAAW,KAAK,UAAU,IAAI;AACpC,SAAO,mBAAmB,QAAQ,MAC/B,mBAAmB,QAAQ,IAAI,uBAAO,OAAO,IAAI;AACtD;AAEM,SAAU,yBACd,WAAuB;AAEvB,MAAM,OAAO,oBAAoB,SAAS;AAE1C,SAAO,KAAK,gBAAgB,KAAK,cAAc,SAC7C,QACA,SAAO;AAEP,QAAM,UACJ,SAAC,MAAM,KAAG;AAAK,aAAA,QAAQ,UAAU,KAAK,IAAI;IAA3B;AAEjB,QAAM,YAAY,QAAQ,YAAY,sBACpC,WACA,SAAA,eAAa;AACX,UAAI,YAAY,eACd,QAAQ,aACR,eAIA,OAAO;AAGT,UACE,cAAc,UACd,WAAW,QAAQ,eACnB,OAAO,KAAK,QAAQ,cAAc,CAAC,CAAC,GACpC;AAUA,oBAAY,eAAe,QAAQ,eAAe,UAAU;;AAG9D,gBACE,cAAc,QACd,GAAA,cAAA,KAAA,GAAA,GAAA,MAAA;AAKF,aAAO;IACT,CAAC;AAGH,WAAO,GAAA,OAAG,QAAQ,UAAQ,GAAA,EAAA,OAAI,KAAK,UAAU,SAAS,CAAC;EACzD;AACF;AASM,SAAU,uBAAuB,WAAuB;AAC5D,MAAM,OAAO,oBAAoB,SAAS;AAE1C,SAAO,KAAK,cAAc,KAAK,YAAY,SAAC,MAAM,IAIjD;QAHC,QAAK,GAAA,OACL,YAAS,GAAA,WACT,YAAS,GAAA;AAET,QAAM,YAAY,sBAAsB,WAAW,SAAA,SAAO;AACxD,UAAM,WAAW,QAAQ,CAAC;AAC1B,UAAM,YAAY,SAAS,OAAO,CAAC;AAEnC,UAAI,cAAc,KAAK;AACrB,YAAI,SAAS,gBAAgB,MAAM,UAAU,GAAG;AAC9C,cAAM,kBAAgB,SAAS,MAAM,CAAC;AAItC,cAAM,IAAI,MAAM,WAAW,KAAK,SAAAE,IAAC;AAAI,mBAAAA,GAAE,KAAK,UAAU;UAAjB,CAA8B;AAEnE,cAAM,gBAAgB,KAAK,yBAAyB,GAAG,SAAS;AAQhE,iBAAO,iBAAiB,eACtB,eAIA,QAAQ,MAAM,CAAC,CAAC;;AAMpB;;AAGF,UAAI,cAAc,KAAK;AACrB,YAAM,eAAe,SAAS,MAAM,CAAC;AACrC,YAAI,aAAa,OAAO,KAAK,WAAW,YAAY,GAAG;AACrD,cAAM,aAAa,QAAQ,MAAM,CAAC;AAClC,qBAAW,CAAC,IAAI;AAChB,iBAAO,eAAe,WAAW,UAAU;;AAK7C;;AAGF,UAAI,MAAM;AACR,eAAO,eAAe,MAAM,OAAO;;IAEvC,CAAC;AAED,QAAM,SAAS,KAAK,UAAU,SAAS;AAOvC,QAAI,QAAQ,WAAW,MAAM;AAC3B,mBAAa,MAAM;;AAGrB,WAAO;EACT;AACF;AAEM,SAAU,sBACd,WACA,WAAkC;AAIlC,MAAM,SAAS,IAAI;AACnB,SAAO,kBAAkB,SAAS,EAAE,OAAO,SAAC,WAAW,MAAI;;AACzD,QAAI,UAAU,UAAU,IAAI;AAC5B,QAAI,YAAY,QAAQ;AAGtB,eAAS,IAAI,KAAK,SAAS,GAAG,KAAK,GAAG,EAAE,GAAG;AACzC,mBAAO,KAAA,CAAA,GAAK,GAAC,KAAK,CAAC,CAAC,IAAG,SAAO;;AAEhC,kBAAY,OAAO,MAAM,WAAW,OAAO;;AAE7C,WAAO;EACT,GAAG,uBAAO,OAAO,IAAI,CAAC;AACxB;AAEM,SAAU,kBAAkB,MAAkB;AAClD,MAAM,OAAO,oBAAoB,IAAI;AAErC,MAAI,CAAC,KAAK,OAAO;AACf,QAAM,UAAoB,KAAK,QAAQ,CAAA;AACvC,QAAM,gBAAwB,CAAA;AAE9B,SAAK,QAAQ,SAAC,GAAG,GAAC;AAChB,UAAI,QAAQ,CAAC,GAAG;AACd,0BAAkB,CAAC,EAAE,QAAQ,SAAA,GAAC;AAAI,iBAAA,QAAM,KAAK,cAAY,OAAO,CAAC,CAAC;QAAhC,CAAiC;AACnE,sBAAY,SAAS;aAChB;AACL,sBAAY,KAAK,CAAC;AAClB,YAAI,CAAC,QAAQ,KAAK,IAAI,CAAC,CAAC,GAAG;AACzB,kBAAM,KAAK,cAAY,MAAM,CAAC,CAAC;AAC/B,wBAAY,SAAS;;;IAG3B,CAAC;;AAGH,SAAO,KAAK;AACd;AAEA,SAAS,WAGP,QAAc,KAAS;AACvB,SAAO,OAAO,GAAG;AACnB;AAEM,SAAU,eACd,QACA,MACA,SAA2B;AAa3B,YAAU,WAAW;AACrB,SAAO,UAAU,KAAK,OAAO,SAAS,QAAQ,KAAK,KAAG;AACpD,WAAO,QAAQ,GAAG,IACd,IAAI,IAAI,SAAA,OAAK;AAAI,aAAA,QAAQ,OAAO,GAAG;IAAlB,CAAmB,IACpC,OAAO,QAAS,KAAK,GAAG;EAC9B,GAAG,MAAM,CAAC;AACZ;AAEA,SAAS,UAAa,OAAQ;AAI5B,MAAI,gBAAgB,KAAK,GAAG;AAC1B,QAAI,QAAQ,KAAK,GAAG;AAClB,aAAO,MAAM,IAAI,SAAS;;AAE5B,WAAO,sBACL,OAAO,KAAK,KAAK,EAAE,KAAI,GACvB,SAAA,MAAI;AAAI,aAAA,eAAe,OAAO,IAAI;IAA1B,CAA2B;;AAGvC,SAAO;AACT;;;AC7MA,gBAAgB,aAAa,kBAAkB;AAoH/C,SAAS,uBAAuB,MAAoB;AAClD,SAAO,KAAK,SAAS,SAAS,KAAK,OACjC,KAAK,QAAQ,yBAAyB,KAAK,OAAO,KAAK,SAAS,IAAI;AACxE;AA6FA,IAAM,kBAAqC,WAAA;AAAM,SAAA;AAAA;AACjD,IAAM,kBAAmC,SAAC,OAAO,SAAO;AAAK,SAAA,QAAQ;AAAR;AAI7D,IAAM,cACJ,SAAC,UAAU,UAAU,IAAgB;MAAd,eAAY,GAAA;AAAO,SAAA,aAAa,UAAU,QAAQ;AAA/B;AAC5C,IAAM,eAAwC,SAAC,GAAG,UAAQ;AAAK,SAAA;AAAA;AAM/D,IAAA,WAAA,WAAA;AAsCE,WAAAC,UAAoB,QAKnB;AALmB,SAAA,SAAA;AArCZ,SAAA,eAYJ,uBAAO,OAAO,IAAI;AAEd,SAAA,YAEJ,uBAAO,OAAO,IAAI;AAMd,SAAA,eAAe,oBAAI,IAAG;AAMtB,SAAA,gBAAgB,oBAAI,IAAG;AAIf,SAAA,oBAA4C,uBAAO,OAAO,IAAI;AAC9D,SAAA,oBAA4C,uBAAO,OAAO,IAAI;AAE9D,SAAA,qBAAqB;AAQnC,SAAK,SAAM,SAAA,EACT,kBAAkB,wBAAuB,GACtC,MAAM;AAGX,SAAK,QAAQ,KAAK,OAAO;AAEzB,SAAK,gBAAgB,OAAO;AAC5B,SAAK,gBAAgB,UAAU;AAC/B,SAAK,gBAAgB,cAAc;AAEnC,QAAI,OAAO,eAAe;AACxB,WAAK,iBAAiB,OAAO,aAAa;;AAG5C,QAAI,OAAO,cAAc;AACvB,WAAK,gBAAgB,OAAO,YAAY;;EAE5C;AAEO,EAAAA,UAAA,UAAA,WAAP,SACE,QACA,gBAA0C;;AAE1C,QAAM,WAAW;AAEjB,QAAM,WAAW,mBACf,eAAe,cACf,KAAA,eAAe,iBAAW,QAAA,OAAA,SAAA,SAAA,GAAE,gBACzB,OAAO;AAOZ,QAAI,aAAa,KAAK,kBAAkB,YAAY;AAClD,aAAO,CAAC,YAAY;;AAItB,QAAM,cAAc,kBAAkB,eAAe,eAAe;AAEpE,QAAM,UAAO,SAAA,SAAA,CAAA,GACR,cAAc,GAAA,EACjB,UACA,aACA,WAAW,kBAAkB,eAAe,aAAa,WAAA;AACvD,UAAM,UAAU,0BAA0B,WAAW,WAAW;AAChE,aAAO,SAAS,UAAU,SAAS;QACjC,OAAO,SAAS,MAAM,MAAM;QAC5B,WAAW,QAAQ;OACpB;IACH,EAAC,CAAA;AAGH,QAAI;AAEJ,QAAM,SAAS,YAAY,KAAK,cAAc,QAAQ;AACtD,QAAI,QAAQ,UAAU,OAAO,SAAS,KAAK,OAAO;AAClD,WAAO,OAAO;AACZ,UAAM,gBAAgB,MAAK,SAAA,SAAA,CAAA,GAAK,MAAM,GAAK,WAAW,GAAG,OAAO;AAChE,UAAI,QAAQ,aAAa,GAAG;AAC1B,gBAAQ,yBAAyB,aAAa;aACzC;AACL,aAAK;AACL;;;AAIJ,SAAK,KAAK,OAAO,EAAE,IAAI;AACvB,WAAO,QAAQ,YAAY,CAAC,IAAI,QAAQ,SAAS,IAAI,CAAC,EAAE;EAC1D;AAEO,EAAAA,UAAA,UAAA,kBAAP,SAAuB,cAA0B;AAAjD,QAAA,QAAA;AACE,WAAO,KAAK,YAAY,EAAE,QAAQ,SAAA,UAAQ;AACxC,UAAM,KAKF,aAAa,QAAQ,GAJvB,YAAS,GAAA,WACT,eAAY,GAAA,cACZ,mBAAgB,GAAA,kBACb,WAAQ,OAAA,IAJP,CAAA,aAAA,gBAAA,kBAAA,CAKL;AAgBD,UAAI;AAAW,cAAK,gBAAgB,SAAS,QAAQ;AACrD,UAAI;AAAc,cAAK,gBAAgB,YAAY,QAAQ;AAC3D,UAAI;AAAkB,cAAK,gBAAgB,gBAAgB,QAAQ;AAEnE,UAAI,OAAO,KAAK,MAAK,WAAW,QAAQ,GAAG;AACzC,cAAK,UAAU,QAAQ,EAAE,KAAK,QAAQ;aACjC;AACL,cAAK,UAAU,QAAQ,IAAI,CAAC,QAAQ;;IAExC,CAAC;EACH;AAEQ,EAAAA,UAAA,UAAA,mBAAR,SAAyB,UAAkB,UAAoB;AAA/D,QAAA,QAAA;AACE,QAAM,WAAW,KAAK,cAAc,QAAQ;AACpC,QAAA,YAAsB,SAAQ,WAAnB,SAAW,SAAQ;AAEtC,aAAS,SACPC,WACA,OAAoC;AAEpC,MAAAA,UAAS,QACP,OAAO,UAAU,aAAa,QAG9B,UAAU,OAAO,cAGjB,UAAU,QAAQ,eAClBA,UAAS;IACb;AAIA,aAAS,UAAU,SAAS,KAAK;AAEjC,aAAS,QAEP,cAAc,QAAQ,kBAGtB,QAAQ,SAAS,IAAI,yBAAyB,SAAS,IAEvD,OAAO,cAAc,aAAa,YAElC,SAAS;AAEX,QAAI,QAAQ;AACV,aAAO,KAAK,MAAM,EAAE,QAAQ,SAAA,WAAS;AACnC,YAAMA,YAAW,MAAK,eAAe,UAAU,WAAW,IAAI;AAC9D,YAAMC,YAAW,OAAO,SAAS;AAEjC,YAAI,OAAOA,cAAa,YAAY;AAClC,UAAAD,UAAS,OAAOC;eACX;AACG,cAAA,UAAyBA,UAAQ,SAAxB,OAAgBA,UAAQ,MAAlB,QAAUA,UAAQ;AAEzC,UAAAD,UAAS,QAGP,YAAY,QAAQ,kBAGpB,QAAQ,OAAO,IAAI,uBAAuB,OAAO,IAEjD,OAAO,YAAY,aAAa,UAEhCA,UAAS;AAEX,cAAI,OAAO,SAAS,YAAY;AAC9B,YAAAA,UAAS,OAAO;;AAGlB,mBAASA,WAAU,KAAK;;AAG1B,YAAIA,UAAS,QAAQA,UAAS,OAAO;AAMnC,UAAAA,UAAS,QAAQA,UAAS,SAAS;;MAEvC,CAAC;;EAEL;AAEQ,EAAAD,UAAA,UAAA,kBAAR,SACE,OACA,UAAwB;AAAxB,QAAA,aAAA,QAAA;AAAA,iBAAA;IAAwB;AAExB,QAAM,SAAS,UAAU,MAAM,YAAW;AAC1C,QAAM,MAAM,KAAK,kBAAkB,MAAM;AACzC,QAAI,aAAa,KAAK;AACpB,gBAAU,CAAC,OAAO,QAAQ,OAAO,GAAA,KAAA;AAGjC,UAAI;AAAK,eAAO,KAAK,kBAAkB,GAAG;AAE1C,WAAK,kBAAkB,QAAQ,IAAI;AAEnC,WAAK,kBAAkB,MAAM,IAAI;;EAErC;AAEO,EAAAA,UAAA,UAAA,mBAAP,SAAwB,eAA+B;AAAvD,QAAA,QAAA;AACG,SAAK,qBAAiC;AACvC,WAAO,KAAK,aAAa,EAAE,QAAQ,SAAA,WAAS;AAI1C,YAAK,gBAAgB,WAAW,IAAI;AAEpC,oBAAc,SAAS,EAAE,QAAQ,SAAA,SAAO;AACtC,cAAK,gBAAgB,SAAS,IAAI,EAAG,IAAI,SAAS;AAClD,YAAM,QAAQ,QAAQ,MAAM,qBAAqB;AACjD,YAAI,CAAC,SAAS,MAAM,CAAC,MAAM,SAAS;AAElC,gBAAK,cAAc,IAAI,SAAS,IAAI,OAAO,OAAO,CAAC;;MAEvD,CAAC;IACH,CAAC;EACH;AAEQ,EAAAA,UAAA,UAAA,gBAAR,SAAsB,UAAgB;AAAtC,QAAA,QAAA;AACE,QAAI,CAAC,OAAO,KAAK,KAAK,cAAc,QAAQ,GAAG;AAC7C,UAAM,WACJ,KAAK,aAAa,QAAQ,IAAI,uBAAO,OAAO,IAAI;AAClD,eAAO,SAAS,uBAAO,OAAO,IAAI;AAuBlC,UAAI,eAAa,KAAK,aAAa,IAAI,QAAQ;AAC/C,UAAI,CAAC,gBAAc,KAAK,cAAc,MAAM;AAI1C,uBAAa,KAAK,gBAAgB,UAAU,IAAI;AAMhD,aAAK,cAAc,QAAQ,SAAC,QAAQ,OAAK;AACvC,cAAI,OAAO,KAAK,QAAQ,GAAG;AAIzB,gBAAM,kBAAkB,MAAK,aAAa,IAAI,KAAK;AACnD,gBAAI,iBAAiB;AACnB,8BAAgB,QAAQ,SAAA,WAAS;AAAI,uBAAA,aAAY,IAAI,SAAS;cAAzB,CAA0B;;;QAGrE,CAAC;;AAEH,UAAI,gBAAc,aAAW,MAAM;AACjC,qBAAW,QAAQ,SAAA,WAAS;AAC1B,cAAM,KAAsB,MAAK,cAAc,SAAS,GAAhD,SAAM,GAAA,QAAK,OAAI,OAAA,IAAjB,CAAA,QAAA,CAAmB;AACzB,iBAAO,OAAO,UAAQ,IAAI;AAC1B,iBAAO,OAAO,SAAO,QAAQ,MAAM;QACrC,CAAC;;;AAIL,QAAM,QAAQ,KAAK,UAAU,QAAQ;AACrC,QAAI,SAAS,MAAM,QAAQ;AAGzB,YAAM,OAAO,CAAC,EAAE,QAAQ,SAAA,QAAM;AAC5B,cAAK,iBAAiB,UAAU,MAAM;MACxC,CAAC;;AAGH,WAAO,KAAK,aAAa,QAAQ;EACnC;AAEQ,EAAAA,UAAA,UAAA,iBAAR,SACE,UACA,WACA,iBAAwB;AAMxB,QAAI,UAAU;AACZ,UAAM,gBAAgB,KAAK,cAAc,QAAQ,EAAE;AACnD,aAAO,cAAc,SAAS,KAC5B,oBAAoB,cAAc,SAAS,IAAI,uBAAO,OAAO,IAAI;;EAEvE;AAEQ,EAAAA,UAAA,UAAA,kBAAR,SACE,SACA,iBAAwB;AAExB,QAAI,eAAe,KAAK,aAAa,IAAI,OAAO;AAChD,QAAI,CAAC,gBAAgB,iBAAiB;AACpC,WAAK,aAAa,IAAI,SAAS,eAAe,oBAAI,IAAG,CAAU;;AAEjE,WAAO;EACT;AAEO,EAAAA,UAAA,UAAA,kBAAP,SACE,UACA,UACA,QACA,WAA+B;AAJjC,QAAA,QAAA;AAME,QAAI,CAAC,SAAS;AAAe,aAAO;AAIpC,QAAI,CAAC;AAAU,aAAO;AAEtB,QAAM,YAAY,SAAS,cAAc,KAAK;AAE9C,QAAI,aAAa;AAAW,aAAO;AAEnC,QAAI,KAAK,sBACL,KAAK,aAAa,IAAI,SAAS,GAAG;AACpC,UAAM,uBAAuB,KAAK,gBAAgB,UAAU,IAAI;AAChE,UAAM,cAAY,CAAC,oBAAoB;AACvC,UAAM,iBAAe,SAAC,SAAe;AACnC,YAAMG,gBAAe,MAAK,gBAAgB,SAAS,KAAK;AACxD,YAAIA,iBACAA,cAAa,QACb,YAAU,QAAQA,aAAY,IAAI,GAAG;AACvC,sBAAU,KAAKA,aAAY;;MAE/B;AAQA,UAAI,2BAA2B,CAAC,EAAE,UAAU,KAAK,cAAc;AAC/D,UAAI,wBAAwB;AAI5B,eAAS,IAAI,GAAG,IAAI,YAAU,QAAQ,EAAE,GAAG;AACzC,YAAM,eAAe,YAAU,CAAC;AAEhC,YAAI,aAAa,IAAI,SAAS,GAAG;AAC/B,cAAI,CAAC,qBAAqB,IAAI,SAAS,GAAG;AACxC,gBAAI,uBAAuB;AACzB,yBAAU,YAAK,SAAA,UAAA,KAAA,GAAA,UAAwC,SAAU;;AAMnE,iCAAqB,IAAI,SAAS;;AAEpC,iBAAO;;AAGT,qBAAa,QAAQ,cAAY;AAEjC,YAAI,4BAGA,MAAM,YAAU,SAAS,KAKzB,0BAA0B,SAAS,cAAc,QAAS,SAAS,GAAG;AAIxE,qCAA2B;AAC3B,kCAAwB;AAMxB,eAAK,cAAc,QAAQ,SAAC,QAAQ,aAAW;AAC7C,gBAAM,QAAQ,SAAS,MAAM,MAAM;AACnC,gBAAI,SAAS,MAAM,CAAC,MAAM,UAAU;AAClC,6BAAa,WAAW;;UAE5B,CAAC;;;;AAKP,WAAO;EACT;AAEO,EAAAH,UAAA,UAAA,aAAP,SAAkB,UAA8B,WAAiB;AAC/D,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,WAAO,CAAC,EAAE,UAAU,OAAO;EAC7B;AAEO,EAAAA,UAAA,UAAA,oBAAP,SAAyB,WAAyB;AACxC,QAAA,WAAwB,UAAS,UAAvB,YAAc,UAAS;AACzC,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,QAAI;AAEJ,QAAI,QAAQ,UAAU,OAAO;AAC7B,QAAI,SAAS,UAAU;AACrB,UAAM,UAA0C;QAC9C;QACA;QACA,OAAO,UAAU,SAAS;QAC1B,WAAW,UAAU;;AAEvB,UAAM,OAAO,uBAAuB,SAAS;AAC7C,aAAO,OAAO;AACZ,YAAM,oBAAoB,MAAM,MAAM,OAAO;AAC7C,YAAI,QAAQ,iBAAiB,GAAG;AAC9B,kBAAQ,uBAAuB,iBAAiB;eAC3C;AAGL,2BAAiB,qBAAqB;AACtC;;;;AAKN,QAAI,mBAAmB,QAAQ;AAC7B,uBAAiB,UAAU,QACvB,sBAAsB,UAAU,OAAO,UAAU,SAAS,IAC1D,gBAAgB,WAAW,uBAAuB,SAAS,CAAC;;AAKlE,QAAI,mBAAmB,OAAO;AAC5B,aAAO;;AAMT,WAAO,cAAc,uBAAuB,cAAc,IACtD,iBACA,YAAY,MAAM;EACxB;AAEO,EAAAA,UAAA,UAAA,YAAP,SACE,SACA,SAA+B;AAE/B,QAAM,oBAAoB,QAAQ;AAClC,QAAI,CAAC;AAAmB;AAExB,QAAM,cAAc,QAAQ,SAAS,QAAQ;AAC7C,QAAI,CAAC;AAAa;AAElB,QAAI,QAAQ,aAAa,QAAQ;AAC/B,UAAM,WAAW,QAAQ,MAAM,cAAsB,mBAAmB,YAAY;AACpF,UAAI;AAAU,gBAAQ,WAAW;;AAGnC,QAAM,iBAAiB,KAAK,kBAAkB,OAAO;AACrD,QAAM,YAAY,uBAAuB,cAAc;AACvD,QAAM,WAAW,QAAQ,MAAM,cAAiB,mBAAmB,cAAc;AACjF,QAAM,SAAS,KAAK,eAAe,QAAQ,UAAU,WAAW,KAAK;AACrE,QAAM,OAAO,UAAU,OAAO;AAE9B,QAAI,MAAM;AACR,UAAM,cAAc,yBAClB,MACA,mBACA,SACA,SACA,QAAQ,MAAM,WACZ,YAAY,iBAAiB,IACzB,kBAAkB,QAClB,mBACJ,cAAc,CACf;AAIH,aAAO,UAAU,UACf,KAAK,OACL,MACA,CAAC,UAAU,WAAW,CAAC;;AAI3B,WAAO;EACT;AAEO,EAAAA,UAAA,UAAA,kBAAP,SACE,UACA,WAAiB;AAEjB,QAAM,SAAS,KAAK,eAAe,UAAU,WAAW,KAAK;AAC7D,WAAO,UAAU,OAAO;EAC1B;AAEO,EAAAA,UAAA,UAAA,mBAAP,SACE,gBACA,WACA,eAAiC;AAEjC,QAAI,SAIF,KAAK,eAAe,gBAAgB,WAAW,KAAK;AACtD,QAAI,QAAQ,UAAU,OAAO;AAC7B,QAAI,CAAC,SAAS,eAAe;AAC3B,eAAS,KAAK,cAAc,aAAa;AACzC,cAAQ,UAAU,OAAO;;AAE3B,WAAO;EACT;AAEO,EAAAA,UAAA,UAAA,mBAAP,SACE,UACA,UACA,IACA,SACA,SAAqB;QAFnB,QAAK,GAAA,OAAE,WAAQ,GAAA,UAAE,QAAK,GAAA;AAIxB,QAAI,UAAU,aAAa;AAIzB,aAAO,yBACL,QAAQ,KAAK,EACb,UACA,QAAuB;;AAG3B,QAAI,UAAU,cAAc;AAE1B,aAAO;;AAOT,QAAI,QAAQ,WAAW;AACrB,iBAAW;;AAGb,WAAO,MAAM,UAAU,UAAU,yBAC/B,MAYA,QACA,EAAE,UACA,WAAW,MAAM,KAAK,OACtB,OACA,WAAW,QAAQ,UAAS,GAC9B,SACA,WAAW,uBAAO,OAAO,IAAI,CAAC,CAC/B;EACH;AACF,SAAAA;AAAA,EAtnBA;AAwnBA,SAAS,yBACP,UACA,mBACA,WACA,SACA,SAAoB;AAEpB,MAAM,iBAAiB,SAAS,kBAAkB,SAAS;AAC3D,MAAM,YAAY,uBAAuB,cAAc;AACvD,MAAM,YAAY,UAAU,aAAa,QAAQ;AAC3C,MAAA,KAA2B,QAAQ,OAAjC,cAAW,GAAA,aAAE,UAAO,GAAA;AAE5B,SAAO;IACL,MAAM,uBAAuB,SAAS;IACtC,OAAO,UAAU,SAAS;IAC1B;IACA;IACA;IACA;IACA;IACA;IACA,OAAO,SAAS;IAChB;IACA,WAAS,WAAA;AACP,aAAO,SAAS,UACd,0BAA0B,WAAW,mBAAmB,SAAS,GACjE,OAAO;IAEX;IACA,cAAc,yBAAyB,QAAQ,KAAK;;AAExD;AAEM,SAAU,0BACd,eACA,mBACA,WAA+C;AAG7C,MAAG,qBAGD,cAAa,CAAA,GAFZ,OAED,cAAa,CAAA,GADP,OACN,cAAa;AAEjB,MAAI;AAEJ,MAAI,OAAO,uBAAuB,UAAU;AAC1C,cAAU;MACR,WAAW;MAIX,MAAM,OAAO,IAAI,OAAO;;SAErB;AACL,cAAO,SAAA,CAAA,GAAQ,kBAAkB;AAGjC,QAAI,CAAC,OAAO,KAAK,SAAS,MAAM,GAAG;AACjC,cAAQ,OAAO;;;AAInB,MAAI,WAAW,YAAY,SAAK,QAAQ,SAAA,QAAA;AACtC,eAAU,YAAK,SAAA,UAAA,KAAA,GAAA,oBAAA,MAA0D,KAAA,aAAoB,CAAA,CAAA;;AAG/F,MAAI,WAAW,QAAQ,WAAW;AAChC,YAAQ,YAAY;;AAGtB,SAAO;AACT;AAEA,SAAS,yBACP,OAAsB;AAEtB,SAAO,SAAS,aAAa,UAAU,UAAQ;AAC7C,QAAI,QAAQ,QAAQ,KAAK,QAAQ,QAAQ,GAAG;AAC1C,YAAM,kBAAkB,CAAA;;AAO1B,QAAI,gBAAgB,QAAQ,KACxB,gBAAgB,QAAQ,GAAG;AAC7B,UAAM,QAAQ,MAAM,cAAc,UAAU,YAAY;AACxD,UAAM,QAAQ,MAAM,cAAc,UAAU,YAAY;AACxD,UAAM,cAAc,SAAS,SAAS,UAAU;AAEhD,UAAI,aAAa;AACf,eAAO;;AAGT,UAAI,YAAY,QAAQ,KACpB,wBAAwB,QAAQ,GAAG;AAIrC,cAAM,MAAM,SAAS,OAAO,QAAQ;AACpC,eAAO;;AAGT,UAAI,wBAAwB,QAAQ,KAChC,YAAY,QAAQ,GAAG;AAKzB,cAAM,MAAM,UAAU,SAAS,KAAK;AACpC,eAAO;;AAGT,UAAI,wBAAwB,QAAQ,KAChC,wBAAwB,QAAQ,GAAG;AACrC,eAAA,SAAA,SAAA,CAAA,GAAY,QAAQ,GAAK,QAAQ;;;AAIrC,WAAO;EACT;AACF;;;AC97BA,SAAS,iBACP,SACA,YACA,UAA8B;AAE9B,MAAM,MAAM,GAAA,OAAG,UAAU,EAAA,OAAG,QAAQ;AACpC,MAAI,WAAW,QAAQ,QAAQ,IAAI,GAAG;AACtC,MAAI,CAAC,UAAU;AACb,YAAQ,QAAQ,IAAI,KAAK,WACvB,QAAQ,eAAe,cACvB,QAAQ,aAAa,WACnB,UAAS,SAAA,SAAA,CAAA,GACR,OAAO,GAAA,EACV,YACA,SAAQ,CAAA,CACT;;AAEH,SAAO;AACT;AAUA,IAAA,cAAA,WAAA;AACE,WAAAI,aACkB,OACR,QACA,WAA4C;AAFpC,SAAA,QAAA;AACR,SAAA,SAAA;AACA,SAAA,YAAA;EACP;AAEI,EAAAA,aAAA,UAAA,eAAP,SAAoB,OAAwB,IAMvB;AANrB,QAAA,QAAA;QACE,QAAK,GAAA,OACL,SAAM,GAAA,QACN,SAAM,GAAA,QACN,YAAS,GAAA,WACT,YAAS,GAAA;AAET,QAAM,sBAAsB,uBAAuB,KAAK;AACxD,QAAM,SAAS,0BAAyB;AAExC,gBAAS,SAAA,SAAA,CAAA,GACJ,iBAAiB,mBAAmB,CAAC,GACrC,SAAU;AAGf,QAAM,UAAO,SAAA,SAAA,EACX,OACA,SAAS,uBAAO,OAAO,IAAI,GAC3B,OAAK,SAAI,UAAa,UAAW;AAC/B,aAAO,OAAO,MAAM,UAAU,QAAQ;IACxC,GACA,WACA,WAAW,mBAAmB,SAAS,EAAC,GACrC,uBAAuB,OAAO,KAAK,SAAS,CAAC,GAAA,EAChD,WAAW,CAAC,CAAC,WACb,cAAc,oBAAI,OAClB,YAAY,OACZ,UAAU,OACV,SAAS,oBAAI,MAAG,CAAA;AAGlB,QAAM,MAAM,KAAK,oBAAoB;MACnC,QAAQ,UAAU,uBAAO,OAAO,IAAI;MACpC;MACA,cAAc,oBAAoB;MAClC,WAAW,EAAE,KAAK,oBAAI,MAAG;MACzB;KACD;AAED,QAAI,CAAC,YAAY,GAAG,GAAG;AACrB,YAAM,kBAAkB,GAAA,MAAA;;AAK1B,YAAQ,aAAa,QAAQ,SAACC,KAA0CC,SAAM;UAA9C,cAAWD,IAAA,aAAE,YAASA,IAAA,WAAE,eAAYA,IAAA;AAClE,UAAM,YAAY,cAAcC,OAAM;AAEtC,UAAI,aAAa,UAAU,IAAI,MAAM;AACnC,YAAM,UAAU,MAAK,YAAY,WAAW,WAAW,aAAa,OAAO;AAC3E,YAAI,YAAY,OAAO,GAAG;AAIxB;;AAIF,sBAAc;;AAGhB,UAAI,WAAW,YAAS,SAAW,CAAA,QAAA,WAAA;AACjC,YAAM,4BAAgD,uBAAO,OAAO,IAAI;AACxE,qBAAa,QAAQ,SAAA,OAAK;AACxB,cAAI,MAAM,cAAc;AACtB,sCAAwB,MAAM,KAAK,KAAK,IAAI;;QAEhD,CAAC;AAED,YAAM,oBAAkB,SAAC,gBAAsB;AAC7C,iBAAA,0BACE,uBAAuB,cAAc,CAAC,MAClC;QAFN;AAIF,YAAM,qBAAmB,SAAC,gBAAsB;AAC9C,cAAM,YAAY,aAAa,UAAU,IAAI,IAAI,cAAc;AAC/D,iBAAO,QAAQ,aAAa,UAAU,QAAQ,UAAU,KAAK,KAAK;QACpE;AAEA,eAAO,KAAK,WAAW,EAAE,QAAQ,SAAA,gBAAc;AAK7C,cAAI,kBAAgB,cAAc,KAC9B,CAAC,mBAAiB,cAAc,GAAG;AACrC,8BACE,WACA,aACA,gBACA,QAAQ,KAAK;;QAGnB,CAAC;;AAGH,YAAM,MAAMA,SAAQ,WAAW;IACjC,CAAC;AAOD,UAAM,OAAO,IAAI,KAAK;AAEtB,WAAO;EACT;AAEQ,EAAAF,aAAA,UAAA,sBAAR,SAA4B,IAQC;AAR7B,QAAA,QAAA;QACE,SAAM,GAAA,QACN,SAAM,GAAA,QACN,eAAY,GAAA,cACZ,UAAO,GAAA,SAGP,YAAS,GAAA;AAED,QAAA,WAAa,KAAK,MAAK;AAI/B,QAAI,WAAwB,uBAAO,OAAO,IAAI;AAK9C,QAAM,WACH,UAAU,SAAS,kBAAkB,MAAM,KAC5C,sBAAsB,QAAQ,cAAc,QAAQ,WAAW,KAC9D,UAAU,QAAQ,MAAM,IAAI,QAAQ,YAAY;AAEnD,QAAI,aAAa,OAAO,UAAU;AAChC,eAAS,aAAa;;AAWxB,QAAM,YAA+B,WAAA;AACnC,UAAM,UAAU,0BACd,WACA,UACA,QAAQ,SAAS;AAGnB,UAAI,YAAY,QAAQ,IAAI,GAAG;AAC7B,YAAM,OAAO,QAAQ,aAAa,IAAI,QAAQ,KAAK,KAAK;AACxD,YAAI,MAAM;AACR,cAAM,WAAS,SAAS,UAAS,SAAA,SAAA,CAAA,GAC5B,OAAO,GAAA,EACV,MAAM,KAAK,YAAW,CAAA,GACrB,OAAO;AAEV,cAAI,aAAW,QAAQ;AACrB,mBAAO;;;;AAKb,aAAO,SAAS,UAAU,SAAS,OAAO;IAC5C;AAEA,QAAM,eAAe,oBAAI,IAAG;AAE5B,SAAK,cACH,cACA,QAIA,SACA,QAAQ,EACR,QAAQ,SAACG,UAAS,OAAK;;AACvB,UAAM,iBAAiB,uBAAuB,KAAK;AACnD,UAAM,QAAQ,OAAO,cAAc;AAEnC,mBAAa,IAAI,KAAK;AAEtB,UAAI,UAAU,QAAQ;AACpB,YAAM,iBAAiB,SAAS,kBAAkB;UAChD;UACA,WAAW,MAAM,KAAK;UACtB;UACA,WAAWA,SAAQ;SACpB;AAED,YAAM,YAAY,kBAAkB,WAAW,cAAc;AAE7D,YAAI,gBAAgB,MAAK,kBACvB,OACA,OAGA,MAAM,eACF,iBAAiBA,UAAS,OAAO,KAAK,IACtCA,UACJ,SAAS;AAMX,YAAI,gBAAa;AAIjB,YAAI,MAAM,iBACL,YAAY,aAAa,KACzB,wBAAwB,aAAa,IAAI;AAC5C,0BAAgB,UAAkB,cAAc,aAAa;;AAG/D,YAAM,QAAQ,SAAS,iBACrB,UACA,MAAM,KAAK,OACX,aAAa;AAGf,YAAI,OAAO;AACT,oBAAU,OAAO;YAEf;YACA;YACA;;eAEG;AACL,qCAA2B,WAAW,cAAc;;AAGtD,mBAAWA,SAAQ,MAAM,WAAQF,MAAA,CAAA,GAC/BA,IAAC,cAAc,IAAG;iBAIpB,WAAO,YAAA,SACP,CAACE,SAAQ,cACT,CAACA,SAAQ,YACT,CAAC,sBAAsB,MAAM,KAAK,KAIlC,CAAC,SAAS,gBAAgB,UAAU,MAAM,KAAK,KAAK,GACpD;AACA,mBAAU,YAAM,SAAA,UAAA,MAAA,IAAA,uBAA8C,KAAA,GAAA,MAAuB;;IAEzF,CAAC;AAID,QAAI;AACI,UAAA,KAAkB,SAAS,SAAS,QAAQ;QAChD;QACA;QACA,aAAa,QAAQ;QACrB,aAAa;QACb;OACD,GANM,KAAE,GAAA,CAAA,GAAE,YAAS,GAAA,CAAA;AAUpB,eAAS,UAAU;AAInB,UAAI,WAAW;AAEb,mBAAW,QAAQ,MAAM,UAAU,SAAS;;aAEvC,GAAG;AAEV,UAAI,CAAC;AAAQ,cAAM;;AAGrB,QAAI,aAAa,OAAO,QAAQ;AAC9B,UAAM,UAAU,cAAc,MAAM;AAOpC,UAAM,OAAO,QAAQ,QAAQ,MAAM,MAAM,QAAQ,QAAQ,MAAM,IAAI,CAAA;AACnE,UAAI,KAAK,QAAQ,YAAY,KAAK;AAAG,eAAO;AAC5C,WAAK,KAAK,YAAY;AAOtB,UAAI,KAAK,UAAU,KAAK,OAAO,QAC7B,QACA,SACA,cACA,OAAO,GACN;AACD,eAAO;;AAGT,UAAM,aAAW,QAAQ,aAAa,IAAI,MAAM;AAChD,UAAI,YAAU;AACZ,mBAAS,cAAc,QAAQ,MAAM,WAAS,aAAa,QAAQ;AACnE,mBAAS,YAAY,gBAAgB,WAAS,WAAW,SAAS;AAClE,qBAAa,QAAQ,SAAA,OAAK;AAAI,iBAAA,WAAS,aAAa,IAAI,KAAK;QAA/B,CAAgC;aACzD;AACL,gBAAQ,aAAa,IAAI,QAAQ;UAC/B,aAAa;UAIb,WAAW,iBAAiB,SAAS,IAAI,SAAS;UAClD;SACD;;AAGH,aAAO;;AAGT,WAAO;EACT;AAEQ,EAAAH,aAAA,UAAA,oBAAR,SACE,OACA,OACA,SACA,WAAoB;AAJtB,QAAA,QAAA;AAME,QAAI,CAAC,MAAM,gBAAgB,UAAU,MAAM;AAIzC,aAAO,WAAU,YAAU,QAAS,UAAM,KAAA,IAAA;;AAG5C,QAAI,QAAQ,KAAK,GAAG;AAClB,aAAO,MAAM,IAAI,SAAC,MAAM,GAAC;AACvB,YAAMI,SAAQ,MAAK,kBACjB,MAAM,OAAO,SAAS,kBAAkB,WAAW,CAAC,CAAC;AACvD,mCAA2B,WAAW,CAAC;AACvC,eAAOA;MACT,CAAC;;AAGH,WAAO,KAAK,oBAAoB;MAC9B,QAAQ;MACR,cAAc,MAAM;MACpB;MACA;KACD;EACH;AAIQ,EAAAJ,aAAA,UAAA,gBAAR,SASE,cACA,QACA,SACA,UAA2E;AAA3E,QAAA,aAAA,QAAA;AAAA,iBAAW,sBAAsB,QAAQ,cAAc,QAAQ,WAAW;IAAC;AAE3E,QAAM,WAAW,oBAAI,IAAG;AAChB,QAAA,WAAa,KAAK,MAAK;AAE/B,QAAM,eAAe,IAAI,KAUtB,KAAK;AAER,KAAC,SAAS,QAERK,eACA,kBAA0B;AAE1B,UAAM,cAAc,aAAa,OAC/BA,eAKA,iBAAiB,YACjB,iBAAiB,QAAQ;AAE3B,UAAI,YAAY;AAAS;AACzB,kBAAY,UAAU;AAEtB,MAAAA,cAAa,WAAW,QAAQ,SAAA,WAAS;AACvC,YAAI,CAAC,cAAc,WAAW,QAAQ,SAAS;AAAG;AAE5C,YAAA,aAAyB,iBAAgB,YAA7B,WAAa,iBAAgB;AAC/C,YAIE,EAAE,cAAc,aAChB,gBAAgB,UAAU,UAAU,GACpC;AACA,oBAAU,WAAW,QAAQ,SAAA,KAAG;AAC9B,gBAAM,OAAO,IAAI,KAAK;AACtB,gBAAI,SAAS;AAAU,2BAAa;AACpC,gBAAI,SAAS,SAAS;AACpB,kBAAM,OAAO,yBAAyB,KAAK,QAAQ,SAAS;AAK5D,kBAAI,CAAC,QAAS,KAA0B,OAAO,OAAO;AACpD,2BAAW;;;UAKjB,CAAC;;AAGH,YAAI,QAAQ,SAAS,GAAG;AACtB,cAAM,WAAW,SAAS,IAAI,SAAS;AACvC,cAAI,UAAU;AAIZ,yBAAa,cAAc,SAAS;AACpC,uBAAW,YAAY,SAAS;;AAGlC,mBAAS,IACP,WACA,iBAAiB,SAAS,YAAY,QAAQ,CAAC;eAG5C;AACL,cAAM,WAAW,yBACf,WACA,QAAQ,cAAc;AAGxB,cAAI,CAAC,YAAY,UAAU,SAAS,KAAK,iBAAiB;AACxD,kBAAM,kBAAkB,IAAA,UAAA,KAAA,KAAwB;;AAGlD,cAAI,YACA,SAAS,gBACP,UAAU,UAAU,QAAQ,QAAQ,SAAS,GAAG;AAEpD,oBACE,SAAS,cACT,iBAAiB,SAAS,YAAY,QAAQ,CAAC;;;MAIvD,CAAC;IACH,GAAG,cAAc,OAAO;AAExB,WAAO;EACT;AAEQ,EAAAL,aAAA,UAAA,cAAR,SACE,WACA,UACA,UACA,SACA,gBAAsD;;AALxD,QAAA,QAAA;AAOE,QAAI,UAAU,IAAI,QAAQ,CAAC,YAAY,QAAQ,GAAG;AAChD,UAAM,MAIJ,CAAC,QAAQ,QAAQ,MAIhB,YAAY,QAAQ,KAAK,wBAAwB,QAAQ,KACxD,WAAW;AAKf,UAAM,MAAI;AAMV,UAAI,OAAK,CAAC,gBAAgB;AACxB,yBAAiB,CAAC,YAAY,GAAC,IAAI,IAAE,QAAQ,GAAC;;AAQhD,UAAI;AAEJ,UAAM,aAAW,SACf,MACA,MAAqB;AAErB,eAAO,QAAQ,IAAI,IACd,OAAO,SAAS,WAAW,KAAK,IAAI,IAAI,SACzC,QAAQ,MAAM,cAAc,MAAM,OAAO,IAAI,CAAC;MACpD;AAEA,gBAAU,IAAI,QAAQ,SAAC,WAAW,gBAAc;AAC9C,YAAM,OAAO,WAAS,KAAG,cAAc;AACvC,YAAM,OAAO,WAAS,KAAG,cAAc;AAEvC,YAAI,WAAW;AAAM;AACrB,YAAI,gBAAgB;AAClB,yBAAe,KAAK,cAAc;;AAEpC,YAAM,OAAO,MAAK,YAChB,WACA,MACA,MACA,SACA,cAAc;AAEhB,YAAI,SAAS,MAAM;AACjB,4BAAgB,mBAAiB,oBAAI;AACrC,0BAAc,IAAI,gBAAgB,IAAI;;AAExC,YAAI,gBAAgB;AAClB,oBAAU,eAAe,IAAG,MAAO,cAAc;;MAErD,CAAC;AAED,UAAI,iBAAe;AAEjB,mBAAY,QAAQ,GAAC,IAAI,IAAE,MAAM,CAAC,IAAG,SAAA,CAAA,GAAM,GAAC;AAC5C,wBAAc,QAAQ,SAAC,OAAO,MAAI;AAC/B,mBAAiB,IAAI,IAAI;QAC5B,CAAC;;;AAIL,QAAI,UAAU,MAAM;AAClB,aAAO,KAAK,MAAM,SAAS,iBACzB,UACA,UACA,UAAU,MACV,SACA,mBAAkB,KAAA,QAAQ,OAAM,WAAU,MAAA,IAAI,cAAc,CAAC;;AAIjE,WAAO;EACT;AACF,SAAAA;AAAA,EA/jBA;AAikBA,IAAM,qBAAkC,CAAA;AAExC,SAAS,kBACP,IACA,MAAqB;MADnB,MAAG,GAAA;AAGL,MAAI,CAAC,IAAI,IAAI,IAAI,GAAG;AAClB,QAAI,IAAI,MAAM,mBAAmB,IAAG,KAAM,EAAE,KAAK,oBAAI,MAAG,CAAE;;AAE5D,SAAO,IAAI,IAAI,IAAI;AACrB;AAEA,SAAS,gBACP,MACA,OAA4B;AAE5B,MAAI,SAAS,SAAS,CAAC,SAAS,iBAAiB,KAAK;AAAG,WAAO;AAChE,MAAI,CAAC,QAAQ,iBAAiB,IAAI;AAAG,WAAO;AAE5C,MAAM,OAAO,KAAK,QAAQ,MAAM,OAAM,SAAA,SAAA,CAAA,GACjC,KAAK,IAAI,GACT,MAAM,IAAI,IACX,KAAK,QAAQ,MAAM;AAEvB,MAAM,kBAAkB,KAAK,IAAI,QAAQ,MAAM,IAAI;AACnD,MAAM,MAAM,kBAAkB,oBAAI,QAChC,KAAK,IAAI,OAAO,KAAK,MAAM,MAAM;AAEnC,MAAM,SAAS,EAAE,MAAM,IAAG;AAE1B,MAAI,iBAAiB;AACnB,QAAM,uBAAqB,IAAI,IAAI,MAAM,IAAI,KAAI,CAAE;AAEnD,SAAK,IAAI,QAAQ,SAAC,UAAU,KAAG;AAC7B,aAAO,IAAI,IACT,KACA,gBAAgB,UAAU,MAAM,IAAI,IAAI,GAAG,CAAC,CAAC;AAE/C,2BAAmB,OAAO,GAAG;IAC/B,CAAC;AAED,yBAAmB,QAAQ,SAAA,KAAG;AAC5B,aAAO,IAAI,IACT,KACA,gBACE,MAAM,IAAI,IAAI,GAAG,GACjB,KAAK,IAAI,IAAI,GAAG,CAAC,CAClB;IAEL,CAAC;;AAGH,SAAO;AACT;AAEA,SAAS,iBAAiB,MAA2B;AACnD,SAAO,CAAC,QAAQ,EAAE,KAAK,QAAQ,KAAK,IAAI;AAC1C;AAEA,SAAS,2BACP,IACA,MAAqB;MADnB,MAAG,GAAA;AAGL,MAAM,YAAY,IAAI,IAAI,IAAI;AAC9B,MAAI,aAAa,iBAAiB,SAAS,GAAG;AAC5C,uBAAmB,KAAK,SAAS;AACjC,QAAI,OAAO,IAAI;;AAEnB;AAEA,IAAM,WAAW,oBAAI,IAAG;AAIxB,SAAS,kBACP,aACA,aACA,gBACA,OAAsB;AAEtB,MAAM,WAAW,SAAC,UAAiC;AACjD,QAAM,QAAQ,MAAM,cAA2B,UAAU,cAAc;AACvE,WAAO,OAAO,UAAU,YAAY;EACtC;AAEA,MAAM,WAAW,SAAS,WAAW;AACrC,MAAI,CAAC;AAAU;AAEf,MAAM,WAAW,SAAS,WAAW;AACrC,MAAI,CAAC;AAAU;AAIf,MAAI,YAAY,QAAQ;AAAG;AAI3B,MAAI,MAAM,UAAU,QAAQ;AAAG;AAK/B,MAAI,OAAO,KAAK,QAAQ,EAAE,MACxB,SAAA,KAAG;AAAI,WAAA,MAAM,cAAc,UAAU,GAAG,MAAM;EAAvC,CAA6C,GAAG;AACvD;;AAGF,MAAM,aACJ,MAAM,cAAsB,aAAa,YAAY,KACrD,MAAM,cAAsB,aAAa,YAAY;AACvD,MAAM,YAAY,uBAAuB,cAAc;AACvD,MAAM,cAAc,GAAA,OAAG,YAAU,GAAA,EAAA,OAAI,SAAS;AAE9C,MAAI,SAAS,IAAI,WAAW;AAAG;AAC/B,WAAS,IAAI,WAAW;AAExB,MAAM,iBAA2B,CAAA;AAGjC,MAAI,CAAC,QAAQ,QAAQ,KACjB,CAAC,QAAQ,QAAQ,GAAG;AACtB,KAAC,UAAU,QAAQ,EAAE,QAAQ,SAAA,OAAK;AAChC,UAAM,WAAW,MAAM,cAAc,OAAO,YAAY;AACxD,UAAI,OAAO,aAAa,YACpB,CAAC,eAAe,SAAS,QAAQ,GAAG;AACtC,uBAAe,KAAK,QAAQ;;IAEhC,CAAC;;AAGH,aAAU,YACZ,SAAA,UAAA,KAAA,IAAA,WAAA,YAAA,eAAA,SAiBM,uCAAuC,eAAe,KAAK,OAAO,IAAI,gDACtE,IACJ,aACA,UACA,QAAQ;AAEV;;;AC5xBA,IAAA,gBAAA,SAAA,QAAA;AAAmC,YAAAM,gBAAA,MAAA;AA4BjC,WAAAA,eAAY,QAAgC;AAAhC,QAAA,WAAA,QAAA;AAAA,eAAA,CAAA;IAAgC;AAA5C,QAAA,QACE,OAAA,KAAA,IAAA,KAAO;AAxBD,UAAA,UAAU,oBAAI,IAAG;AAKjB,UAAA,uBAAuB,IAAI,kBAAkB,qBAAqB;AAS1D,UAAA,yBAAyB;AAOzB,UAAA,UAAU;AA+UlB,UAAA,UAAU;AA3UhB,UAAK,SAAS,gBAAgB,MAAM;AACpC,UAAK,cAAc,CAAC,CAAC,MAAK,OAAO;AAEjC,UAAK,WAAW,IAAI,SAAS;MAC3B,OAAO;MACP,kBAAkB,MAAK,OAAO;MAC9B,eAAe,MAAK,OAAO;MAC3B,cAAc,MAAK,OAAO;KAC3B;AAED,UAAK,KAAI;;EACX;AAEQ,EAAAA,eAAA,UAAA,OAAR,WAAA;AAIE,QAAM,YAAY,KAAK,OAAO,IAAI,YAAY,KAAK;MACjD,UAAU,KAAK;MACf,eAAe,KAAK,OAAO;KAC5B;AAOD,SAAK,iBAAiB,UAAU;AAEhC,SAAK,iBAAgB;EACvB;AAEQ,EAAAA,eAAA,UAAA,mBAAR,SAAyB,uBAA+B;AAAxD,QAAA,QAAA;AACE,QAAM,iBAAiB,KAAK;AACpB,QAAA,YAAc,KAAK,OAAM;AAKjC,SAAK,cAAc,IAAI,YACrB,MACA,KAAK,cAAc,IAAI,YAAY;MACjC,OAAO;MACP,aAAa,KAAK;MAClB,oBAAoB,KAAK,OAAO;MAChC,iBAAiB,sBAAsB,KAAK,MAAM;MAClD,OAAO,wBACH,SACA,kBAAkB,eAAe;MACrC;KACD,GACD,SAAS;AAGX,SAAK,sBAAsB,KAAK,SAC9B,GACA,SAA0B;AAE1B,aAAO,MAAK,eAAe,GAAG,OAAO;IACvC,GAAG;MACD,KAAK,KAAK,OAAO;MACjB,cAAc,SAAC,GAAqB;AAGlC,YAAM,QAAQ,EAAE,aAAa,MAAK,iBAAiB,MAAK;AACxD,YAAI,sBAAsB,KAAK,GAAG;AACxB,cAAA,aAA8B,EAAC,YAAnB,KAAkB,EAAC,IAAf,YAAc,EAAC;AACvC,iBAAO,MAAM,aACX,EAAE,OAOF,EAAE,UACF,mBAAmB,EAAE,YAAY,IAAI,UAAS,CAAE,CAAC;;MAGvD;KACD;AAKD,yBAAI,IAAI;MACN,KAAK,KAAK;MACV,KAAK,eAAe;KACrB,GAAE,QAAQ,SAAA,OAAK;AAAI,aAAA,MAAM,aAAY;IAAlB,CAAoB;EAC1C;AAEO,EAAAA,eAAA,UAAA,UAAP,SAAe,MAA2B;AACxC,SAAK,KAAI;AAIT,QAAI;AAAM,WAAK,KAAK,QAAQ,IAAI;AAChC,WAAO;EACT;AAEO,EAAAA,eAAA,UAAA,UAAP,SAAe,YAA2B;AAA3B,QAAA,eAAA,QAAA;AAAA,mBAAA;IAA2B;AACxC,YAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAO;EAC/D;AAEO,EAAAA,eAAA,UAAA,OAAP,SAAe,SAA0B;AASrC,QAAA,KACE,QAAO,mBADT,oBAAiB,OAAA,SAAG,QAAK;AAE3B,QAAI;AACF,aAAO,KAAK,YAAY,sBAAqB,SAAA,SAAA,CAAA,GACxC,OAAO,GAAA,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,KAAK,QACb,kBAAiB,CAAA,CAAA,EAChB,UAAU;aACN,GAAG;AACV,UAAI,aAAa,mBAAmB;AAMlC,eAAO;;AAET,YAAM;;EAEV;AAEO,EAAAA,eAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,QAAI;AACF,QAAE,KAAK;AACP,aAAO,KAAK,YAAY,aAAa,KAAK,MAAM,OAAO;;AAEvD,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK,iBAAgB;;;EAG3B;AAEO,EAAAA,eAAA,UAAA,SAAP,SAAwE,SAAoC;AAC1G,QAAI,OAAO,KAAK,SAAS,IAAI,KAAK,CAAC,QAAQ,IAAI;AAU7C,aAAO;;AAET,QAAM,QAAQ,QAAQ,aAClB,KAAK,iBACL,KAAK;AACT,QAAI;AACF,QAAE,KAAK;AACP,aAAO,MAAM,OAAO,QAAQ,MAAM,cAAc,QAAQ,MAAM;;AAE9D,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK,iBAAgB;;;EAG3B;AAEO,EAAAA,eAAA,UAAA,OAAP,SACE,SAA6C;AAE7C,WAAO,KAAK,YAAY,sBAAqB,SAAA,SAAA,CAAA,GACxC,OAAO,GAAA,EACV,OAAO,QAAQ,aAAa,KAAK,iBAAiB,KAAK,MACvD,QAAQ,QAAQ,MAAM,cACtB,QAAQ,KAAK,OAAM,CAAA,CAAA;EAEvB;AAEO,EAAAA,eAAA,UAAA,QAAP,SACE,OAA4C;AAD9C,QAAA,QAAA;AAGE,QAAI,CAAC,KAAK,QAAQ,MAAM;AAWtB,kBAAY,IAAI;;AAElB,SAAK,QAAQ,IAAI,KAAK;AACtB,QAAI,MAAM,WAAW;AACnB,WAAK,oBAAoB,KAAK;;AAEhC,WAAO,WAAA;AAIL,UAAI,MAAK,QAAQ,OAAO,KAAK,KAAK,CAAC,MAAK,QAAQ,MAAM;AACpD,oBAAY,KAAI;;AAKlB,YAAK,oBAAoB,OAAO,KAAK;IACvC;EACF;AAEO,EAAAA,eAAA,UAAA,KAAP,SAAU,SAQT;AACC,uBAAmB,MAAK;AACxB,QAAM,MAAM,KAAK,eAAe,GAAE;AAClC,QAAI,WAAW,CAAC,KAAK,SAAS;AAC5B,UAAI,QAAQ,kBAAkB;AAC5B,aAAK,iBAAiB,QAAQ,qBAAqB;iBAC1C,QAAQ,uBAAuB;AACxC,aAAK,YAAY,WAAU;;;AAG/B,WAAO;EACT;AASO,EAAAA,eAAA,UAAA,SAAP,SAAc,QAAgB,YAAoB;AAChD,YAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,OAAO,MAAM;EACrE;AAOO,EAAAA,eAAA,UAAA,UAAP,SAAe,QAAgB,YAAoB;AACjD,YAAQ,aAAa,KAAK,iBAAiB,KAAK,MAAM,QAAQ,MAAM;EACtE;AAQO,EAAAA,eAAA,UAAA,WAAP,SAAgB,QAA+B;AAC7C,QAAI,YAAY,MAAM;AAAG,aAAO,OAAO;AACvC,QAAI;AACF,aAAO,KAAK,SAAS,SAAS,MAAM,EAAE,CAAC;aAChC,GAAG;AACV,iBAAU,YAAQ,SAAA,UAAA,KAAA,CAAA;;EAEtB;AAEO,EAAAA,eAAA,UAAA,QAAP,SAAa,SAA2B;AACtC,QAAI,CAAC,QAAQ,IAAI;AACf,UAAI,OAAO,KAAK,SAAS,IAAI,GAAG;AAG9B,eAAO;;AAET,gBAAO,SAAA,SAAA,CAAA,GAAQ,OAAO,GAAA,EAAE,IAAI,aAAY,CAAA;;AAE1C,QAAI;AAKF,QAAE,KAAK;AAIP,aAAO,KAAK,eAAe,MAAM,SAAS,KAAK,IAAI;;AAEnD,UAAI,CAAC,EAAE,KAAK,WAAW,QAAQ,cAAc,OAAO;AAClD,aAAK,iBAAgB;;;EAG3B;AAEO,EAAAA,eAAA,UAAA,QAAP,SAAa,SAA4B;AAAzC,QAAA,QAAA;AACE,SAAK,KAAI;AAET,uBAAmB,MAAK;AAExB,QAAI,WAAW,QAAQ,gBAAgB;AAGrC,WAAK,QAAQ,QAAQ,SAAA,OAAK;AAAI,eAAA,MAAK,oBAAoB,OAAO,KAAK;MAArC,CAAsC;AACpE,WAAK,QAAQ,MAAK;AAClB,kBAAY,IAAI;WACX;AAOL,WAAK,iBAAgB;;AAGvB,WAAO,QAAQ,QAAO;EACxB;AAEO,EAAAA,eAAA,UAAA,mBAAP,SAAwB,YAAkB;AACxC,QAAM,oBAAoB,KAAK,eAAe,YAAY,UAAU;AACpE,QAAI,sBAAsB,KAAK,gBAAgB;AAC7C,WAAK,iBAAiB;AACtB,WAAK,iBAAgB;;EAEzB;AAIO,EAAAA,eAAA,UAAA,QAAP,SACE,SAAyD;AAD3D,QAAA,QAAA;AAII,QAAA,SAIE,QAAO,QAHT,KAGE,QAAO,YAHT,aAAU,OAAA,SAAG,OAAI,IACjB,mBAEE,QAAO,kBADT,iBACE,QAAO;AAEX,QAAI;AACJ,QAAM,UAAU,SAAC,OAAmB;AAC5B,UAAAC,MAA2B,OAAzB,OAAIA,IAAA,MAAE,iBAAcA,IAAA;AAC5B,QAAE,MAAK;AACP,UAAI,OAAO;AACT,cAAK,OAAO,MAAK,iBAAiB;;AAEpC,UAAI;AACF,eAAO,eAAe,OAAO,KAAI;;AAEjC,UAAE,MAAK;AACP,cAAK,OAAO;AACZ,cAAK,iBAAiB;;IAE1B;AAEA,QAAM,eAAe,oBAAI,IAAG;AAE5B,QAAI,kBAAkB,CAAC,KAAK,SAAS;AAUnC,WAAK,iBAAgB,SAAA,SAAA,CAAA,GAChB,OAAO,GAAA,EACV,gBAAc,SAAC,OAAK;AAClB,qBAAa,IAAI,KAAK;AACtB,eAAO;MACT,EAAC,CAAA,CAAA;;AAIL,QAAI,OAAO,eAAe,UAAU;AAIlC,WAAK,iBAAiB,KAAK,eAAe,SAAS,YAAY,OAAO;eAC7D,eAAe,OAAO;AAM/B,cAAQ,KAAK,IAAI;WACZ;AAGL,cAAO;;AAGT,QAAI,OAAO,qBAAqB,UAAU;AACxC,WAAK,iBAAiB,KAAK,eAAe,YAAY,gBAAgB;;AAMxE,QAAI,kBAAkB,aAAa,MAAM;AACvC,WAAK,iBAAgB,SAAA,SAAA,CAAA,GAChB,OAAO,GAAA,EACV,gBAAc,SAAC,OAAO,MAAI;AACxB,YAAM,SAAS,eAAe,KAAK,MAAM,OAAO,IAAI;AACpD,YAAI,WAAW,OAAO;AAIpB,uBAAa,OAAO,KAAK;;AAE3B,eAAO;MACT,EAAC,CAAA,CAAA;AAIH,UAAI,aAAa,MAAM;AACrB,qBAAa,QAAQ,SAAA,OAAK;AAAI,iBAAA,MAAK,oBAAoB,MAAM,KAAK;QAApC,CAAqC;;WAEhE;AAIL,WAAK,iBAAiB,OAAO;;AAG/B,WAAO;EACT;AAEO,EAAAD,eAAA,UAAA,qBAAP,SACE,QACA,cAA4B;AAE5B,WAAO,KAAK,MAAM;MAChB;MACA,YAAY,gBAAiB,iBAAiB;KAC/C;EACH;AAEO,EAAAA,eAAA,UAAA,oBAAP,SAAyB,UAAsB;AAC7C,WAAO,KAAK,sBAAsB,KAAK,uBAAuB,QAAQ,CAAC;EACzE;AAEU,EAAAA,eAAA,UAAA,mBAAV,SAA2B,SAA0B;AAArD,QAAA,QAAA;AACE,QAAI,CAAC,KAAK,SAAS;AACjB,WAAK,QAAQ,QAAQ,SAAA,GAAC;AAAI,eAAA,MAAK,oBAAoB,GAAG,OAAO;MAAnC,CAAoC;;EAElE;AAEQ,EAAAA,eAAA,UAAA,yBAAR,SAA+B,UAAsB;AAC3C,QAAA,YAAc,KAAK,OAAM;AACjC,WAAO,YACH,UAAU,UAAU,QAAQ,IAC5B;EACN;AAEQ,EAAAA,eAAA,UAAA,wBAAR,SAA8B,UAAsB;AAClD,QAAI,KAAK,aAAa;AACpB,aAAO,KAAK,qBAAqB,kBAAkB,QAAQ;;AAE7D,WAAO;EACT;AAQQ,EAAAA,eAAA,UAAA,iBAAR,SACE,GACA,SAA0B;AAElB,QAAA,WAAa,EAAC;AAQtB,QAAM,OAAO,KAAK,KAAU,CAAC;AAE7B,QAAI,SAAS;AACX,UAAI,EAAE,cACF,OAAO,QAAQ,eAAe,UAAU;AAC1C,aAAK,4BAA4B;;AAGnC,UAAI,QAAQ,kBACR,QAAQ,eAAe,KAAK,MAAM,GAAG,MAAM,QAAQ,MAAM,OAAO;AAGlE;;;AAIJ,QAAI,CAAC,YAAY,CAAC,MAAM,SAAS,QAAQ,KAAK,MAAM,GAAG;AACrD,QAAE,SAAS,EAAE,WAAW,MAAM,QAAQ;;EAE1C;AACF,SAAAA;AAAA,EAxhBmC,WAAW;;;ACdxC,SAAU,yBAAsB;AACpC,MAAA,YAAA,CAAA;WAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,cAAA,EAAA,IAAA,UAAA,EAAA;;AAEA,SAAA,KAAW,iBAAgB,KAAA,MAAhB,kBAAgB,cAAA,CAAA,MAAA,GAAI,WAAS,KAAA,CAAA,GAAA;AAC1C;AAEQ,IAAS,mBAAqB,MAAM,UAAS;AAErD,IAAA,mBAAA,WAAA;AAME,WAAAE,oBAAA;AAAY,QAAA,YAAA,CAAA;aAAA,KAAA,GAAA,KAAA,UAAA,QAAA,MAA4B;AAA5B,gBAAA,EAAA,IAAA,UAAA,EAAA;;AALJ,SAAA,WAAwB,uBAAO,OAAO,IAAI;AAMhD,SAAK,YAAW;AAChB,QAAI,UAAU,QAAQ;AACpB,WAAK,SAAS,MAAM,MAAM,SAAS;;EAEvC;AAEO,EAAAA,kBAAA,UAAA,WAAP,WAAA;AAAA,QAAA,QAAA;AACE,QAAM,cAAc,oBAAI,IAAG;AAC3B,qBAAiB,KAAK,WAAW,SAAC,KAAiB;AACjD,6BAAuB,GAAG,EAAE,QAAQ,SAAA,MAAI;AACtC,oBAAY,IAAI,KAAK,KAAK,OAAO,IAAI;MACvC,CAAC;IACH,CAAC;AAED,gBAAY,QAAQ,SAAC,MAAM,MAAI;AAC7B,UAAI,SAAS,MAAK,SAAS,IAAI,GAAG;AAChC,cAAK,SAAS,IAAI,IAAI;AACtB,cAAK,WAAW,IAAI;;IAExB,CAAC;AAED,WAAO;EACT;AAGQ,EAAAA,kBAAA,UAAA,aAAR,SAAmB,MAAY;EAAG;AAE3B,EAAAA,kBAAA,UAAA,cAAP,WAAA;AACE,SAAK,cACH,KAAK,SAAS,KAAK,iBAAiB,QAAQ,GAC5C;AACF,SAAK,YAAY,KAAK,iBAAiB,WAAW;AAClD,SAAK,sBAAsB,KAAK,iBAAiB,qBAAqB;EACxE;AAEQ,EAAAA,kBAAA,UAAA,mBAAR,SAIG,MAAW;AACZ,QAAM,WAAW;AACjB,QAAM,iBAAiBA,kBAAiB,UAAU,IAAI;AACtD,WAAO,KAAK,WAAA;AACV,aAAO,eAAe,MAAM,UAAU,SAAS;IACjD,GAAG;MACD,cAAc,SAAA,KAAG;AAAI,eAAA;MAAA;KACtB;EACH;AAEO,EAAAA,kBAAA,UAAA,SAAP,SAAc,cAAoB;AAChC,WAAO,KAAK,SAAS,YAAY,KAAK;EACxC;AAEO,EAAAA,kBAAA,UAAA,YAAP,SAAyC,UAAW;AAApD,QAAA,QAAA;AACE,QAAM,UAAU,oBAAI,IAAG;AACvB,2BAAuB,QAAQ,EAAE,QAAQ,SAAA,KAAG;AAC1C,cAAQ,IAAI,IAAI,KAAK,OAAO,GAAG;IACjC,CAAC;AAED,QAAM,UAAU,oBAAI,IAAG;AACvB,QAAM,UAAU,SAAC,YAAkB;AACjC,UAAI,CAAC,QAAQ,IAAI,UAAU,GAAG;AAC5B,gBAAQ,IAAI,UAAU;;IAE1B;AAEA,QAAM,sBAAsB,SAAC,MAAa;AAAK,aAAA,OAAO,KACpD,MAAK,oBAAoB,IAAI,CAAC,EAC9B,QAAQ,OAAO;IAF8B;AAI/C,wBAAoB,QAAQ;AAE5B,QAAM,UAAoB,CAAA;AAC1B,QAAM,MAAmB,uBAAO,OAAO,IAAI;AAI3C,YAAQ,QAAQ,SAAA,cAAY;AAC1B,UAAM,mBAAmB,QAAQ,IAAI,YAAY;AACjD,UAAI,kBAAkB;AACpB,4BAAoB,IAAI,YAAY,IAAI,gBAAgB;aACnD;AACL,gBAAQ,KAAK,YAAY;AACzB,YAAM,MAAM,MAAK,OAAO,YAAY;AACpC,YAAI,KAAK;AACP,8BAAoB,IAAI,YAAY,IAAI,GAAG;;;IAGjD,CAAC;AAED,QAAI,QAAQ,QAAQ;AAClB,UAAM,iBAAyC,CAAA;AAC/C,cAAQ,QAAQ,SAAA,MAAI;AAClB,YAAM,MAAM,IAAI,IAAI;AACpB,YAAI,KAAK;AACP,yBAAa,KAAK,GAAG;;MAEzB,CAAC;AAED,UAAI,eAAa,QAAQ;AACvB,mBAAQ,SAAA,SAAA,CAAA,GACH,QAAQ,GAAA,EACX,aAAa,SAAS,YAAY,OAAO,cAAY,EAAC,CAAA;;;AAK5D,WAAO;EACT;AAEO,EAAAA,kBAAA,UAAA,sBAAP,SAA2B,MAAa;AACtC,QAAM,UAA6B,uBAAO,OAAO,IAAI;AAErD,UAAM,MAAM;MACV,gBAAc,SAAC,MAAI;AACjB,gBAAQ,KAAK,KAAK,KAAK,IAAI;MAC7B;KACD;AAED,WAAO;EACT;AACF,SAAAA;AAAA,EAhIA;",
  "names": ["Slot", "dep", "dep", "cache", "ApolloCache", "Cache", "MissingFieldError", "hasOwnProperty", "EntityStore", "CacheGroup", "EntityStore", "Root", "Layer", "Stump", "ObjectCanon", "StoreReader", "result", "_a", "caches", "cache", "d", "Policies", "existing", "incoming", "supertypeSet", "StoreWriter", "_a", "dataId", "context", "value", "selectionSet", "InMemoryCache", "_a", "FragmentRegistry"]
}
